{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YlRH3mQM9tf"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIEGXF8oM9tt"
      },
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2WS96dc-Nzu",
        "outputId": "e09ff8a8-265e-4047-bcdf-28671fcdbd84"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = s.replace(\".\", \"\")\n",
        "    s = s.replace(\",\", \"\")\n",
        "    s = s.replace(\"!\", \"\")\n",
        "    s = s.replace(\" !\", \"\")\n",
        "    s = s.replace(\"?\", \"\")\n",
        "    return s"
      ],
      "metadata": {
        "id": "vLEVMxv6qa-W"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = open(\"drive/MyDrive/rus-eng/rus.txt\", encoding='utf-8').read().strip().split('\\n')\n",
        "loaded_pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in lines]\n",
        "\n",
        "loaded_pairs[-30][0], loaded_pairs[-30][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39-BJAaD9QCS",
        "outputId": "e4f7aa62-d701-44de-fe98-4fd8a0906e06"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('if you take a child outside and point at the moon the child will look at the moon if you do the same with a dog it will look at your finger',\n",
              " 'если вы выведете ребенка и покажете ему пальцем на луну ребенок посмотрит на луну если вы то же самое проделаете с собакои она будет смотреть на ваш палец')"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXKs8j4bM9t6"
      },
      "source": [
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1"
      ],
      "metadata": {
        "id": "SqcINu6H-muV"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 4"
      ],
      "metadata": {
        "id": "48Th_VAj9QSg"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = []\n",
        "\n",
        "prev_pair = ['', '']\n",
        "for pair in loaded_pairs:\n",
        "    if pair[0] == prev_pair[0]: continue\n",
        "    prev_pair = pair\n",
        "    if len(pair[0].split(' ')) >= MAX_LENGTH: continue\n",
        "    if len(pair[1].split(' ')) >= MAX_LENGTH: continue\n",
        "\n",
        "    pairs.append(pair)\n",
        "\n",
        "pairs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jibD-31k4d4R",
        "outputId": "2e7afd30-9afb-47d2-f449-5f84c76aa81c"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['go', 'марш'],\n",
              " ['hi', 'здравствуите'],\n",
              " ['run', 'беги'],\n",
              " ['who', 'кто'],\n",
              " ['wow', 'вот это да'],\n",
              " ['duck', 'пригнись'],\n",
              " ['fire', 'огонь'],\n",
              " ['help', 'помогите'],\n",
              " ['hide', 'прячься'],\n",
              " ['jump', 'прыгаи']]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang = Lang(\"en\")\n",
        "output_lang = Lang(\"ru\")"
      ],
      "metadata": {
        "id": "k-2Y_2vO8uCl"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pair in pairs:\n",
        "    input_lang.addSentence(pair[0])\n",
        "    output_lang.addSentence(pair[1])\n",
        "\n",
        "print(\"Counted words:\")\n",
        "print(input_lang.name, input_lang.n_words)\n",
        "print(output_lang.name, output_lang.n_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZHfS9XQ2tQe",
        "outputId": "cf928f68-68ab-461a-d34d-572bc7cd83c1"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counted words:\n",
            "en 5186\n",
            "ru 9012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgtWqznCM9uH"
      },
      "source": [
        "The Encoder\n",
        "-----------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9vm9QBWM9uI"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, (hidden, _) = self.lstm(output, (hidden, hidden))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwLTlgSyM9uK"
      },
      "source": [
        "The Decoder\n",
        "-----------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFbuUL1LM9uL"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, (hidden, _) = self.lstm(output, (hidden, hidden))\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6gGPtXFM9uQ"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fn8VDv8M9uS"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKsdwPmSM9uU"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_z_k5IiM9uX"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JXG-RzCM9uZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bxf45h6M9ud"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qUmQIGwM9uf"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_56t10oM9uh",
        "outputId": "abab31d2-4722-4649-db95-f8b2fa7be601",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 150000, print_every=5000)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 34s (- 16m 52s) (5000 3%) 5.0351\n",
            "1m 1s (- 14m 18s) (10000 6%) 4.9574\n",
            "1m 27s (- 13m 8s) (15000 10%) 4.7601\n",
            "1m 53s (- 12m 20s) (20000 13%) 4.4711\n",
            "2m 20s (- 11m 40s) (25000 16%) 4.2417\n",
            "2m 46s (- 11m 5s) (30000 20%) 4.0680\n",
            "3m 13s (- 10m 35s) (35000 23%) 3.8825\n",
            "3m 40s (- 10m 5s) (40000 26%) 3.7422\n",
            "4m 6s (- 9m 35s) (45000 30%) 3.6018\n",
            "4m 33s (- 9m 6s) (50000 33%) 3.4724\n",
            "4m 59s (- 8m 37s) (55000 36%) 3.3294\n",
            "5m 26s (- 8m 9s) (60000 40%) 3.2352\n",
            "5m 53s (- 7m 42s) (65000 43%) 3.0793\n",
            "6m 20s (- 7m 14s) (70000 46%) 3.0016\n",
            "6m 47s (- 6m 47s) (75000 50%) 2.8895\n",
            "7m 14s (- 6m 20s) (80000 53%) 2.7964\n",
            "7m 41s (- 5m 53s) (85000 56%) 2.6961\n",
            "8m 8s (- 5m 25s) (90000 60%) 2.6007\n",
            "8m 36s (- 4m 59s) (95000 63%) 2.4987\n",
            "9m 4s (- 4m 32s) (100000 66%) 2.3825\n",
            "9m 31s (- 4m 4s) (105000 70%) 2.2888\n",
            "9m 58s (- 3m 37s) (110000 73%) 2.2301\n",
            "10m 25s (- 3m 10s) (115000 76%) 2.1227\n",
            "10m 53s (- 2m 43s) (120000 80%) 2.0644\n",
            "11m 20s (- 2m 16s) (125000 83%) 1.9531\n",
            "11m 48s (- 1m 48s) (130000 86%) 1.8723\n",
            "12m 15s (- 1m 21s) (135000 90%) 1.7630\n",
            "12m 43s (- 0m 54s) (140000 93%) 1.7020\n",
            "13m 11s (- 0m 27s) (145000 96%) 1.6365\n",
            "13m 39s (- 0m 0s) (150000 100%) 1.5788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEoEylSyM9uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad82771-22c6-43a2-b4d9-61b7890b4925"
      },
      "source": [
        "evaluateRandomly(encoder1, decoder1)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> you must go\n",
            "= ты должен поити\n",
            "< ты должен помочь <EOS>\n",
            "\n",
            "> you didn't look\n",
            "= ты не посмотрел\n",
            "< ты не посмотрел <EOS>\n",
            "\n",
            "> we're deluding ourselves\n",
            "= мы обманываем себя\n",
            "< мы будем себя <EOS>\n",
            "\n",
            "> we're tired\n",
            "= мы устали\n",
            "< мы устали <EOS>\n",
            "\n",
            "> i felt cold\n",
            "= мне было холодно\n",
            "< мне холодно <EOS>\n",
            "\n",
            "> everyone noticed that\n",
            "= все это заметили\n",
            "< все это заметили <EOS>\n",
            "\n",
            "> he's the scapegoat\n",
            "= он козел отпущения\n",
            "< он козел <EOS>\n",
            "\n",
            "> we're too weak\n",
            "= мы слишком слабы\n",
            "< мы слишком закончили <EOS>\n",
            "\n",
            "> i'll arrange that\n",
            "= я это улажу\n",
            "< я это <EOS>\n",
            "\n",
            "> it's really clean\n",
            "= оно очень чистое\n",
            "< это очень тяжело <EOS>\n",
            "\n"
          ]
        }
      ]
    }
  ]
}