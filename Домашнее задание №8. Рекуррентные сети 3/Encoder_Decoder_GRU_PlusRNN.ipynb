{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YlRH3mQM9tf"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIEGXF8oM9tt"
      },
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2WS96dc-Nzu",
        "outputId": "fae3d9ae-a0ef-4e2a-f614-72f17dd227db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = s.replace(\".\", \"\")\n",
        "    s = s.replace(\",\", \"\")\n",
        "    s = s.replace(\"!\", \"\")\n",
        "    s = s.replace(\" !\", \"\")\n",
        "    s = s.replace(\"?\", \"\")\n",
        "    return s"
      ],
      "metadata": {
        "id": "vLEVMxv6qa-W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = open(\"drive/MyDrive/rus-eng/rus.txt\", encoding='utf-8').read().strip().split('\\n')\n",
        "loaded_pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in lines]\n",
        "\n",
        "loaded_pairs[-30][0], loaded_pairs[-30][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39-BJAaD9QCS",
        "outputId": "6aa6f789-95be-4981-8e84-1a0b9e7909e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('if you take a child outside and point at the moon the child will look at the moon if you do the same with a dog it will look at your finger',\n",
              " 'если вы выведете ребенка и покажете ему пальцем на луну ребенок посмотрит на луну если вы то же самое проделаете с собакои она будет смотреть на ваш палец')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXKs8j4bM9t6"
      },
      "source": [
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1"
      ],
      "metadata": {
        "id": "SqcINu6H-muV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 4"
      ],
      "metadata": {
        "id": "48Th_VAj9QSg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = []\n",
        "\n",
        "prev_pair = ['', '']\n",
        "for pair in loaded_pairs:\n",
        "    if pair[0] == prev_pair[0]: continue\n",
        "    prev_pair = pair\n",
        "    if len(pair[0].split(' ')) >= MAX_LENGTH: continue\n",
        "    if len(pair[1].split(' ')) >= MAX_LENGTH: continue\n",
        "\n",
        "    pairs.append(pair)\n",
        "\n",
        "pairs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jibD-31k4d4R",
        "outputId": "802d34ad-90b8-40b0-84f7-52641051085a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['go', 'марш'],\n",
              " ['hi', 'здравствуите'],\n",
              " ['run', 'беги'],\n",
              " ['who', 'кто'],\n",
              " ['wow', 'вот это да'],\n",
              " ['duck', 'пригнись'],\n",
              " ['fire', 'огонь'],\n",
              " ['help', 'помогите'],\n",
              " ['hide', 'прячься'],\n",
              " ['jump', 'прыгаи']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang = Lang(\"en\")\n",
        "output_lang = Lang(\"ru\")"
      ],
      "metadata": {
        "id": "k-2Y_2vO8uCl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pair in pairs:\n",
        "    input_lang.addSentence(pair[0])\n",
        "    output_lang.addSentence(pair[1])\n",
        "\n",
        "print(\"Counted words:\")\n",
        "print(input_lang.name, input_lang.n_words)\n",
        "print(output_lang.name, output_lang.n_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZHfS9XQ2tQe",
        "outputId": "888a378c-cc46-4d07-9297-c033cbfe386a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counted words:\n",
            "en 5186\n",
            "ru 9012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgtWqznCM9uH"
      },
      "source": [
        "The Encoder\n",
        "-----------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9vm9QBWM9uI"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.rnn = nn.RNN(hidden_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwLTlgSyM9uK"
      },
      "source": [
        "The Decoder\n",
        "-----------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFbuUL1LM9uL"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.rnn = nn.RNN(hidden_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6gGPtXFM9uQ"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fn8VDv8M9uS"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKsdwPmSM9uU"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_z_k5IiM9uX"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JXG-RzCM9uZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bxf45h6M9ud"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qUmQIGwM9uf"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_56t10oM9uh",
        "outputId": "3b30800c-21e9-491a-e357-43158ba69224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 150000, print_every=5000)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 46s (- 22m 14s) (5000 3%) 5.0632\n",
            "1m 21s (- 19m 1s) (10000 6%) 4.5664\n",
            "1m 57s (- 17m 33s) (15000 10%) 4.3022\n",
            "2m 34s (- 16m 44s) (20000 13%) 4.0995\n",
            "3m 11s (- 15m 56s) (25000 16%) 3.9519\n",
            "3m 47s (- 15m 11s) (30000 20%) 3.8637\n",
            "4m 24s (- 14m 30s) (35000 23%) 3.7491\n",
            "5m 1s (- 13m 48s) (40000 26%) 3.6567\n",
            "5m 36s (- 13m 5s) (45000 30%) 3.5563\n",
            "6m 11s (- 12m 23s) (50000 33%) 3.4822\n",
            "6m 47s (- 11m 43s) (55000 36%) 3.3997\n",
            "7m 22s (- 11m 4s) (60000 40%) 3.3171\n",
            "7m 58s (- 10m 25s) (65000 43%) 3.2776\n",
            "8m 34s (- 9m 47s) (70000 46%) 3.2370\n",
            "9m 10s (- 9m 10s) (75000 50%) 3.1374\n",
            "9m 48s (- 8m 34s) (80000 53%) 3.0814\n",
            "10m 25s (- 7m 58s) (85000 56%) 3.0232\n",
            "11m 1s (- 7m 20s) (90000 60%) 2.9799\n",
            "11m 37s (- 6m 43s) (95000 63%) 2.9361\n",
            "12m 12s (- 6m 6s) (100000 66%) 2.9049\n",
            "12m 48s (- 5m 29s) (105000 70%) 2.8499\n",
            "13m 25s (- 4m 52s) (110000 73%) 2.8175\n",
            "14m 0s (- 4m 15s) (115000 76%) 2.7768\n",
            "14m 36s (- 3m 39s) (120000 80%) 2.7409\n",
            "15m 12s (- 3m 2s) (125000 83%) 2.6982\n",
            "15m 48s (- 2m 25s) (130000 86%) 2.6952\n",
            "16m 23s (- 1m 49s) (135000 90%) 2.6550\n",
            "16m 59s (- 1m 12s) (140000 93%) 2.6212\n",
            "17m 34s (- 0m 36s) (145000 96%) 2.5694\n",
            "18m 11s (- 0m 0s) (150000 100%) 2.5790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEoEylSyM9uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3161aa9f-ba18-4a86-bc35-3bee4bf18ce3"
      },
      "source": [
        "evaluateRandomly(encoder1, decoder1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> tom fixed everything\n",
            "= том все починил\n",
            "< том все слышал <EOS>\n",
            "\n",
            "> tom is falling\n",
            "= том падает\n",
            "< том разведен <EOS>\n",
            "\n",
            "> we're both grandfathers\n",
            "= мы оба дедушки\n",
            "< мы оба друзья <EOS>\n",
            "\n",
            "> we're fasting\n",
            "= мы постимся\n",
            "< мы чувствительные <EOS>\n",
            "\n",
            "> tom don't die\n",
            "= не умираи том\n",
            "< том не жадныи <EOS>\n",
            "\n",
            "> that's a wolf\n",
            "= это волк\n",
            "< это самое <EOS>\n",
            "\n",
            "> it's so weird\n",
            "= это так странно\n",
            "< это так странно <EOS>\n",
            "\n",
            "> i was poor\n",
            "= я был беден\n",
            "< я был спокоен <EOS>\n",
            "\n",
            "> hold this\n",
            "= подержи это\n",
            "< хватит <EOS>\n",
            "\n",
            "> you're early\n",
            "= ты рано\n",
            "< ты права <EOS>\n",
            "\n"
          ]
        }
      ]
    }
  ]
}