{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "                !pip install -q transformers"
      ],
      "metadata": {
        "id": "pT-BjEyUSXuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ddf94d3-2155-42fd-95e7-4320a067cb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import os\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "KyoyY9YPcx3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cabd2d1d-e275-45a4-a1e9-72f873a10fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNlKs_9Hb-VO",
        "outputId": "99b3107e-a464-4776-d68f-77f50bed580c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text):\n",
        "    text = text.replace('«', '')\n",
        "    text = text.replace('»', '')\n",
        "    text = text.replace('\"', '')\n",
        "    text = text.replace('-', '')\n",
        "\n",
        "    text = text.replace('т. д.', 'т д')\n",
        "    text = text.replace('т. п.', 'т п')\n",
        "    text = text.replace('др.', 'др')\n",
        "\n",
        "    text = text.replace('...,', ',')\n",
        "    text = text.replace('?,', ',')\n",
        "    text = text.replace('!,', ',')\n",
        "    text = text.replace('.,', ',')\n",
        "    text = text.replace('.)', ')')\n",
        "    text = text.replace(';,', ',')\n",
        "\n",
        "    text = text.replace('....', ';')\n",
        "    text = text.replace('...', ';')\n",
        "    text = text.replace('..', ';')\n",
        "\n",
        "    text = text.replace('!', ';')\n",
        "    text = text.replace('!!', ';')\n",
        "    text = text.replace('!!!', ';')\n",
        "    text = text.replace('?', ';')\n",
        "    text = text.replace('??', ';')\n",
        "    text = text.replace('???', ';')\n",
        "    text = text.replace('!?', ';')\n",
        "    text = text.replace('?!', ';')\n",
        "    text = text.replace('.', ';')\n",
        "    text = text.replace(u'\\xa0', u' ')\n",
        "\n",
        "    return [txt.strip() for txt in text.split(';')]"
      ],
      "metadata": {
        "id": "D6D6Z7QCb_ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка описания психологических векторов.**"
      ],
      "metadata": {
        "id": "zWesr9__cHVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "person_vectors = (\"brown\", \"black\", \"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\")"
      ],
      "metadata": {
        "id": "nejPs-qPcKek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = dict(zip(person_vectors, [vectorId for vectorId in range(len(person_vectors))]))\n",
        "print(label_map)\n",
        "id2label = dict(zip([vectorId for vectorId in range(len(person_vectors))], person_vectors))\n",
        "print(id2label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1S9fSpmhaSm",
        "outputId": "edcb7c41-a4b6-4e82-a98d-618a61b47344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'brown': 0, 'black': 1, 'red': 2, 'orange': 3, 'yellow': 4, 'green': 5, 'blue': 6, 'purple': 7}\n",
            "{0: 'brown', 1: 'black', 2: 'red', 3: 'orange', 4: 'yellow', 5: 'green', 6: 'blue', 7: 'purple'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = []; train_labels = []\n",
        "\n",
        "# Загружаем описание личности человека для каждого вектора из книги В.К. Толкачева\n",
        "for person_vector in person_vectors:\n",
        "    with open(\"drive/MyDrive/vectors/\" + person_vector + \".txt\", encoding=\"utf8\") as rf:\n",
        "        for text in rf.readlines():\n",
        "            for sentence in split_text(text):\n",
        "              if len(sentence) <= 5: continue\n",
        "              train_text.append(sentence.strip())\n",
        "              train_labels.append(person_vectors.index(person_vector))\n",
        "\n",
        "# Загружаем описание личности человека для каждого вектора из книги М.В. Бородянского\n",
        "for person_vector in person_vectors:\n",
        "    with open(\"drive/MyDrive/vectors_/\" + person_vector + \".txt\", encoding=\"utf8\") as rf:\n",
        "        for text in rf.readlines():\n",
        "            for sentence in split_text(text):\n",
        "              if len(sentence) <= 5: continue\n",
        "              train_text.append(sentence.strip())\n",
        "              train_labels.append(person_vectors.index(person_vector))\n",
        "\n",
        "train_text = np.array(train_text)\n",
        "train_labels = np.array(train_labels)"
      ],
      "metadata": {
        "id": "TWmmomZOcDb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxhyLe4uj2Mx",
        "outputId": "1c3721f2-3672-46b1-9321-e60954a2e000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Люди, которых я хотел бы описать, выделяются тем, что в их характере обнаруживается, как правило, присутствие следующих трех черт: они аккуратны, бережливы и упрямы',\n",
              "       'От себя добавим, что есть в этом характере и четвертая обязательная черта — склонность к садизму, в том числе и в его скрытых, латентных формах',\n",
              "       'Аккуратность обозначает здесь не только физическую чистоплотность, но также и добросовестность в исполнении иного рода мелких обязательств: на людей аккуратных в этом смысле можно положиться',\n",
              "       'Эти люди обладают морально нравственной чистоплотностью, иногда просто патологически честны',\n",
              "       'Такой ребенок может ответить по телефону: Мама сказала, что ее нет дома',\n",
              "       'Он — классический флегматик (носитель флегматического темперамента), он способен спокойно и рассудительно продумать расходование каждого рубля',\n",
              "       'При покупке товара в магазине ведет себя крайне нерешительно и выбирает долго, перетрогает и перепробует весь то вар, при этом будет спрашивать совет у продавца и других покупателей',\n",
              "       'Он — человек нерешительный, нуждается в советах и ищет советчиков',\n",
              "       'Помогите ему советами в начале дела',\n",
              "       'По нашему мнению его гнев и мстительность — это не гнев и мстительность в чистом виде, а проявления бытового садизма в скрытых формах'],\n",
              "      dtype='<U635')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_text = []; val_labels = []\n",
        "\n",
        "# Загружаем описание личности человека для каждого вектора из книги В.К. Толкачева\n",
        "for person_vector in person_vectors:\n",
        "    rf = None\n",
        "    if person_vector == 'brown':\n",
        "        rf = open(\"drive/MyDrive/val/Чарлз Дарвин.txt\", encoding=\"utf8\")\n",
        "    elif person_vector == 'green':\n",
        "        rf = open(\"drive/MyDrive/val/Дюймовочка.txt\", encoding=\"utf8\")\n",
        "    else:\n",
        "        rf = open(\"drive/MyDrive/vectors/\" + person_vector + \".txt\", encoding=\"utf8\")\n",
        "\n",
        "    '''elif person_vector == 'black':\n",
        "        rf = open(\"drive/MyDrive/vectors/\" + person_vector + \".txt\", encoding=\"utf8\")\n",
        "    elif person_vector == 'red':\n",
        "        rf = open(\"drive/MyDrive/val/Валерий Харламов. Легенда №17.txt\", encoding=\"utf8\")\n",
        "    elif person_vector == 'orange':\n",
        "        rf = open(\"drive/MyDrive/vectors/\" + person_vector + \".txt\", encoding=\"utf8\")\n",
        "    elif person_vector == 'yellow':\n",
        "        rf = open(\"drive/MyDrive/vectors/\" + person_vector + \".txt\", encoding=\"utf8\")\n",
        "    elif person_vector == 'green':\n",
        "        rf = open(\"drive/MyDrive/val/Дюймовочка.txt\", encoding=\"utf8\")\n",
        "    elif person_vector == 'blue':\n",
        "        rf = open(\"drive/MyDrive/vectors/\" + person_vector + \".txt\", encoding=\"utf8\")\n",
        "    elif person_vector == 'purple':\n",
        "        rf = open(\"drive/MyDrive/val/Парфюмер.txt\", encoding=\"utf8\")'''\n",
        "\n",
        "    for text in rf.readlines():\n",
        "        for sentence in split_text(text):\n",
        "            if len(sentence) <= 5: continue\n",
        "            val_text.append(sentence.strip())\n",
        "            val_labels.append(person_vectors.index(person_vector))\n",
        "\n",
        "    rf.close()\n",
        "\n",
        "val_text = np.array(val_text)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "_, val_text, _, val_labels = train_test_split(val_text, val_labels, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "ROaglS0jhXmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxPuKPSsmWcY",
        "outputId": "28269c35-d9b8-4983-d8c5-d3ed264bd92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RWE1dcQ8ZscG"
      },
      "cell_type": "code",
      "source": [
        "#train_text, val_text, train_labels, val_labels = train_test_split(df_vectors['description'], df_vectors['vectorId'],\n",
        "#                                                                    random_state=2018,\n",
        "#                                                                    test_size=0.2,\n",
        "#                                                                   stratify=df_vectors['vectorId'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "372d9be4c4744d20a17c1e868c892806",
            "0ecc8efebe8b4b58943809fbf3dd3cab",
            "bb8b4ef442f94599b9c94b24fdca62d2",
            "07603cab14504a3f81864e435e9ce418",
            "21b701c4bac1456388e7dd83089b54ef",
            "635328ca174b43b3b4631be37df7d904",
            "be8a2d71376748969241e7fc71d2aac2",
            "2f12650930094915ab1a55b475959dc2",
            "bf28a06466b345959205985ed00ba6e0",
            "3c36079dd862418882a601674a1cb42b",
            "e101fd731d4c4f539b049c51493eb483",
            "d09d351272984df8b777859668183285",
            "857712483b82468a8449d61f055575bf",
            "0855645d612c4bee8446e610b8c3057f",
            "38bae10048834677b6b746408d500da3",
            "0d7bc181c7d94659bacfa80e622000af",
            "d773e4a8f79943639379f1c2f4997215",
            "77dd419320e7434ea5681ac1fc509937",
            "3404968f53234d7ca4987b70a7e11145",
            "161d5a54142749f6a5334847cd9ffd47",
            "13b4d83f20d04382bc120c71dc38a0ae",
            "1f38823bbe574f85bf7aecf5bdf5cf9e",
            "0434c1fd0cdf4782acab845087f3e0f1",
            "e6b430d60e744b3fa7c707057e4fea0b",
            "52933f8588ec49938aa85bf06e5bc353",
            "9bbb52473d054ddca374acfc02b8779f",
            "a5e63b8c10a841678d1e1789b1fb1546",
            "538ae6aa7a6845c5ae10bb4f5ca4989c",
            "942ce88c4e654f0580d91b9b65e6c41f",
            "bc509a2702914fa9967ea77c5658aaa9",
            "31f8935195fd4b098b35d901b2fd1451",
            "69b71b4faacf46e191e8263af3414e3b",
            "745068b568904dba86748801e41e07fc"
          ]
        },
        "id": "6C6JhRwdZscG",
        "outputId": "4bda6d35-a07b-4bb4-b341-30e2f2e1e927"
      },
      "cell_type": "code",
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"sberbank-ai/ruBert-base\")\n",
        "bert = BertModel.from_pretrained(\"sberbank-ai/ruBert-base\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "372d9be4c4744d20a17c1e868c892806"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/590 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d09d351272984df8b777859668183285"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/716M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0434c1fd0cdf4782acab845087f3e0f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at sberbank-ai/ruBert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "yILCzqK0ZscH",
        "outputId": "7a4b65ae-d714-4ad1-972a-eb855ad4cdba"
      },
      "cell_type": "code",
      "source": [
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)\n",
        "max_seq_len = max(seq_len)\n",
        "print(max_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pcgvy8wEZscI"
      },
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "if max_seq_len>512:\n",
        "    max_seq_len = 512\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfqOwHiEZscI",
        "outputId": "f9042980-8f6c-4fba-8845-0408848c57c1"
      },
      "cell_type": "code",
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "print(\"train_y:\",train_y)\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "print(\"val_y:\",val_y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_y: tensor([0, 0, 0,  ..., 7, 7, 7])\n",
            "val_y: tensor([5, 0, 7,  ..., 0, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "R628lET0ZscJ"
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 16\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Ae32U8K6ZscJ"
      },
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "VOYdFmb5ZscK"
      },
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert, num_classes):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        self.bert = bert\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # relu activation function\n",
        "        self.relu =  nn.ReLU()\n",
        "\n",
        "        # dense layer 1\n",
        "        self.fc1 = nn.Linear(768, 512)\n",
        "\n",
        "        # dense layer 2 (Output layer)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "        #softmax activation function\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "        #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "        #pass the inputs to the model\n",
        "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "\n",
        "        x = self.fc1(cls_hs)\n",
        "\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # output layer\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # apply softmax activation\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Lm02pGy6ZscK"
      },
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert, len(person_vectors))\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "r6o4tHfKZscK"
      },
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "WMgjhIwmZscK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1656e8-d9a0-485b-a5e9-8725b516d8d6"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.72971698 0.94482899 1.00891304 0.6898038  1.46867089 1.31547619\n",
            " 1.4576005  0.99677835]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "iHmtEjhUZscL"
      },
      "cell_type": "code",
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "F7cf-cFrZscL"
      },
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "    total_labels =[]\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "        # append the model predictions\n",
        "        total_preds+=list(preds)\n",
        "        total_labels+=labels.tolist()\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
        "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hpwv7x0gZscL"
      },
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "    total_labels = []\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "\n",
        "          # Calculate elapsed time in minutes.\n",
        "          #elapsed = format_time(time.time() - t0)\n",
        "\n",
        "          # Report progress.\n",
        "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            preds = model(sent_id, mask)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            preds = np.argmax(preds, axis=1)\n",
        "            total_preds+=list(preds)\n",
        "            total_labels+=labels.tolist()\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
        "    return avg_loss, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "cUK72dHnZscL"
      },
      "cell_type": "code",
      "source": [
        "def save_checkpoint(filename, epoch, model, optimizer, label_map, id2label):\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'model': model,\n",
        "        'optimizer': optimizer,\n",
        "        'label_map': label_map,\n",
        "        'id_map':id2label}\n",
        "    torch.save(state, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IYaQ0CKeZscM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e01522-8630-48d8-cfef-efd522303bbd"
      },
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_train_loss = float('inf')\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, f1_train = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, f1_valid = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if train_loss < best_train_loss:\n",
        "        best_train_loss = train_loss\n",
        "        file_name = 'drive/MyDrive/BERT/model_weights.pt'\n",
        "        save_checkpoint(file_name, epoch, model, optimizer, label_map, id2label)\n",
        "\n",
        "    if valid_loss < best_val_loss:\n",
        "        best_val_loss = valid_loss\n",
        "        file_name = 'drive/MyDrive/BERT/model_weights_val.pt'\n",
        "        save_checkpoint(file_name, epoch, model, optimizer, label_map, id2label)\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "    print(f'\\nTraining F1: {f1_train:.3f}')\n",
        "    print(f'Validation F1: {f1_valid:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.605\n",
            "Validation Loss: 1.507\n",
            "\n",
            "Training F1: 0.407\n",
            "Validation F1: 0.516\n",
            "\n",
            " Epoch 17 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.591\n",
            "Validation Loss: 1.499\n",
            "\n",
            "Training F1: 0.411\n",
            "Validation F1: 0.510\n",
            "\n",
            " Epoch 18 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.553\n",
            "Validation Loss: 1.485\n",
            "\n",
            "Training F1: 0.425\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 19 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.546\n",
            "Validation Loss: 1.411\n",
            "\n",
            "Training F1: 0.431\n",
            "Validation F1: 0.549\n",
            "\n",
            " Epoch 20 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.528\n",
            "Validation Loss: 1.477\n",
            "\n",
            "Training F1: 0.429\n",
            "Validation F1: 0.546\n",
            "\n",
            " Epoch 21 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.518\n",
            "Validation Loss: 1.394\n",
            "\n",
            "Training F1: 0.439\n",
            "Validation F1: 0.550\n",
            "\n",
            " Epoch 22 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.502\n",
            "Validation Loss: 1.462\n",
            "\n",
            "Training F1: 0.441\n",
            "Validation F1: 0.530\n",
            "\n",
            " Epoch 23 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.499\n",
            "Validation Loss: 1.563\n",
            "\n",
            "Training F1: 0.451\n",
            "Validation F1: 0.487\n",
            "\n",
            " Epoch 24 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.490\n",
            "Validation Loss: 1.468\n",
            "\n",
            "Training F1: 0.451\n",
            "Validation F1: 0.523\n",
            "\n",
            " Epoch 25 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.455\n",
            "Validation Loss: 1.759\n",
            "\n",
            "Training F1: 0.453\n",
            "Validation F1: 0.363\n",
            "\n",
            " Epoch 26 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.438\n",
            "Validation Loss: 1.410\n",
            "\n",
            "Training F1: 0.460\n",
            "Validation F1: 0.526\n",
            "\n",
            " Epoch 27 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.449\n",
            "Validation Loss: 1.576\n",
            "\n",
            "Training F1: 0.461\n",
            "Validation F1: 0.487\n",
            "\n",
            " Epoch 28 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.426\n",
            "Validation Loss: 1.568\n",
            "\n",
            "Training F1: 0.466\n",
            "Validation F1: 0.463\n",
            "\n",
            " Epoch 29 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.412\n",
            "Validation Loss: 1.444\n",
            "\n",
            "Training F1: 0.475\n",
            "Validation F1: 0.554\n",
            "\n",
            " Epoch 30 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.416\n",
            "Validation Loss: 1.572\n",
            "\n",
            "Training F1: 0.472\n",
            "Validation F1: 0.507\n",
            "\n",
            " Epoch 31 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.394\n",
            "Validation Loss: 1.481\n",
            "\n",
            "Training F1: 0.476\n",
            "Validation F1: 0.531\n",
            "\n",
            " Epoch 32 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.362\n",
            "Validation Loss: 1.439\n",
            "\n",
            "Training F1: 0.494\n",
            "Validation F1: 0.561\n",
            "\n",
            " Epoch 33 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.363\n",
            "Validation Loss: 1.576\n",
            "\n",
            "Training F1: 0.498\n",
            "Validation F1: 0.506\n",
            "\n",
            " Epoch 34 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.365\n",
            "Validation Loss: 1.379\n",
            "\n",
            "Training F1: 0.488\n",
            "Validation F1: 0.563\n",
            "\n",
            " Epoch 35 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.361\n",
            "Validation Loss: 1.488\n",
            "\n",
            "Training F1: 0.492\n",
            "Validation F1: 0.504\n",
            "\n",
            " Epoch 36 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.347\n",
            "Validation Loss: 1.478\n",
            "\n",
            "Training F1: 0.499\n",
            "Validation F1: 0.534\n",
            "\n",
            " Epoch 37 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.337\n",
            "Validation Loss: 1.585\n",
            "\n",
            "Training F1: 0.505\n",
            "Validation F1: 0.474\n",
            "\n",
            " Epoch 38 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.340\n",
            "Validation Loss: 1.424\n",
            "\n",
            "Training F1: 0.508\n",
            "Validation F1: 0.549\n",
            "\n",
            " Epoch 39 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.341\n",
            "Validation Loss: 1.459\n",
            "\n",
            "Training F1: 0.505\n",
            "Validation F1: 0.541\n",
            "\n",
            " Epoch 40 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.298\n",
            "Validation Loss: 1.524\n",
            "\n",
            "Training F1: 0.529\n",
            "Validation F1: 0.490\n",
            "\n",
            " Epoch 41 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.305\n",
            "Validation Loss: 1.397\n",
            "\n",
            "Training F1: 0.513\n",
            "Validation F1: 0.531\n",
            "\n",
            " Epoch 42 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.282\n",
            "Validation Loss: 1.529\n",
            "\n",
            "Training F1: 0.524\n",
            "Validation F1: 0.517\n",
            "\n",
            " Epoch 43 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.276\n",
            "Validation Loss: 1.515\n",
            "\n",
            "Training F1: 0.528\n",
            "Validation F1: 0.540\n",
            "\n",
            " Epoch 44 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.289\n",
            "Validation Loss: 1.393\n",
            "\n",
            "Training F1: 0.531\n",
            "Validation F1: 0.562\n",
            "\n",
            " Epoch 45 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.276\n",
            "Validation Loss: 1.547\n",
            "\n",
            "Training F1: 0.528\n",
            "Validation F1: 0.545\n",
            "\n",
            " Epoch 46 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.274\n",
            "Validation Loss: 1.540\n",
            "\n",
            "Training F1: 0.523\n",
            "Validation F1: 0.531\n",
            "\n",
            " Epoch 47 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.244\n",
            "Validation Loss: 1.446\n",
            "\n",
            "Training F1: 0.530\n",
            "Validation F1: 0.546\n",
            "\n",
            " Epoch 48 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.233\n",
            "Validation Loss: 1.477\n",
            "\n",
            "Training F1: 0.535\n",
            "Validation F1: 0.545\n",
            "\n",
            " Epoch 49 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.240\n",
            "Validation Loss: 1.302\n",
            "\n",
            "Training F1: 0.546\n",
            "Validation F1: 0.599\n",
            "\n",
            " Epoch 50 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.222\n",
            "Validation Loss: 1.556\n",
            "\n",
            "Training F1: 0.547\n",
            "Validation F1: 0.506\n",
            "\n",
            " Epoch 51 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.213\n",
            "Validation Loss: 1.388\n",
            "\n",
            "Training F1: 0.540\n",
            "Validation F1: 0.576\n",
            "\n",
            " Epoch 52 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.188\n",
            "Validation Loss: 1.393\n",
            "\n",
            "Training F1: 0.546\n",
            "Validation F1: 0.571\n",
            "\n",
            " Epoch 53 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.209\n",
            "Validation Loss: 1.586\n",
            "\n",
            "Training F1: 0.556\n",
            "Validation F1: 0.517\n",
            "\n",
            " Epoch 54 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.200\n",
            "Validation Loss: 1.484\n",
            "\n",
            "Training F1: 0.555\n",
            "Validation F1: 0.545\n",
            "\n",
            " Epoch 55 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.169\n",
            "Validation Loss: 1.384\n",
            "\n",
            "Training F1: 0.563\n",
            "Validation F1: 0.607\n",
            "\n",
            " Epoch 56 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.175\n",
            "Validation Loss: 1.449\n",
            "\n",
            "Training F1: 0.554\n",
            "Validation F1: 0.555\n",
            "\n",
            " Epoch 57 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.182\n",
            "Validation Loss: 1.448\n",
            "\n",
            "Training F1: 0.554\n",
            "Validation F1: 0.601\n",
            "\n",
            " Epoch 58 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.165\n",
            "Validation Loss: 1.485\n",
            "\n",
            "Training F1: 0.570\n",
            "Validation F1: 0.554\n",
            "\n",
            " Epoch 59 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.151\n",
            "Validation Loss: 1.540\n",
            "\n",
            "Training F1: 0.577\n",
            "Validation F1: 0.573\n",
            "\n",
            " Epoch 60 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.166\n",
            "Validation Loss: 1.429\n",
            "\n",
            "Training F1: 0.576\n",
            "Validation F1: 0.579\n",
            "\n",
            " Epoch 61 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.163\n",
            "Validation Loss: 1.429\n",
            "\n",
            "Training F1: 0.564\n",
            "Validation F1: 0.556\n",
            "\n",
            " Epoch 62 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.160\n",
            "Validation Loss: 1.583\n",
            "\n",
            "Training F1: 0.571\n",
            "Validation F1: 0.537\n",
            "\n",
            " Epoch 63 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.143\n",
            "Validation Loss: 1.557\n",
            "\n",
            "Training F1: 0.577\n",
            "Validation F1: 0.537\n",
            "\n",
            " Epoch 64 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.123\n",
            "Validation Loss: 1.477\n",
            "\n",
            "Training F1: 0.581\n",
            "Validation F1: 0.579\n",
            "\n",
            " Epoch 65 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.140\n",
            "Validation Loss: 1.596\n",
            "\n",
            "Training F1: 0.580\n",
            "Validation F1: 0.568\n",
            "\n",
            " Epoch 66 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.126\n",
            "Validation Loss: 1.422\n",
            "\n",
            "Training F1: 0.587\n",
            "Validation F1: 0.567\n",
            "\n",
            " Epoch 67 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.102\n",
            "Validation Loss: 1.586\n",
            "\n",
            "Training F1: 0.585\n",
            "Validation F1: 0.523\n",
            "\n",
            " Epoch 68 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.105\n",
            "Validation Loss: 1.539\n",
            "\n",
            "Training F1: 0.580\n",
            "Validation F1: 0.586\n",
            "\n",
            " Epoch 69 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.118\n",
            "Validation Loss: 1.603\n",
            "\n",
            "Training F1: 0.583\n",
            "Validation F1: 0.547\n",
            "\n",
            " Epoch 70 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.102\n",
            "Validation Loss: 1.505\n",
            "\n",
            "Training F1: 0.593\n",
            "Validation F1: 0.531\n",
            "\n",
            " Epoch 71 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.082\n",
            "Validation Loss: 1.542\n",
            "\n",
            "Training F1: 0.595\n",
            "Validation F1: 0.551\n",
            "\n",
            " Epoch 72 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.082\n",
            "Validation Loss: 1.473\n",
            "\n",
            "Training F1: 0.598\n",
            "Validation F1: 0.573\n",
            "\n",
            " Epoch 73 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.081\n",
            "Validation Loss: 1.479\n",
            "\n",
            "Training F1: 0.591\n",
            "Validation F1: 0.559\n",
            "\n",
            " Epoch 74 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.068\n",
            "Validation Loss: 1.355\n",
            "\n",
            "Training F1: 0.602\n",
            "Validation F1: 0.616\n",
            "\n",
            " Epoch 75 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.078\n",
            "Validation Loss: 1.426\n",
            "\n",
            "Training F1: 0.597\n",
            "Validation F1: 0.585\n",
            "\n",
            " Epoch 76 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.077\n",
            "Validation Loss: 1.601\n",
            "\n",
            "Training F1: 0.601\n",
            "Validation F1: 0.486\n",
            "\n",
            " Epoch 77 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.068\n",
            "Validation Loss: 1.498\n",
            "\n",
            "Training F1: 0.600\n",
            "Validation F1: 0.578\n",
            "\n",
            " Epoch 78 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.053\n",
            "Validation Loss: 1.493\n",
            "\n",
            "Training F1: 0.602\n",
            "Validation F1: 0.596\n",
            "\n",
            " Epoch 79 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.043\n",
            "Validation Loss: 1.351\n",
            "\n",
            "Training F1: 0.615\n",
            "Validation F1: 0.621\n",
            "\n",
            " Epoch 80 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.051\n",
            "Validation Loss: 1.452\n",
            "\n",
            "Training F1: 0.604\n",
            "Validation F1: 0.578\n",
            "\n",
            " Epoch 81 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.053\n",
            "Validation Loss: 1.385\n",
            "\n",
            "Training F1: 0.602\n",
            "Validation F1: 0.627\n",
            "\n",
            " Epoch 82 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.037\n",
            "Validation Loss: 1.576\n",
            "\n",
            "Training F1: 0.613\n",
            "Validation F1: 0.534\n",
            "\n",
            " Epoch 83 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.030\n",
            "Validation Loss: 1.438\n",
            "\n",
            "Training F1: 0.614\n",
            "Validation F1: 0.638\n",
            "\n",
            " Epoch 84 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.051\n",
            "Validation Loss: 1.553\n",
            "\n",
            "Training F1: 0.606\n",
            "Validation F1: 0.607\n",
            "\n",
            " Epoch 85 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.044\n",
            "Validation Loss: 1.426\n",
            "\n",
            "Training F1: 0.619\n",
            "Validation F1: 0.591\n",
            "\n",
            " Epoch 86 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.018\n",
            "Validation Loss: 1.536\n",
            "\n",
            "Training F1: 0.616\n",
            "Validation F1: 0.557\n",
            "\n",
            " Epoch 87 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.014\n",
            "Validation Loss: 1.464\n",
            "\n",
            "Training F1: 0.624\n",
            "Validation F1: 0.591\n",
            "\n",
            " Epoch 88 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.042\n",
            "Validation Loss: 1.436\n",
            "\n",
            "Training F1: 0.613\n",
            "Validation F1: 0.610\n",
            "\n",
            " Epoch 89 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.003\n",
            "Validation Loss: 1.552\n",
            "\n",
            "Training F1: 0.635\n",
            "Validation F1: 0.554\n",
            "\n",
            " Epoch 90 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.016\n",
            "Validation Loss: 1.428\n",
            "\n",
            "Training F1: 0.621\n",
            "Validation F1: 0.627\n",
            "\n",
            " Epoch 91 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.011\n",
            "Validation Loss: 1.480\n",
            "\n",
            "Training F1: 0.624\n",
            "Validation F1: 0.602\n",
            "\n",
            " Epoch 92 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.994\n",
            "Validation Loss: 1.626\n",
            "\n",
            "Training F1: 0.633\n",
            "Validation F1: 0.502\n",
            "\n",
            " Epoch 93 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.973\n",
            "Validation Loss: 1.222\n",
            "\n",
            "Training F1: 0.632\n",
            "Validation F1: 0.674\n",
            "\n",
            " Epoch 94 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 1.008\n",
            "Validation Loss: 1.391\n",
            "\n",
            "Training F1: 0.625\n",
            "Validation F1: 0.597\n",
            "\n",
            " Epoch 95 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.977\n",
            "Validation Loss: 1.369\n",
            "\n",
            "Training F1: 0.631\n",
            "Validation F1: 0.633\n",
            "\n",
            " Epoch 96 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.997\n",
            "Validation Loss: 1.450\n",
            "\n",
            "Training F1: 0.637\n",
            "Validation F1: 0.602\n",
            "\n",
            " Epoch 97 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.981\n",
            "Validation Loss: 1.520\n",
            "\n",
            "Training F1: 0.626\n",
            "Validation F1: 0.541\n",
            "\n",
            " Epoch 98 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.996\n",
            "Validation Loss: 1.366\n",
            "\n",
            "Training F1: 0.632\n",
            "Validation F1: 0.615\n",
            "\n",
            " Epoch 99 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.976\n",
            "Validation Loss: 1.375\n",
            "\n",
            "Training F1: 0.629\n",
            "Validation F1: 0.596\n",
            "\n",
            " Epoch 100 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.945\n",
            "Validation Loss: 1.428\n",
            "\n",
            "Training F1: 0.643\n",
            "Validation F1: 0.628\n",
            "\n",
            " Epoch 101 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.973\n",
            "Validation Loss: 1.401\n",
            "\n",
            "Training F1: 0.629\n",
            "Validation F1: 0.583\n",
            "\n",
            " Epoch 102 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.963\n",
            "Validation Loss: 1.537\n",
            "\n",
            "Training F1: 0.642\n",
            "Validation F1: 0.598\n",
            "\n",
            " Epoch 103 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.968\n",
            "Validation Loss: 1.351\n",
            "\n",
            "Training F1: 0.650\n",
            "Validation F1: 0.622\n",
            "\n",
            " Epoch 104 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.968\n",
            "Validation Loss: 1.403\n",
            "\n",
            "Training F1: 0.647\n",
            "Validation F1: 0.616\n",
            "\n",
            " Epoch 105 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.945\n",
            "Validation Loss: 1.409\n",
            "\n",
            "Training F1: 0.648\n",
            "Validation F1: 0.625\n",
            "\n",
            " Epoch 106 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.953\n",
            "Validation Loss: 1.416\n",
            "\n",
            "Training F1: 0.642\n",
            "Validation F1: 0.607\n",
            "\n",
            " Epoch 107 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.987\n",
            "Validation Loss: 1.466\n",
            "\n",
            "Training F1: 0.634\n",
            "Validation F1: 0.605\n",
            "\n",
            " Epoch 108 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.956\n",
            "Validation Loss: 1.414\n",
            "\n",
            "Training F1: 0.649\n",
            "Validation F1: 0.583\n",
            "\n",
            " Epoch 109 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.939\n",
            "Validation Loss: 1.356\n",
            "\n",
            "Training F1: 0.647\n",
            "Validation F1: 0.620\n",
            "\n",
            " Epoch 110 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.949\n",
            "Validation Loss: 1.375\n",
            "\n",
            "Training F1: 0.640\n",
            "Validation F1: 0.623\n",
            "\n",
            " Epoch 111 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.920\n",
            "Validation Loss: 1.386\n",
            "\n",
            "Training F1: 0.652\n",
            "Validation F1: 0.640\n",
            "\n",
            " Epoch 112 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.958\n",
            "Validation Loss: 1.508\n",
            "\n",
            "Training F1: 0.646\n",
            "Validation F1: 0.597\n",
            "\n",
            " Epoch 113 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.926\n",
            "Validation Loss: 1.388\n",
            "\n",
            "Training F1: 0.659\n",
            "Validation F1: 0.650\n",
            "\n",
            " Epoch 114 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.927\n",
            "Validation Loss: 1.567\n",
            "\n",
            "Training F1: 0.659\n",
            "Validation F1: 0.573\n",
            "\n",
            " Epoch 115 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.929\n",
            "Validation Loss: 1.459\n",
            "\n",
            "Training F1: 0.647\n",
            "Validation F1: 0.614\n",
            "\n",
            " Epoch 116 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.925\n",
            "Validation Loss: 1.562\n",
            "\n",
            "Training F1: 0.655\n",
            "Validation F1: 0.569\n",
            "\n",
            " Epoch 117 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.935\n",
            "Validation Loss: 1.530\n",
            "\n",
            "Training F1: 0.658\n",
            "Validation F1: 0.571\n",
            "\n",
            " Epoch 118 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.929\n",
            "Validation Loss: 1.632\n",
            "\n",
            "Training F1: 0.656\n",
            "Validation F1: 0.623\n",
            "\n",
            " Epoch 119 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.928\n",
            "Validation Loss: 1.452\n",
            "\n",
            "Training F1: 0.662\n",
            "Validation F1: 0.611\n",
            "\n",
            " Epoch 120 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.899\n",
            "Validation Loss: 1.362\n",
            "\n",
            "Training F1: 0.667\n",
            "Validation F1: 0.622\n",
            "\n",
            " Epoch 121 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.898\n",
            "Validation Loss: 1.384\n",
            "\n",
            "Training F1: 0.663\n",
            "Validation F1: 0.627\n",
            "\n",
            " Epoch 122 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.918\n",
            "Validation Loss: 1.628\n",
            "\n",
            "Training F1: 0.663\n",
            "Validation F1: 0.562\n",
            "\n",
            " Epoch 123 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.898\n",
            "Validation Loss: 1.392\n",
            "\n",
            "Training F1: 0.667\n",
            "Validation F1: 0.627\n",
            "\n",
            " Epoch 124 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.888\n",
            "Validation Loss: 1.518\n",
            "\n",
            "Training F1: 0.674\n",
            "Validation F1: 0.609\n",
            "\n",
            " Epoch 125 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.886\n",
            "Validation Loss: 1.560\n",
            "\n",
            "Training F1: 0.669\n",
            "Validation F1: 0.628\n",
            "\n",
            " Epoch 126 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.901\n",
            "Validation Loss: 1.574\n",
            "\n",
            "Training F1: 0.661\n",
            "Validation F1: 0.598\n",
            "\n",
            " Epoch 127 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.887\n",
            "Validation Loss: 1.460\n",
            "\n",
            "Training F1: 0.663\n",
            "Validation F1: 0.623\n",
            "\n",
            " Epoch 128 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.905\n",
            "Validation Loss: 1.522\n",
            "\n",
            "Training F1: 0.661\n",
            "Validation F1: 0.636\n",
            "\n",
            " Epoch 129 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.896\n",
            "Validation Loss: 1.502\n",
            "\n",
            "Training F1: 0.670\n",
            "Validation F1: 0.611\n",
            "\n",
            " Epoch 130 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.882\n",
            "Validation Loss: 1.434\n",
            "\n",
            "Training F1: 0.672\n",
            "Validation F1: 0.606\n",
            "\n",
            " Epoch 131 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.844\n",
            "Validation Loss: 1.536\n",
            "\n",
            "Training F1: 0.683\n",
            "Validation F1: 0.610\n",
            "\n",
            " Epoch 132 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.887\n",
            "Validation Loss: 1.488\n",
            "\n",
            "Training F1: 0.674\n",
            "Validation F1: 0.610\n",
            "\n",
            " Epoch 133 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.865\n",
            "Validation Loss: 1.533\n",
            "\n",
            "Training F1: 0.685\n",
            "Validation F1: 0.587\n",
            "\n",
            " Epoch 134 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.901\n",
            "Validation Loss: 1.417\n",
            "\n",
            "Training F1: 0.671\n",
            "Validation F1: 0.626\n",
            "\n",
            " Epoch 135 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.879\n",
            "Validation Loss: 1.433\n",
            "\n",
            "Training F1: 0.677\n",
            "Validation F1: 0.634\n",
            "\n",
            " Epoch 136 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.887\n",
            "Validation Loss: 1.474\n",
            "\n",
            "Training F1: 0.674\n",
            "Validation F1: 0.594\n",
            "\n",
            " Epoch 137 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.850\n",
            "Validation Loss: 1.523\n",
            "\n",
            "Training F1: 0.680\n",
            "Validation F1: 0.645\n",
            "\n",
            " Epoch 138 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.867\n",
            "Validation Loss: 1.622\n",
            "\n",
            "Training F1: 0.679\n",
            "Validation F1: 0.595\n",
            "\n",
            " Epoch 139 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.879\n",
            "Validation Loss: 1.425\n",
            "\n",
            "Training F1: 0.672\n",
            "Validation F1: 0.656\n",
            "\n",
            " Epoch 140 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.859\n",
            "Validation Loss: 1.486\n",
            "\n",
            "Training F1: 0.682\n",
            "Validation F1: 0.640\n",
            "\n",
            " Epoch 141 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.866\n",
            "Validation Loss: 1.580\n",
            "\n",
            "Training F1: 0.681\n",
            "Validation F1: 0.582\n",
            "\n",
            " Epoch 142 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.869\n",
            "Validation Loss: 1.358\n",
            "\n",
            "Training F1: 0.688\n",
            "Validation F1: 0.676\n",
            "\n",
            " Epoch 143 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.838\n",
            "Validation Loss: 1.654\n",
            "\n",
            "Training F1: 0.679\n",
            "Validation F1: 0.605\n",
            "\n",
            " Epoch 144 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.844\n",
            "Validation Loss: 1.561\n",
            "\n",
            "Training F1: 0.678\n",
            "Validation F1: 0.603\n",
            "\n",
            " Epoch 145 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.853\n",
            "Validation Loss: 1.426\n",
            "\n",
            "Training F1: 0.680\n",
            "Validation F1: 0.645\n",
            "\n",
            " Epoch 146 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.834\n",
            "Validation Loss: 1.493\n",
            "\n",
            "Training F1: 0.689\n",
            "Validation F1: 0.672\n",
            "\n",
            " Epoch 147 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.853\n",
            "Validation Loss: 1.464\n",
            "\n",
            "Training F1: 0.681\n",
            "Validation F1: 0.632\n",
            "\n",
            " Epoch 148 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.846\n",
            "Validation Loss: 1.507\n",
            "\n",
            "Training F1: 0.683\n",
            "Validation F1: 0.628\n",
            "\n",
            " Epoch 149 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.856\n",
            "Validation Loss: 1.693\n",
            "\n",
            "Training F1: 0.681\n",
            "Validation F1: 0.599\n",
            "\n",
            " Epoch 150 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.861\n",
            "Validation Loss: 1.420\n",
            "\n",
            "Training F1: 0.683\n",
            "Validation F1: 0.647\n",
            "\n",
            " Epoch 151 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.827\n",
            "Validation Loss: 1.385\n",
            "\n",
            "Training F1: 0.683\n",
            "Validation F1: 0.652\n",
            "\n",
            " Epoch 152 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.836\n",
            "Validation Loss: 1.373\n",
            "\n",
            "Training F1: 0.689\n",
            "Validation F1: 0.632\n",
            "\n",
            " Epoch 153 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.835\n",
            "Validation Loss: 1.403\n",
            "\n",
            "Training F1: 0.689\n",
            "Validation F1: 0.641\n",
            "\n",
            " Epoch 154 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.818\n",
            "Validation Loss: 1.572\n",
            "\n",
            "Training F1: 0.696\n",
            "Validation F1: 0.593\n",
            "\n",
            " Epoch 155 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.831\n",
            "Validation Loss: 1.370\n",
            "\n",
            "Training F1: 0.685\n",
            "Validation F1: 0.623\n",
            "\n",
            " Epoch 156 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.833\n",
            "Validation Loss: 1.456\n",
            "\n",
            "Training F1: 0.692\n",
            "Validation F1: 0.640\n",
            "\n",
            " Epoch 157 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.839\n",
            "Validation Loss: 1.626\n",
            "\n",
            "Training F1: 0.686\n",
            "Validation F1: 0.626\n",
            "\n",
            " Epoch 158 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.817\n",
            "Validation Loss: 1.435\n",
            "\n",
            "Training F1: 0.697\n",
            "Validation F1: 0.637\n",
            "\n",
            " Epoch 159 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.852\n",
            "Validation Loss: 1.593\n",
            "\n",
            "Training F1: 0.686\n",
            "Validation F1: 0.586\n",
            "\n",
            " Epoch 160 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.812\n",
            "Validation Loss: 1.567\n",
            "\n",
            "Training F1: 0.701\n",
            "Validation F1: 0.633\n",
            "\n",
            " Epoch 161 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.874\n",
            "Validation Loss: 1.509\n",
            "\n",
            "Training F1: 0.681\n",
            "Validation F1: 0.626\n",
            "\n",
            " Epoch 162 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.823\n",
            "Validation Loss: 1.478\n",
            "\n",
            "Training F1: 0.695\n",
            "Validation F1: 0.657\n",
            "\n",
            " Epoch 163 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.823\n",
            "Validation Loss: 1.381\n",
            "\n",
            "Training F1: 0.691\n",
            "Validation F1: 0.670\n",
            "\n",
            " Epoch 164 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.813\n",
            "Validation Loss: 1.479\n",
            "\n",
            "Training F1: 0.701\n",
            "Validation F1: 0.650\n",
            "\n",
            " Epoch 165 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.812\n",
            "Validation Loss: 1.496\n",
            "\n",
            "Training F1: 0.705\n",
            "Validation F1: 0.630\n",
            "\n",
            " Epoch 166 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.800\n",
            "Validation Loss: 1.549\n",
            "\n",
            "Training F1: 0.709\n",
            "Validation F1: 0.596\n",
            "\n",
            " Epoch 167 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.834\n",
            "Validation Loss: 1.598\n",
            "\n",
            "Training F1: 0.686\n",
            "Validation F1: 0.617\n",
            "\n",
            " Epoch 168 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.815\n",
            "Validation Loss: 1.376\n",
            "\n",
            "Training F1: 0.705\n",
            "Validation F1: 0.675\n",
            "\n",
            " Epoch 169 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.818\n",
            "Validation Loss: 1.571\n",
            "\n",
            "Training F1: 0.701\n",
            "Validation F1: 0.600\n",
            "\n",
            " Epoch 170 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.809\n",
            "Validation Loss: 1.485\n",
            "\n",
            "Training F1: 0.695\n",
            "Validation F1: 0.647\n",
            "\n",
            " Epoch 171 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.793\n",
            "Validation Loss: 1.592\n",
            "\n",
            "Training F1: 0.704\n",
            "Validation F1: 0.624\n",
            "\n",
            " Epoch 172 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.793\n",
            "Validation Loss: 1.550\n",
            "\n",
            "Training F1: 0.705\n",
            "Validation F1: 0.627\n",
            "\n",
            " Epoch 173 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.820\n",
            "Validation Loss: 1.716\n",
            "\n",
            "Training F1: 0.696\n",
            "Validation F1: 0.625\n",
            "\n",
            " Epoch 174 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.808\n",
            "Validation Loss: 1.534\n",
            "\n",
            "Training F1: 0.702\n",
            "Validation F1: 0.615\n",
            "\n",
            " Epoch 175 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.802\n",
            "Validation Loss: 1.614\n",
            "\n",
            "Training F1: 0.706\n",
            "Validation F1: 0.563\n",
            "\n",
            " Epoch 176 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.785\n",
            "Validation Loss: 1.610\n",
            "\n",
            "Training F1: 0.704\n",
            "Validation F1: 0.578\n",
            "\n",
            " Epoch 177 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.792\n",
            "Validation Loss: 1.612\n",
            "\n",
            "Training F1: 0.706\n",
            "Validation F1: 0.622\n",
            "\n",
            " Epoch 178 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.777\n",
            "Validation Loss: 1.349\n",
            "\n",
            "Training F1: 0.719\n",
            "Validation F1: 0.691\n",
            "\n",
            " Epoch 179 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.807\n",
            "Validation Loss: 1.378\n",
            "\n",
            "Training F1: 0.702\n",
            "Validation F1: 0.677\n",
            "\n",
            " Epoch 180 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.797\n",
            "Validation Loss: 1.568\n",
            "\n",
            "Training F1: 0.712\n",
            "Validation F1: 0.621\n",
            "\n",
            " Epoch 181 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.796\n",
            "Validation Loss: 1.675\n",
            "\n",
            "Training F1: 0.708\n",
            "Validation F1: 0.626\n",
            "\n",
            " Epoch 182 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.805\n",
            "Validation Loss: 1.563\n",
            "\n",
            "Training F1: 0.701\n",
            "Validation F1: 0.639\n",
            "\n",
            " Epoch 183 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.776\n",
            "Validation Loss: 1.540\n",
            "\n",
            "Training F1: 0.709\n",
            "Validation F1: 0.608\n",
            "\n",
            " Epoch 184 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.772\n",
            "Validation Loss: 1.440\n",
            "\n",
            "Training F1: 0.714\n",
            "Validation F1: 0.647\n",
            "\n",
            " Epoch 185 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.789\n",
            "Validation Loss: 1.592\n",
            "\n",
            "Training F1: 0.707\n",
            "Validation F1: 0.599\n",
            "\n",
            " Epoch 186 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.763\n",
            "Validation Loss: 1.441\n",
            "\n",
            "Training F1: 0.711\n",
            "Validation F1: 0.639\n",
            "\n",
            " Epoch 187 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.752\n",
            "Validation Loss: 1.457\n",
            "\n",
            "Training F1: 0.719\n",
            "Validation F1: 0.664\n",
            "\n",
            " Epoch 188 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.774\n",
            "Validation Loss: 1.490\n",
            "\n",
            "Training F1: 0.711\n",
            "Validation F1: 0.621\n",
            "\n",
            " Epoch 189 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.759\n",
            "Validation Loss: 1.955\n",
            "\n",
            "Training F1: 0.721\n",
            "Validation F1: 0.599\n",
            "\n",
            " Epoch 190 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.760\n",
            "Validation Loss: 1.586\n",
            "\n",
            "Training F1: 0.716\n",
            "Validation F1: 0.624\n",
            "\n",
            " Epoch 191 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.757\n",
            "Validation Loss: 1.622\n",
            "\n",
            "Training F1: 0.720\n",
            "Validation F1: 0.610\n",
            "\n",
            " Epoch 192 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.755\n",
            "Validation Loss: 1.820\n",
            "\n",
            "Training F1: 0.716\n",
            "Validation F1: 0.627\n",
            "\n",
            " Epoch 193 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.786\n",
            "Validation Loss: 1.670\n",
            "\n",
            "Training F1: 0.712\n",
            "Validation F1: 0.598\n",
            "\n",
            " Epoch 194 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.757\n",
            "Validation Loss: 1.531\n",
            "\n",
            "Training F1: 0.728\n",
            "Validation F1: 0.616\n",
            "\n",
            " Epoch 195 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.752\n",
            "Validation Loss: 1.504\n",
            "\n",
            "Training F1: 0.724\n",
            "Validation F1: 0.655\n",
            "\n",
            " Epoch 196 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.759\n",
            "Validation Loss: 1.561\n",
            "\n",
            "Training F1: 0.723\n",
            "Validation F1: 0.597\n",
            "\n",
            " Epoch 197 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.766\n",
            "Validation Loss: 1.558\n",
            "\n",
            "Training F1: 0.721\n",
            "Validation F1: 0.629\n",
            "\n",
            " Epoch 198 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.757\n",
            "Validation Loss: 1.523\n",
            "\n",
            "Training F1: 0.724\n",
            "Validation F1: 0.641\n",
            "\n",
            " Epoch 199 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.759\n",
            "Validation Loss: 1.642\n",
            "\n",
            "Training F1: 0.716\n",
            "Validation F1: 0.602\n",
            "\n",
            " Epoch 200 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.775\n",
            "Validation Loss: 1.495\n",
            "\n",
            "Training F1: 0.721\n",
            "Validation F1: 0.618\n",
            "\n",
            " Epoch 201 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.770\n",
            "Validation Loss: 1.584\n",
            "\n",
            "Training F1: 0.721\n",
            "Validation F1: 0.624\n",
            "\n",
            " Epoch 202 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.743\n",
            "Validation Loss: 1.528\n",
            "\n",
            "Training F1: 0.728\n",
            "Validation F1: 0.632\n",
            "\n",
            " Epoch 203 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.720\n",
            "Validation Loss: 1.451\n",
            "\n",
            "Training F1: 0.731\n",
            "Validation F1: 0.664\n",
            "\n",
            " Epoch 204 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.755\n",
            "Validation Loss: 1.564\n",
            "\n",
            "Training F1: 0.719\n",
            "Validation F1: 0.621\n",
            "\n",
            " Epoch 205 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.762\n",
            "Validation Loss: 1.577\n",
            "\n",
            "Training F1: 0.718\n",
            "Validation F1: 0.591\n",
            "\n",
            " Epoch 206 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.753\n",
            "Validation Loss: 1.644\n",
            "\n",
            "Training F1: 0.727\n",
            "Validation F1: 0.578\n",
            "\n",
            " Epoch 207 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.763\n",
            "Validation Loss: 1.568\n",
            "\n",
            "Training F1: 0.719\n",
            "Validation F1: 0.614\n",
            "\n",
            " Epoch 208 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.753\n",
            "Validation Loss: 1.565\n",
            "\n",
            "Training F1: 0.728\n",
            "Validation F1: 0.609\n",
            "\n",
            " Epoch 209 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.743\n",
            "Validation Loss: 1.445\n",
            "\n",
            "Training F1: 0.719\n",
            "Validation F1: 0.626\n",
            "\n",
            " Epoch 210 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.706\n",
            "Validation Loss: 1.539\n",
            "\n",
            "Training F1: 0.742\n",
            "Validation F1: 0.591\n",
            "\n",
            " Epoch 211 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.699\n",
            "Validation Loss: 1.330\n",
            "\n",
            "Training F1: 0.731\n",
            "Validation F1: 0.659\n",
            "\n",
            " Epoch 212 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.728\n",
            "Validation Loss: 1.428\n",
            "\n",
            "Training F1: 0.722\n",
            "Validation F1: 0.623\n",
            "\n",
            " Epoch 213 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.752\n",
            "Validation Loss: 1.383\n",
            "\n",
            "Training F1: 0.721\n",
            "Validation F1: 0.634\n",
            "\n",
            " Epoch 214 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.721\n",
            "Validation Loss: 1.448\n",
            "\n",
            "Training F1: 0.733\n",
            "Validation F1: 0.632\n",
            "\n",
            " Epoch 215 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.741\n",
            "Validation Loss: 1.425\n",
            "\n",
            "Training F1: 0.731\n",
            "Validation F1: 0.667\n",
            "\n",
            " Epoch 216 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.745\n",
            "Validation Loss: 1.539\n",
            "\n",
            "Training F1: 0.727\n",
            "Validation F1: 0.641\n",
            "\n",
            " Epoch 217 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.730\n",
            "Validation Loss: 1.613\n",
            "\n",
            "Training F1: 0.734\n",
            "Validation F1: 0.585\n",
            "\n",
            " Epoch 218 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.727\n",
            "Validation Loss: 1.682\n",
            "\n",
            "Training F1: 0.739\n",
            "Validation F1: 0.609\n",
            "\n",
            " Epoch 219 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.765\n",
            "Validation Loss: 1.303\n",
            "\n",
            "Training F1: 0.727\n",
            "Validation F1: 0.660\n",
            "\n",
            " Epoch 220 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.738\n",
            "Validation Loss: 1.437\n",
            "\n",
            "Training F1: 0.726\n",
            "Validation F1: 0.596\n",
            "\n",
            " Epoch 221 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.749\n",
            "Validation Loss: 1.355\n",
            "\n",
            "Training F1: 0.721\n",
            "Validation F1: 0.681\n",
            "\n",
            " Epoch 222 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.732\n",
            "Validation Loss: 1.669\n",
            "\n",
            "Training F1: 0.733\n",
            "Validation F1: 0.579\n",
            "\n",
            " Epoch 223 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.715\n",
            "Validation Loss: 1.500\n",
            "\n",
            "Training F1: 0.740\n",
            "Validation F1: 0.635\n",
            "\n",
            " Epoch 224 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.735\n",
            "Validation Loss: 1.465\n",
            "\n",
            "Training F1: 0.737\n",
            "Validation F1: 0.625\n",
            "\n",
            " Epoch 225 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.714\n",
            "Validation Loss: 1.649\n",
            "\n",
            "Training F1: 0.734\n",
            "Validation F1: 0.595\n",
            "\n",
            " Epoch 226 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.739\n",
            "Validation Loss: 1.586\n",
            "\n",
            "Training F1: 0.734\n",
            "Validation F1: 0.600\n",
            "\n",
            " Epoch 227 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.747\n",
            "Validation Loss: 1.647\n",
            "\n",
            "Training F1: 0.734\n",
            "Validation F1: 0.594\n",
            "\n",
            " Epoch 228 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.689\n",
            "Validation Loss: 1.681\n",
            "\n",
            "Training F1: 0.746\n",
            "Validation F1: 0.568\n",
            "\n",
            " Epoch 229 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.717\n",
            "Validation Loss: 1.468\n",
            "\n",
            "Training F1: 0.742\n",
            "Validation F1: 0.659\n",
            "\n",
            " Epoch 230 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.690\n",
            "Validation Loss: 1.578\n",
            "\n",
            "Training F1: 0.737\n",
            "Validation F1: 0.630\n",
            "\n",
            " Epoch 231 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.725\n",
            "Validation Loss: 1.609\n",
            "\n",
            "Training F1: 0.730\n",
            "Validation F1: 0.622\n",
            "\n",
            " Epoch 232 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.714\n",
            "Validation Loss: 1.592\n",
            "\n",
            "Training F1: 0.741\n",
            "Validation F1: 0.631\n",
            "\n",
            " Epoch 233 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.725\n",
            "Validation Loss: 1.580\n",
            "\n",
            "Training F1: 0.741\n",
            "Validation F1: 0.601\n",
            "\n",
            " Epoch 234 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.713\n",
            "Validation Loss: 1.636\n",
            "\n",
            "Training F1: 0.736\n",
            "Validation F1: 0.630\n",
            "\n",
            " Epoch 235 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.728\n",
            "Validation Loss: 1.539\n",
            "\n",
            "Training F1: 0.727\n",
            "Validation F1: 0.613\n",
            "\n",
            " Epoch 236 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.714\n",
            "Validation Loss: 1.521\n",
            "\n",
            "Training F1: 0.740\n",
            "Validation F1: 0.644\n",
            "\n",
            " Epoch 237 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.699\n",
            "Validation Loss: 1.593\n",
            "\n",
            "Training F1: 0.741\n",
            "Validation F1: 0.620\n",
            "\n",
            " Epoch 238 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.735\n",
            "Validation Loss: 1.599\n",
            "\n",
            "Training F1: 0.732\n",
            "Validation F1: 0.621\n",
            "\n",
            " Epoch 239 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.720\n",
            "Validation Loss: 1.511\n",
            "\n",
            "Training F1: 0.739\n",
            "Validation F1: 0.635\n",
            "\n",
            " Epoch 240 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.714\n",
            "Validation Loss: 1.518\n",
            "\n",
            "Training F1: 0.738\n",
            "Validation F1: 0.616\n",
            "\n",
            " Epoch 241 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.717\n",
            "Validation Loss: 1.459\n",
            "\n",
            "Training F1: 0.736\n",
            "Validation F1: 0.654\n",
            "\n",
            " Epoch 242 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.721\n",
            "Validation Loss: 1.736\n",
            "\n",
            "Training F1: 0.732\n",
            "Validation F1: 0.577\n",
            "\n",
            " Epoch 243 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.694\n",
            "Validation Loss: 1.551\n",
            "\n",
            "Training F1: 0.743\n",
            "Validation F1: 0.607\n",
            "\n",
            " Epoch 244 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.721\n",
            "Validation Loss: 1.559\n",
            "\n",
            "Training F1: 0.734\n",
            "Validation F1: 0.658\n",
            "\n",
            " Epoch 245 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.699\n",
            "Validation Loss: 1.490\n",
            "\n",
            "Training F1: 0.749\n",
            "Validation F1: 0.621\n",
            "\n",
            " Epoch 246 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.684\n",
            "Validation Loss: 1.600\n",
            "\n",
            "Training F1: 0.750\n",
            "Validation F1: 0.627\n",
            "\n",
            " Epoch 247 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.689\n",
            "Validation Loss: 1.445\n",
            "\n",
            "Training F1: 0.742\n",
            "Validation F1: 0.658\n",
            "\n",
            " Epoch 248 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.696\n",
            "Validation Loss: 1.698\n",
            "\n",
            "Training F1: 0.742\n",
            "Validation F1: 0.608\n",
            "\n",
            " Epoch 249 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.677\n",
            "Validation Loss: 1.445\n",
            "\n",
            "Training F1: 0.749\n",
            "Validation F1: 0.671\n",
            "\n",
            " Epoch 250 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.677\n",
            "Validation Loss: 1.549\n",
            "\n",
            "Training F1: 0.747\n",
            "Validation F1: 0.649\n",
            "\n",
            " Epoch 251 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.692\n",
            "Validation Loss: 1.639\n",
            "\n",
            "Training F1: 0.746\n",
            "Validation F1: 0.635\n",
            "\n",
            " Epoch 252 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.702\n",
            "Validation Loss: 1.367\n",
            "\n",
            "Training F1: 0.742\n",
            "Validation F1: 0.646\n",
            "\n",
            " Epoch 253 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.683\n",
            "Validation Loss: 1.508\n",
            "\n",
            "Training F1: 0.747\n",
            "Validation F1: 0.647\n",
            "\n",
            " Epoch 254 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.674\n",
            "Validation Loss: 1.486\n",
            "\n",
            "Training F1: 0.749\n",
            "Validation F1: 0.642\n",
            "\n",
            " Epoch 255 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.694\n",
            "Validation Loss: 1.641\n",
            "\n",
            "Training F1: 0.745\n",
            "Validation F1: 0.632\n",
            "\n",
            " Epoch 256 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.696\n",
            "Validation Loss: 1.623\n",
            "\n",
            "Training F1: 0.747\n",
            "Validation F1: 0.610\n",
            "\n",
            " Epoch 257 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.700\n",
            "Validation Loss: 1.457\n",
            "\n",
            "Training F1: 0.746\n",
            "Validation F1: 0.639\n",
            "\n",
            " Epoch 258 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.665\n",
            "Validation Loss: 1.475\n",
            "\n",
            "Training F1: 0.748\n",
            "Validation F1: 0.663\n",
            "\n",
            " Epoch 259 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.677\n",
            "Validation Loss: 1.587\n",
            "\n",
            "Training F1: 0.751\n",
            "Validation F1: 0.639\n",
            "\n",
            " Epoch 260 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.702\n",
            "Validation Loss: 1.468\n",
            "\n",
            "Training F1: 0.737\n",
            "Validation F1: 0.668\n",
            "\n",
            " Epoch 261 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.696\n",
            "Validation Loss: 1.747\n",
            "\n",
            "Training F1: 0.741\n",
            "Validation F1: 0.591\n",
            "\n",
            " Epoch 262 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.692\n",
            "Validation Loss: 1.528\n",
            "\n",
            "Training F1: 0.746\n",
            "Validation F1: 0.632\n",
            "\n",
            " Epoch 263 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.687\n",
            "Validation Loss: 1.562\n",
            "\n",
            "Training F1: 0.750\n",
            "Validation F1: 0.614\n",
            "\n",
            " Epoch 264 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.677\n",
            "Validation Loss: 1.440\n",
            "\n",
            "Training F1: 0.755\n",
            "Validation F1: 0.651\n",
            "\n",
            " Epoch 265 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.691\n",
            "Validation Loss: 1.625\n",
            "\n",
            "Training F1: 0.748\n",
            "Validation F1: 0.618\n",
            "\n",
            " Epoch 266 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.687\n",
            "Validation Loss: 1.380\n",
            "\n",
            "Training F1: 0.752\n",
            "Validation F1: 0.660\n",
            "\n",
            " Epoch 267 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.690\n",
            "Validation Loss: 1.736\n",
            "\n",
            "Training F1: 0.748\n",
            "Validation F1: 0.617\n",
            "\n",
            " Epoch 268 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.655\n",
            "Validation Loss: 1.567\n",
            "\n",
            "Training F1: 0.758\n",
            "Validation F1: 0.683\n",
            "\n",
            " Epoch 269 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.682\n",
            "Validation Loss: 1.693\n",
            "\n",
            "Training F1: 0.750\n",
            "Validation F1: 0.636\n",
            "\n",
            " Epoch 270 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.680\n",
            "Validation Loss: 1.602\n",
            "\n",
            "Training F1: 0.753\n",
            "Validation F1: 0.666\n",
            "\n",
            " Epoch 271 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.679\n",
            "Validation Loss: 1.617\n",
            "\n",
            "Training F1: 0.748\n",
            "Validation F1: 0.678\n",
            "\n",
            " Epoch 272 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.673\n",
            "Validation Loss: 1.744\n",
            "\n",
            "Training F1: 0.752\n",
            "Validation F1: 0.633\n",
            "\n",
            " Epoch 273 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.660\n",
            "Validation Loss: 1.516\n",
            "\n",
            "Training F1: 0.758\n",
            "Validation F1: 0.703\n",
            "\n",
            " Epoch 274 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.692\n",
            "Validation Loss: 1.512\n",
            "\n",
            "Training F1: 0.743\n",
            "Validation F1: 0.649\n",
            "\n",
            " Epoch 275 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.660\n",
            "Validation Loss: 1.517\n",
            "\n",
            "Training F1: 0.760\n",
            "Validation F1: 0.656\n",
            "\n",
            " Epoch 276 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.652\n",
            "Validation Loss: 1.606\n",
            "\n",
            "Training F1: 0.757\n",
            "Validation F1: 0.650\n",
            "\n",
            " Epoch 277 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.664\n",
            "Validation Loss: 1.517\n",
            "\n",
            "Training F1: 0.760\n",
            "Validation F1: 0.684\n",
            "\n",
            " Epoch 278 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.658\n",
            "Validation Loss: 1.572\n",
            "\n",
            "Training F1: 0.756\n",
            "Validation F1: 0.644\n",
            "\n",
            " Epoch 279 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.649\n",
            "Validation Loss: 1.570\n",
            "\n",
            "Training F1: 0.765\n",
            "Validation F1: 0.667\n",
            "\n",
            " Epoch 280 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.663\n",
            "Validation Loss: 1.578\n",
            "\n",
            "Training F1: 0.756\n",
            "Validation F1: 0.643\n",
            "\n",
            " Epoch 281 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.667\n",
            "Validation Loss: 1.696\n",
            "\n",
            "Training F1: 0.756\n",
            "Validation F1: 0.629\n",
            "\n",
            " Epoch 282 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.664\n",
            "Validation Loss: 1.565\n",
            "\n",
            "Training F1: 0.759\n",
            "Validation F1: 0.633\n",
            "\n",
            " Epoch 283 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.657\n",
            "Validation Loss: 1.828\n",
            "\n",
            "Training F1: 0.757\n",
            "Validation F1: 0.603\n",
            "\n",
            " Epoch 284 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.657\n",
            "Validation Loss: 1.643\n",
            "\n",
            "Training F1: 0.759\n",
            "Validation F1: 0.632\n",
            "\n",
            " Epoch 285 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.657\n",
            "Validation Loss: 1.600\n",
            "\n",
            "Training F1: 0.756\n",
            "Validation F1: 0.654\n",
            "\n",
            " Epoch 286 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.648\n",
            "Validation Loss: 1.740\n",
            "\n",
            "Training F1: 0.759\n",
            "Validation F1: 0.617\n",
            "\n",
            " Epoch 287 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.664\n",
            "Validation Loss: 1.617\n",
            "\n",
            "Training F1: 0.755\n",
            "Validation F1: 0.631\n",
            "\n",
            " Epoch 288 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.642\n",
            "Validation Loss: 1.633\n",
            "\n",
            "Training F1: 0.761\n",
            "Validation F1: 0.613\n",
            "\n",
            " Epoch 289 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.670\n",
            "Validation Loss: 1.743\n",
            "\n",
            "Training F1: 0.759\n",
            "Validation F1: 0.620\n",
            "\n",
            " Epoch 290 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.668\n",
            "Validation Loss: 1.455\n",
            "\n",
            "Training F1: 0.763\n",
            "Validation F1: 0.660\n",
            "\n",
            " Epoch 291 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.660\n",
            "Validation Loss: 1.684\n",
            "\n",
            "Training F1: 0.758\n",
            "Validation F1: 0.591\n",
            "\n",
            " Epoch 292 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.661\n",
            "Validation Loss: 1.812\n",
            "\n",
            "Training F1: 0.766\n",
            "Validation F1: 0.613\n",
            "\n",
            " Epoch 293 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.648\n",
            "Validation Loss: 1.685\n",
            "\n",
            "Training F1: 0.764\n",
            "Validation F1: 0.644\n",
            "\n",
            " Epoch 294 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.675\n",
            "Validation Loss: 1.735\n",
            "\n",
            "Training F1: 0.759\n",
            "Validation F1: 0.605\n",
            "\n",
            " Epoch 295 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.662\n",
            "Validation Loss: 1.639\n",
            "\n",
            "Training F1: 0.762\n",
            "Validation F1: 0.655\n",
            "\n",
            " Epoch 296 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.643\n",
            "Validation Loss: 1.639\n",
            "\n",
            "Training F1: 0.764\n",
            "Validation F1: 0.596\n",
            "\n",
            " Epoch 297 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.680\n",
            "Validation Loss: 1.729\n",
            "\n",
            "Training F1: 0.755\n",
            "Validation F1: 0.625\n",
            "\n",
            " Epoch 298 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.653\n",
            "Validation Loss: 1.640\n",
            "\n",
            "Training F1: 0.766\n",
            "Validation F1: 0.639\n",
            "\n",
            " Epoch 299 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.661\n",
            "Validation Loss: 1.681\n",
            "\n",
            "Training F1: 0.755\n",
            "Validation F1: 0.628\n",
            "\n",
            " Epoch 300 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.646\n",
            "Validation Loss: 1.591\n",
            "\n",
            "Training F1: 0.762\n",
            "Validation F1: 0.633\n",
            "\n",
            " Epoch 301 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.660\n",
            "Validation Loss: 1.337\n",
            "\n",
            "Training F1: 0.764\n",
            "Validation F1: 0.691\n",
            "\n",
            " Epoch 302 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.637\n",
            "Validation Loss: 1.444\n",
            "\n",
            "Training F1: 0.772\n",
            "Validation F1: 0.689\n",
            "\n",
            " Epoch 303 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.664\n",
            "Validation Loss: 1.591\n",
            "\n",
            "Training F1: 0.764\n",
            "Validation F1: 0.644\n",
            "\n",
            " Epoch 304 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.642\n",
            "Validation Loss: 1.792\n",
            "\n",
            "Training F1: 0.765\n",
            "Validation F1: 0.589\n",
            "\n",
            " Epoch 305 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.628\n",
            "Validation Loss: 1.768\n",
            "\n",
            "Training F1: 0.765\n",
            "Validation F1: 0.619\n",
            "\n",
            " Epoch 306 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.657\n",
            "Validation Loss: 1.725\n",
            "\n",
            "Training F1: 0.769\n",
            "Validation F1: 0.630\n",
            "\n",
            " Epoch 307 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.623\n",
            "Validation Loss: 1.870\n",
            "\n",
            "Training F1: 0.772\n",
            "Validation F1: 0.609\n",
            "\n",
            " Epoch 308 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.639\n",
            "Validation Loss: 1.766\n",
            "\n",
            "Training F1: 0.760\n",
            "Validation F1: 0.622\n",
            "\n",
            " Epoch 309 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.646\n",
            "Validation Loss: 1.586\n",
            "\n",
            "Training F1: 0.766\n",
            "Validation F1: 0.654\n",
            "\n",
            " Epoch 310 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.638\n",
            "Validation Loss: 1.815\n",
            "\n",
            "Training F1: 0.770\n",
            "Validation F1: 0.620\n",
            "\n",
            " Epoch 311 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.641\n",
            "Validation Loss: 1.778\n",
            "\n",
            "Training F1: 0.768\n",
            "Validation F1: 0.606\n",
            "\n",
            " Epoch 312 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.612\n",
            "Validation Loss: 1.882\n",
            "\n",
            "Training F1: 0.769\n",
            "Validation F1: 0.593\n",
            "\n",
            " Epoch 313 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.636\n",
            "Validation Loss: 1.658\n",
            "\n",
            "Training F1: 0.767\n",
            "Validation F1: 0.634\n",
            "\n",
            " Epoch 314 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.628\n",
            "Validation Loss: 1.743\n",
            "\n",
            "Training F1: 0.765\n",
            "Validation F1: 0.629\n",
            "\n",
            " Epoch 315 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.652\n",
            "Validation Loss: 1.394\n",
            "\n",
            "Training F1: 0.760\n",
            "Validation F1: 0.664\n",
            "\n",
            " Epoch 316 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.629\n",
            "Validation Loss: 1.628\n",
            "\n",
            "Training F1: 0.769\n",
            "Validation F1: 0.635\n",
            "\n",
            " Epoch 317 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.615\n",
            "Validation Loss: 1.599\n",
            "\n",
            "Training F1: 0.767\n",
            "Validation F1: 0.646\n",
            "\n",
            " Epoch 318 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.626\n",
            "Validation Loss: 1.418\n",
            "\n",
            "Training F1: 0.777\n",
            "Validation F1: 0.663\n",
            "\n",
            " Epoch 319 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.649\n",
            "Validation Loss: 1.841\n",
            "\n",
            "Training F1: 0.771\n",
            "Validation F1: 0.588\n",
            "\n",
            " Epoch 320 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.633\n",
            "Validation Loss: 1.683\n",
            "\n",
            "Training F1: 0.763\n",
            "Validation F1: 0.636\n",
            "\n",
            " Epoch 321 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.624\n",
            "Validation Loss: 1.716\n",
            "\n",
            "Training F1: 0.772\n",
            "Validation F1: 0.621\n",
            "\n",
            " Epoch 322 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.605\n",
            "Validation Loss: 1.851\n",
            "\n",
            "Training F1: 0.782\n",
            "Validation F1: 0.598\n",
            "\n",
            " Epoch 323 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.622\n",
            "Validation Loss: 1.592\n",
            "\n",
            "Training F1: 0.776\n",
            "Validation F1: 0.658\n",
            "\n",
            " Epoch 324 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.633\n",
            "Validation Loss: 1.653\n",
            "\n",
            "Training F1: 0.767\n",
            "Validation F1: 0.639\n",
            "\n",
            " Epoch 325 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.634\n",
            "Validation Loss: 1.641\n",
            "\n",
            "Training F1: 0.768\n",
            "Validation F1: 0.630\n",
            "\n",
            " Epoch 326 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.636\n",
            "Validation Loss: 1.730\n",
            "\n",
            "Training F1: 0.771\n",
            "Validation F1: 0.616\n",
            "\n",
            " Epoch 327 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.616\n",
            "Validation Loss: 1.649\n",
            "\n",
            "Training F1: 0.770\n",
            "Validation F1: 0.654\n",
            "\n",
            " Epoch 328 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.607\n",
            "Validation Loss: 1.588\n",
            "\n",
            "Training F1: 0.779\n",
            "Validation F1: 0.660\n",
            "\n",
            " Epoch 329 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.602\n",
            "Validation Loss: 1.753\n",
            "\n",
            "Training F1: 0.783\n",
            "Validation F1: 0.647\n",
            "\n",
            " Epoch 330 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.622\n",
            "Validation Loss: 1.724\n",
            "\n",
            "Training F1: 0.781\n",
            "Validation F1: 0.648\n",
            "\n",
            " Epoch 331 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.622\n",
            "Validation Loss: 1.508\n",
            "\n",
            "Training F1: 0.778\n",
            "Validation F1: 0.651\n",
            "\n",
            " Epoch 332 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.614\n",
            "Validation Loss: 1.781\n",
            "\n",
            "Training F1: 0.775\n",
            "Validation F1: 0.608\n",
            "\n",
            " Epoch 333 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.641\n",
            "Validation Loss: 1.663\n",
            "\n",
            "Training F1: 0.766\n",
            "Validation F1: 0.648\n",
            "\n",
            " Epoch 334 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.660\n",
            "Validation Loss: 1.516\n",
            "\n",
            "Training F1: 0.761\n",
            "Validation F1: 0.678\n",
            "\n",
            " Epoch 335 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.641\n",
            "Validation Loss: 1.550\n",
            "\n",
            "Training F1: 0.771\n",
            "Validation F1: 0.666\n",
            "\n",
            " Epoch 336 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.628\n",
            "Validation Loss: 1.568\n",
            "\n",
            "Training F1: 0.769\n",
            "Validation F1: 0.637\n",
            "\n",
            " Epoch 337 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.609\n",
            "Validation Loss: 1.802\n",
            "\n",
            "Training F1: 0.780\n",
            "Validation F1: 0.608\n",
            "\n",
            " Epoch 338 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.628\n",
            "Validation Loss: 1.429\n",
            "\n",
            "Training F1: 0.771\n",
            "Validation F1: 0.663\n",
            "\n",
            " Epoch 339 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.624\n",
            "Validation Loss: 1.743\n",
            "\n",
            "Training F1: 0.770\n",
            "Validation F1: 0.621\n",
            "\n",
            " Epoch 340 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.621\n",
            "Validation Loss: 1.655\n",
            "\n",
            "Training F1: 0.770\n",
            "Validation F1: 0.638\n",
            "\n",
            " Epoch 341 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.617\n",
            "Validation Loss: 1.766\n",
            "\n",
            "Training F1: 0.777\n",
            "Validation F1: 0.635\n",
            "\n",
            " Epoch 342 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.620\n",
            "Validation Loss: 1.568\n",
            "\n",
            "Training F1: 0.770\n",
            "Validation F1: 0.674\n",
            "\n",
            " Epoch 343 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.592\n",
            "Validation Loss: 1.827\n",
            "\n",
            "Training F1: 0.785\n",
            "Validation F1: 0.662\n",
            "\n",
            " Epoch 344 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.621\n",
            "Validation Loss: 1.599\n",
            "\n",
            "Training F1: 0.776\n",
            "Validation F1: 0.642\n",
            "\n",
            " Epoch 345 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.615\n",
            "Validation Loss: 1.826\n",
            "\n",
            "Training F1: 0.773\n",
            "Validation F1: 0.620\n",
            "\n",
            " Epoch 346 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.606\n",
            "Validation Loss: 1.803\n",
            "\n",
            "Training F1: 0.783\n",
            "Validation F1: 0.658\n",
            "\n",
            " Epoch 347 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.611\n",
            "Validation Loss: 1.657\n",
            "\n",
            "Training F1: 0.775\n",
            "Validation F1: 0.660\n",
            "\n",
            " Epoch 348 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.610\n",
            "Validation Loss: 1.546\n",
            "\n",
            "Training F1: 0.776\n",
            "Validation F1: 0.670\n",
            "\n",
            " Epoch 349 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.602\n",
            "Validation Loss: 1.572\n",
            "\n",
            "Training F1: 0.779\n",
            "Validation F1: 0.654\n",
            "\n",
            " Epoch 350 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.613\n",
            "Validation Loss: 1.815\n",
            "\n",
            "Training F1: 0.783\n",
            "Validation F1: 0.664\n",
            "\n",
            " Epoch 351 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.602\n",
            "Validation Loss: 1.970\n",
            "\n",
            "Training F1: 0.782\n",
            "Validation F1: 0.601\n",
            "\n",
            " Epoch 352 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.626\n",
            "Validation Loss: 1.555\n",
            "\n",
            "Training F1: 0.771\n",
            "Validation F1: 0.647\n",
            "\n",
            " Epoch 353 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.569\n",
            "Validation Loss: 1.766\n",
            "\n",
            "Training F1: 0.794\n",
            "Validation F1: 0.629\n",
            "\n",
            " Epoch 354 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.595\n",
            "Validation Loss: 1.584\n",
            "\n",
            "Training F1: 0.780\n",
            "Validation F1: 0.629\n",
            "\n",
            " Epoch 355 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.608\n",
            "Validation Loss: 1.548\n",
            "\n",
            "Training F1: 0.777\n",
            "Validation F1: 0.663\n",
            "\n",
            " Epoch 356 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.613\n",
            "Validation Loss: 1.664\n",
            "\n",
            "Training F1: 0.782\n",
            "Validation F1: 0.658\n",
            "\n",
            " Epoch 357 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.623\n",
            "Validation Loss: 1.694\n",
            "\n",
            "Training F1: 0.774\n",
            "Validation F1: 0.609\n",
            "\n",
            " Epoch 358 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.622\n",
            "Validation Loss: 1.867\n",
            "\n",
            "Training F1: 0.778\n",
            "Validation F1: 0.627\n",
            "\n",
            " Epoch 359 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.612\n",
            "Validation Loss: 1.565\n",
            "\n",
            "Training F1: 0.774\n",
            "Validation F1: 0.663\n",
            "\n",
            " Epoch 360 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.617\n",
            "Validation Loss: 1.822\n",
            "\n",
            "Training F1: 0.768\n",
            "Validation F1: 0.641\n",
            "\n",
            " Epoch 361 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.595\n",
            "Validation Loss: 1.670\n",
            "\n",
            "Training F1: 0.779\n",
            "Validation F1: 0.650\n",
            "\n",
            " Epoch 362 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.588\n",
            "Validation Loss: 1.650\n",
            "\n",
            "Training F1: 0.789\n",
            "Validation F1: 0.653\n",
            "\n",
            " Epoch 363 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.614\n",
            "Validation Loss: 1.642\n",
            "\n",
            "Training F1: 0.777\n",
            "Validation F1: 0.638\n",
            "\n",
            " Epoch 364 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.604\n",
            "Validation Loss: 1.636\n",
            "\n",
            "Training F1: 0.785\n",
            "Validation F1: 0.650\n",
            "\n",
            " Epoch 365 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.605\n",
            "Validation Loss: 1.599\n",
            "\n",
            "Training F1: 0.782\n",
            "Validation F1: 0.659\n",
            "\n",
            " Epoch 366 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.612\n",
            "Validation Loss: 1.510\n",
            "\n",
            "Training F1: 0.776\n",
            "Validation F1: 0.684\n",
            "\n",
            " Epoch 367 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.622\n",
            "Validation Loss: 1.596\n",
            "\n",
            "Training F1: 0.778\n",
            "Validation F1: 0.640\n",
            "\n",
            " Epoch 368 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.616\n",
            "Validation Loss: 1.313\n",
            "\n",
            "Training F1: 0.782\n",
            "Validation F1: 0.680\n",
            "\n",
            " Epoch 369 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.619\n",
            "Validation Loss: 1.746\n",
            "\n",
            "Training F1: 0.778\n",
            "Validation F1: 0.628\n",
            "\n",
            " Epoch 370 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.598\n",
            "Validation Loss: 1.619\n",
            "\n",
            "Training F1: 0.788\n",
            "Validation F1: 0.643\n",
            "\n",
            " Epoch 371 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.580\n",
            "Validation Loss: 1.563\n",
            "\n",
            "Training F1: 0.791\n",
            "Validation F1: 0.668\n",
            "\n",
            " Epoch 372 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.616\n",
            "Validation Loss: 1.667\n",
            "\n",
            "Training F1: 0.777\n",
            "Validation F1: 0.661\n",
            "\n",
            " Epoch 373 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.588\n",
            "Validation Loss: 1.598\n",
            "\n",
            "Training F1: 0.785\n",
            "Validation F1: 0.638\n",
            "\n",
            " Epoch 374 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.593\n",
            "Validation Loss: 1.760\n",
            "\n",
            "Training F1: 0.788\n",
            "Validation F1: 0.636\n",
            "\n",
            " Epoch 375 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.585\n",
            "Validation Loss: 1.601\n",
            "\n",
            "Training F1: 0.785\n",
            "Validation F1: 0.664\n",
            "\n",
            " Epoch 376 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.588\n",
            "Validation Loss: 1.690\n",
            "\n",
            "Training F1: 0.782\n",
            "Validation F1: 0.640\n",
            "\n",
            " Epoch 377 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.564\n",
            "Validation Loss: 1.944\n",
            "\n",
            "Training F1: 0.785\n",
            "Validation F1: 0.614\n",
            "\n",
            " Epoch 378 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.588\n",
            "Validation Loss: 1.859\n",
            "\n",
            "Training F1: 0.783\n",
            "Validation F1: 0.628\n",
            "\n",
            " Epoch 379 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.594\n",
            "Validation Loss: 1.581\n",
            "\n",
            "Training F1: 0.783\n",
            "Validation F1: 0.652\n",
            "\n",
            " Epoch 380 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.587\n",
            "Validation Loss: 1.651\n",
            "\n",
            "Training F1: 0.784\n",
            "Validation F1: 0.641\n",
            "\n",
            " Epoch 381 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.607\n",
            "Validation Loss: 1.726\n",
            "\n",
            "Training F1: 0.785\n",
            "Validation F1: 0.648\n",
            "\n",
            " Epoch 382 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.585\n",
            "Validation Loss: 1.662\n",
            "\n",
            "Training F1: 0.787\n",
            "Validation F1: 0.631\n",
            "\n",
            " Epoch 383 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.590\n",
            "Validation Loss: 1.655\n",
            "\n",
            "Training F1: 0.783\n",
            "Validation F1: 0.663\n",
            "\n",
            " Epoch 384 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.598\n",
            "Validation Loss: 1.717\n",
            "\n",
            "Training F1: 0.784\n",
            "Validation F1: 0.623\n",
            "\n",
            " Epoch 385 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.580\n",
            "Validation Loss: 1.900\n",
            "\n",
            "Training F1: 0.789\n",
            "Validation F1: 0.609\n",
            "\n",
            " Epoch 386 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.586\n",
            "Validation Loss: 1.864\n",
            "\n",
            "Training F1: 0.780\n",
            "Validation F1: 0.617\n",
            "\n",
            " Epoch 387 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.596\n",
            "Validation Loss: 1.441\n",
            "\n",
            "Training F1: 0.787\n",
            "Validation F1: 0.685\n",
            "\n",
            " Epoch 388 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.581\n",
            "Validation Loss: 1.613\n",
            "\n",
            "Training F1: 0.786\n",
            "Validation F1: 0.669\n",
            "\n",
            " Epoch 389 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.577\n",
            "Validation Loss: 1.802\n",
            "\n",
            "Training F1: 0.791\n",
            "Validation F1: 0.610\n",
            "\n",
            " Epoch 390 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.541\n",
            "Validation Loss: 1.500\n",
            "\n",
            "Training F1: 0.800\n",
            "Validation F1: 0.661\n",
            "\n",
            " Epoch 391 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.579\n",
            "Validation Loss: 1.785\n",
            "\n",
            "Training F1: 0.782\n",
            "Validation F1: 0.616\n",
            "\n",
            " Epoch 392 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.594\n",
            "Validation Loss: 1.422\n",
            "\n",
            "Training F1: 0.792\n",
            "Validation F1: 0.683\n",
            "\n",
            " Epoch 393 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.595\n",
            "Validation Loss: 1.882\n",
            "\n",
            "Training F1: 0.784\n",
            "Validation F1: 0.601\n",
            "\n",
            " Epoch 394 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.571\n",
            "Validation Loss: 1.919\n",
            "\n",
            "Training F1: 0.794\n",
            "Validation F1: 0.588\n",
            "\n",
            " Epoch 395 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.565\n",
            "Validation Loss: 1.620\n",
            "\n",
            "Training F1: 0.796\n",
            "Validation F1: 0.656\n",
            "\n",
            " Epoch 396 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.571\n",
            "Validation Loss: 1.898\n",
            "\n",
            "Training F1: 0.790\n",
            "Validation F1: 0.612\n",
            "\n",
            " Epoch 397 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.592\n",
            "Validation Loss: 1.854\n",
            "\n",
            "Training F1: 0.782\n",
            "Validation F1: 0.615\n",
            "\n",
            " Epoch 398 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.572\n",
            "Validation Loss: 1.870\n",
            "\n",
            "Training F1: 0.795\n",
            "Validation F1: 0.614\n",
            "\n",
            " Epoch 399 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.592\n",
            "Validation Loss: 1.866\n",
            "\n",
            "Training F1: 0.789\n",
            "Validation F1: 0.618\n",
            "\n",
            " Epoch 400 / 400\n",
            "  Batch   100  of    291.\n",
            "  Batch   200  of    291.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     75.\n",
            "\n",
            "Training Loss: 0.640\n",
            "Validation Loss: 1.843\n",
            "\n",
            "Training F1: 0.775\n",
            "Validation F1: 0.622\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "dn8hAbOkZscM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854fbf62-c0dc-4d37-b743-f4e18c176a13"
      },
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/BERT/model_weights.pt'\n",
        "\n",
        "checkpoint = torch.load(path, map_location=device)\n",
        "model = checkpoint.get(\"model\")\n",
        "tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-base')\n",
        "\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "test_text = []; test_labels = []\n",
        "\n",
        "# Загружаем описание личности человека для каждого вектора из книги М.В. Бородянского\n",
        "for person_vector in person_vectors:\n",
        "    with open(\"drive/MyDrive/vectors_/\" + person_vector + \".txt\", encoding=\"utf8\") as rf:\n",
        "        for sentence in split_text(rf.read().strip()):\n",
        "            if len(sentence) <= 2: continue\n",
        "            test_text.append(sentence)\n",
        "            test_labels.append(person_vectors.index(person_vector))\n",
        "\n",
        "test_text = np.array(test_text)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())\n",
        "print(\"test_y:\",test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_y: tensor([0, 0, 0,  ..., 7, 7, 7])\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wEvR7h6EZscM"
      },
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hThwcQugZscM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4ef0e0-2867-48cb-da17-31cbc56580e4"
      },
      "cell_type": "code",
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       396\n",
            "           1       0.97      0.98      0.97       299\n",
            "           2       0.99      0.95      0.97       369\n",
            "           3       0.98      0.94      0.96       317\n",
            "           4       0.97      0.99      0.98       232\n",
            "           5       0.96      1.00      0.98       252\n",
            "           6       0.99      0.99      0.99       192\n",
            "           7       0.98      1.00      0.99       252\n",
            "\n",
            "    accuracy                           0.97      2309\n",
            "   macro avg       0.98      0.98      0.98      2309\n",
            "weighted avg       0.98      0.97      0.97      2309\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zOtcxnqrZscM"
      },
      "cell_type": "code",
      "source": [
        "class Prediction:\n",
        "    def __init__(self):\n",
        "        path = 'drive/MyDrive/BERT/model_weights.pt'\n",
        "\n",
        "        checkpoint = torch.load(path,map_location=device)\n",
        "        self.predictor = checkpoint.get(\"model\")\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-base')\n",
        "        self.tag = checkpoint.get(\"id_map\")\n",
        "\n",
        "    def predict(self,text):\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        tokens = tokens[:max_seq_len - 2]\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        input_ids = input_ids + [0] * (max_seq_len-len(input_ids))\n",
        "        input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
        "        input_ids = input_ids.to(device)\n",
        "\n",
        "        input_mask = [1]*len(tokens) + [0] * (max_seq_len - len(tokens))\n",
        "        input_mask = torch.tensor(input_mask).unsqueeze(0)\n",
        "        input_mask = input_mask.to(device)\n",
        "\n",
        "        logits = self.predictor(input_ids,input_mask)\n",
        "        prob = torch.nn.functional.softmax(logits,dim=1)\n",
        "        result = [(self.tag[idx],item) for idx,item in enumerate(prob[0].tolist())]\n",
        "        preds = logits.detach().cpu().numpy()\n",
        "        pred_val = np.argmax(preds)\n",
        "        pred_val = self.tag[pred_val]\n",
        "        return result,pred_val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "W_ClvtnbZscN"
      },
      "cell_type": "code",
      "source": [
        "pred = Prediction()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = []\n",
        "\n",
        "with open(\"drive/MyDrive/val/Основы дзэн-буддизма.txt\", encoding=\"utf8\") as rf:\n",
        "    for sentence in split_text(rf.read().strip()):\n",
        "        if len(sentence) <= 5: continue\n",
        "        text.append(sentence)\n",
        "\n",
        "text[:30]"
      ],
      "metadata": {
        "id": "tbwKhvSp5ir2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b7f02ab-07db-4cf4-e16c-4c1ae222671f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Спасибо, что скачали книгу в бесплатной электронной библиотеке Royallib',\n",
              " 'ru\\nВсе книги автора\\nЭта же книга в других форматах\\n\\nПриятного чтения',\n",
              " 'Дайсэцу Тайтаро Судзуки\\nОсновы дзэнбуддизма\\n\\nКРАТКО ОБ АВТОРЕ\\n\\nДзэнбуддизм в последние годы вызывает к себе самый живой интерес как в Америке, так и в Европе',\n",
              " 'Пробуждению на Западе такого интереса к одной из наиболее древних и глубоких религий Востока в значительной мере способствовал автор данной книги Дайсэцу Тайтаро Судзуки',\n",
              " 'Он является самым прославленным и красноречивым толкователем дзэна на земном шаре',\n",
              " 'Судзуки сначала преподавал в нескольких ведущих университетах Японии, а затем расширил свою деятельность, перенеся ее за рамки отечества и развивая в международном масштабе',\n",
              " 'Начиная с посещения Великобритании в 1936 году в качестве преподавателя (по обмену), он затем читал лекции в различных университетах Америки и Европы',\n",
              " 'Он также написал более ста работ о дзэне и буддизме как на японском, так и на английском языке',\n",
              " 'Целый ряд его работ был переведен на другие западные языки',\n",
              " 'В число книг, опубликованных на английском языке, входят: Введение в дзэнбуддизм, Образ жизни по дзэну, Руководство (учебник) дзэнбуддизма, Дзэнбуддизм, Мистицизм христианский и буддийский, Занятия дзэнбуддизмом, Ланкаватарасутра, Очерки о дзэнбуддизме, три серии, Дзэн и японская культура, Сущность дзэнбуддизма и многие другие',\n",
              " 'В молодые годы автор жил в качестве мирского ученика в Энгакукее, большом монастыре Камакуры',\n",
              " 'За выдающиеся заслуги и вклад в области религии, а также за популяризацию японской культуры за рубежом он был награжден императором Японии в 1949 году медалью и избран членом Японской академии',\n",
              " 'В 1954 году он был награжден премией Асахи за заслуги в области культуры',\n",
              " 'ПРЕДИСЛОВИЕ АНГЛИЙСКОГО РЕДАКТОРА\\n\\nПокойный Дайсэцу Тайтаро Судзуки, профессор буддийской философии в университете Отани в Киото, родился в 1870м, умер в 1966 году',\n",
              " 'Он был, вероятно, величайшим из современных авторитетов в дзэнбуддизме',\n",
              " 'На английском языке насчитывается 25 основных его работ о дзэнбуддизме, а на японском — до сих пор неизвестных на Западе — еще по крайней мере 18',\n",
              " 'Более того, он был, как показывает хронологическая библиография книг о дзэнбуддизме на английском языке, пионером обучения этому предмету вне Японии, так как до опубликования его первой серии Эссе о дзэнбуддизме в 1927 году на Западе о дзэне, как о живом опыте, не знал никто, исключая знакомых с Религией самураев Кайтена Нукарийи и читателей журнала Восточный буддизм',\n",
              " 'Доктор Судзуки пишет со знанием дела',\n",
              " 'Он не только изучил оригинальные буддийские произведения на санскрите, пали, китайском и японском языках, но прекрасно ориентировался в современной философской литературе как на немецком и французском, так и на английском языке, на котором он бегло говорил и писал',\n",
              " 'Более того, он был больше, чем ученый',\n",
              " 'Хотя он и не являлся священником ни одной из буддийских сект, его уважали в каждом японском храме, так как знание духовных ценностей было в нем непосредственным и глубоким, о чем свидетельствуют все, кто имел возможность лично с ним общаться',\n",
              " 'Когда он обсуждал высшие состояния сознания, он говорил как человек, который в них жил',\n",
              " 'и на тех, кто духовно общался с ним, он производил впечатление человека, ищущего интеллектуальные символы для описания состояния сознания, лежащего по ту сторону интеллекта',\n",
              " 'Его труды должны заменить личное общение с мастером тем, кто не имел этой возможности',\n",
              " 'С этой целью вскоре после войны работы доктора Судзуки были собраны в одно восьмитомное собрание сочинений, опубликованное издательством Райдер и К° в Лондоне',\n",
              " 'Три знаменитые тома Эссе о дзэнбуддизме и собрание статей, написанных в течение 50 лет, которые я назвал Штудии в дзэнбуддизме',\n",
              " 'Эти работы не равноценны, поэтому неудивительно, что наиболее популярным было Введение в дзэнбуддизм, последнее издание которого открывалось предисловием Карла Юнга из Цюриха',\n",
              " 'Доктор Юнг своим Секретом Золотого Цветка предпринял пионерскую попытку наведения мостов между специфически китайской мыслью и западной психологией',\n",
              " 'Комментарии этого великого психолога, хотя доктор Судзуки с ними согласен полностью не был, — несомненно, ценное дополнение к этой знаменитой попытке донести дзэнбуддизм до западных читателей',\n",
              " 'Сейчас Райдер и К° вновь перепечатывает Введение в дзэнбуддизм, и этот выбор вполне понятен, ибо интерес к дзэну все возрастает, и все больше и больше западных писателей пытаются выразить невыразимое']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lEtm_Vh3ZscN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3648a669-eb33-4836-fc68-f2ab576c1c65"
      },
      "cell_type": "code",
      "source": [
        "list_input = ['Такие люди обладают ясновидением, точнее яснослышанием.']\n",
        "\n",
        "for item in list_input:\n",
        "    confidence,pred_val = pred.predict(item)\n",
        "    print(pred_val)\n",
        "    print(confidence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blue\n",
            "[('brown', 0.0002236814034404233), ('black', 0.028900807723402977), ('red', 0.0013563736574724317), ('orange', 0.0008247167570516467), ('yellow', 9.238251368515193e-05), ('green', 0.0006321947439573705), ('blue', 0.9646031856536865), ('purple', 0.003366561373695731)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/BERT/model_weights.pt'\n",
        "\n",
        "checkpoint = torch.load(path, map_location=device)\n",
        "model = checkpoint.get(\"model\")\n",
        "tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-base')\n",
        "\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "test_text = []\n",
        "\n",
        "with open(\"drive/MyDrive/val/Гамлет, принц Датский - Уильям Шекспир.txt\", encoding=\"utf8\") as rf:\n",
        "    for text in rf.readlines():\n",
        "        for sentence in split_text(text):\n",
        "            if len(sentence) <= 5: continue\n",
        "            test_text.append(sentence.strip())\n",
        "\n",
        "test_text = np.array(test_text)\n",
        "\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])"
      ],
      "metadata": {
        "id": "HOIAi-848v-I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "9627ebf8-5739-4443-9877-45a1c4d6d8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-2911a2027fb1>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/val/Гамлет, принц Датский - Уильям Шекспир.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/val/Гамлет, принц Датский - Уильям Шекспир.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "7dmwK1he9TyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(preds, axis = 1)"
      ],
      "metadata": {
        "id": "SRHfQiyC9ZEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for vectorId in range(len(person_vectors)):\n",
        "    prob = (preds == vectorId).sum() / len(preds)\n",
        "    print(person_vectors[vectorId], prob)"
      ],
      "metadata": {
        "id": "EeViIw7l_219"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "372d9be4c4744d20a17c1e868c892806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ecc8efebe8b4b58943809fbf3dd3cab",
              "IPY_MODEL_bb8b4ef442f94599b9c94b24fdca62d2",
              "IPY_MODEL_07603cab14504a3f81864e435e9ce418"
            ],
            "layout": "IPY_MODEL_21b701c4bac1456388e7dd83089b54ef"
          }
        },
        "0ecc8efebe8b4b58943809fbf3dd3cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_635328ca174b43b3b4631be37df7d904",
            "placeholder": "​",
            "style": "IPY_MODEL_be8a2d71376748969241e7fc71d2aac2",
            "value": "Downloading (…)solve/main/vocab.txt: "
          }
        },
        "bb8b4ef442f94599b9c94b24fdca62d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f12650930094915ab1a55b475959dc2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf28a06466b345959205985ed00ba6e0",
            "value": 1
          }
        },
        "07603cab14504a3f81864e435e9ce418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c36079dd862418882a601674a1cb42b",
            "placeholder": "​",
            "style": "IPY_MODEL_e101fd731d4c4f539b049c51493eb483",
            "value": " 1.78M/? [00:00&lt;00:00, 5.69MB/s]"
          }
        },
        "21b701c4bac1456388e7dd83089b54ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "635328ca174b43b3b4631be37df7d904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be8a2d71376748969241e7fc71d2aac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f12650930094915ab1a55b475959dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bf28a06466b345959205985ed00ba6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c36079dd862418882a601674a1cb42b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e101fd731d4c4f539b049c51493eb483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d09d351272984df8b777859668183285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_857712483b82468a8449d61f055575bf",
              "IPY_MODEL_0855645d612c4bee8446e610b8c3057f",
              "IPY_MODEL_38bae10048834677b6b746408d500da3"
            ],
            "layout": "IPY_MODEL_0d7bc181c7d94659bacfa80e622000af"
          }
        },
        "857712483b82468a8449d61f055575bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d773e4a8f79943639379f1c2f4997215",
            "placeholder": "​",
            "style": "IPY_MODEL_77dd419320e7434ea5681ac1fc509937",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "0855645d612c4bee8446e610b8c3057f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3404968f53234d7ca4987b70a7e11145",
            "max": 590,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_161d5a54142749f6a5334847cd9ffd47",
            "value": 590
          }
        },
        "38bae10048834677b6b746408d500da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13b4d83f20d04382bc120c71dc38a0ae",
            "placeholder": "​",
            "style": "IPY_MODEL_1f38823bbe574f85bf7aecf5bdf5cf9e",
            "value": " 590/590 [00:00&lt;00:00, 49.1kB/s]"
          }
        },
        "0d7bc181c7d94659bacfa80e622000af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d773e4a8f79943639379f1c2f4997215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77dd419320e7434ea5681ac1fc509937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3404968f53234d7ca4987b70a7e11145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "161d5a54142749f6a5334847cd9ffd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13b4d83f20d04382bc120c71dc38a0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f38823bbe574f85bf7aecf5bdf5cf9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0434c1fd0cdf4782acab845087f3e0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6b430d60e744b3fa7c707057e4fea0b",
              "IPY_MODEL_52933f8588ec49938aa85bf06e5bc353",
              "IPY_MODEL_9bbb52473d054ddca374acfc02b8779f"
            ],
            "layout": "IPY_MODEL_a5e63b8c10a841678d1e1789b1fb1546"
          }
        },
        "e6b430d60e744b3fa7c707057e4fea0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_538ae6aa7a6845c5ae10bb4f5ca4989c",
            "placeholder": "​",
            "style": "IPY_MODEL_942ce88c4e654f0580d91b9b65e6c41f",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "52933f8588ec49938aa85bf06e5bc353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc509a2702914fa9967ea77c5658aaa9",
            "max": 716133354,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31f8935195fd4b098b35d901b2fd1451",
            "value": 716133354
          }
        },
        "9bbb52473d054ddca374acfc02b8779f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69b71b4faacf46e191e8263af3414e3b",
            "placeholder": "​",
            "style": "IPY_MODEL_745068b568904dba86748801e41e07fc",
            "value": " 716M/716M [00:14&lt;00:00, 38.0MB/s]"
          }
        },
        "a5e63b8c10a841678d1e1789b1fb1546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "538ae6aa7a6845c5ae10bb4f5ca4989c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942ce88c4e654f0580d91b9b65e6c41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc509a2702914fa9967ea77c5658aaa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f8935195fd4b098b35d901b2fd1451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69b71b4faacf46e191e8263af3414e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "745068b568904dba86748801e41e07fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}