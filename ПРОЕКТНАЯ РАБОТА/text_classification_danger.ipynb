{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "pT-BjEyUSXuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff114d1-6f11-4e81-cea9-185be6df38f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import os\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "KyoyY9YPcx3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434e9ee7-90cd-4bf8-b5aa-9a1cf1c7ee86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dNlKs_9Hb-VO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f51e21f-43f2-4732-f2a5-bbe91a0e71dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text):\n",
        "    text = text.replace('«', '')\n",
        "    text = text.replace('»', '')\n",
        "    text = text.replace('\"', '')\n",
        "    text = text.replace('-', '')\n",
        "\n",
        "    text = text.replace('т. д.', 'т д')\n",
        "    text = text.replace('т. п.', 'т п')\n",
        "    text = text.replace('др.', 'др')\n",
        "\n",
        "    text = text.replace('...,', ',')\n",
        "    text = text.replace('?,', ',')\n",
        "    text = text.replace('!,', ',')\n",
        "    text = text.replace('.,', ',')\n",
        "    text = text.replace('.)', ')')\n",
        "    text = text.replace(';,', ',')\n",
        "\n",
        "    text = text.replace('....', ';')\n",
        "    text = text.replace('...', ';')\n",
        "    text = text.replace('..', ';')\n",
        "\n",
        "    text = text.replace('!', ';')\n",
        "    text = text.replace('!!', ';')\n",
        "    text = text.replace('!!!', ';')\n",
        "    text = text.replace('?', ';')\n",
        "    text = text.replace('??', ';')\n",
        "    text = text.replace('???', ';')\n",
        "    text = text.replace('!?', ';')\n",
        "    text = text.replace('?!', ';')\n",
        "    text = text.replace('.', ';')\n",
        "    text = text.replace(u'\\xa0', u' ')\n",
        "\n",
        "    return [txt.strip() for txt in text.split(';')]"
      ],
      "metadata": {
        "id": "D6D6Z7QCb_ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка описания психологических векторов.**"
      ],
      "metadata": {
        "id": "zWesr9__cHVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "danger_types = (\"type1\", \"type2\", \"type3\", \"type4\")"
      ],
      "metadata": {
        "id": "nejPs-qPcKek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = dict(zip(danger_types, [vectorId for vectorId in range(len(danger_types))]))\n",
        "print(label_map)\n",
        "id2label = dict(zip([vectorId for vectorId in range(len(danger_types))], danger_types))\n",
        "print(id2label)"
      ],
      "metadata": {
        "id": "k1S9fSpmhaSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b034f77c-6033-4571-8437-ab98ae31dd3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'type1': 0, 'type2': 1, 'type3': 2, 'type4': 3}\n",
            "{0: 'type1', 1: 'type2', 2: 'type3', 3: 'type4'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = []; train_labels = []\n",
        "\n",
        "# Загружаем описание личности человека для каждого типа из книги Джо Наварро \"Опасные личности\"\n",
        "for danger_type in danger_types:\n",
        "    with open(\"drive/MyDrive/danger_types/\" + danger_type + \".txt\", encoding=\"utf8\") as rf:\n",
        "        for text in rf.readlines():\n",
        "            for sentence in split_text(text):\n",
        "              if len(sentence) <= 5: continue\n",
        "              train_text.append(sentence.strip())\n",
        "              train_labels.append(danger_types.index(danger_type))\n",
        "\n",
        "train_text = np.array(train_text)\n",
        "train_labels = np.array(train_labels)"
      ],
      "metadata": {
        "id": "TWmmomZOcDb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text[:10]"
      ],
      "metadata": {
        "id": "HxhyLe4uj2Mx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7444cb87-e22d-4908-ba5f-86132aebceb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Из всех ярлыков, которыми модно небрежно бросаться, нарцисс – вероятно, один из самых затасканных и наименее понятных',\n",
              "       'Это популярный термин с древним происхождением (см',\n",
              "       'греческий миф о Нарциссе, который влюбился в собственное отражение), однако его истинный смысл может оставаться неясным',\n",
              "       'Многие люди считают нарциссами тех, кто, к примеру, называет своим именем отели или всегда желает быть в центре внимания – чемто вроде героя реалитиТВ',\n",
              "       'Безусловно, свет софитов любят многие',\n",
              "       'Но такого рода нарцисс, о котором мы говорим, далеко не удовлетворяется саморекламой, его поведение токсично и опасно',\n",
              "       'С этого момента я буду использовать термины нарцисс и нарциссическая личность взаимозаменяемо',\n",
              "       'Нарциссические личности заботятся только о себе, своих потребностях и своих приоритетах',\n",
              "       'В то время как и я, и вы просто ценим внимание, нарцисс жаждет его и манипулирует людьми и ситуациями, чтобы его добиться',\n",
              "       'В то время как и вы, и я усердно трудимся, чтобы добиться успеха, нарциссическая личность ловчит, мошенничает, лжет, приукрашивает правду или составляет преступные схемы ради своего процветания, не заботясь о том, как это повлияет на других людей'],\n",
              "      dtype='<U393')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_text = []; val_labels = []\n",
        "\n",
        "# Загружаем описание личности человека для каждого вектора из книги В.К. Толкачева\n",
        "for danger_type in danger_types:\n",
        "    rf = None\n",
        "    if danger_type == 'type1':\n",
        "        rf = open(\"drive/MyDrive/val/Чарлз Дарвин.txt\", encoding=\"utf8\")\n",
        "    elif danger_type == 'type4':\n",
        "        rf = open(\"drive/MyDrive/val/Потрошитель.txt\", encoding=\"utf8\")\n",
        "    else:\n",
        "        rf = open(\"drive/MyDrive/danger_types/\" + danger_type + \".txt\", encoding=\"utf8\")\n",
        "\n",
        "    for text in rf.readlines():\n",
        "        for sentence in split_text(text):\n",
        "            if len(sentence) <= 5: continue\n",
        "            val_text.append(sentence.strip())\n",
        "            val_labels.append(danger_types.index(danger_type))\n",
        "\n",
        "    rf.close()\n",
        "\n",
        "val_text = np.array(val_text)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "_, val_text, _, val_labels = train_test_split(val_text, val_labels, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "ROaglS0jhXmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(val_labels)"
      ],
      "metadata": {
        "id": "XxPuKPSsmWcY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aed1ba0-b565-45a1-88bc-f4f723748564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RWE1dcQ8ZscG"
      },
      "cell_type": "code",
      "source": [
        "#train_text, val_text, train_labels, val_labels = train_test_split(df_vectors['description'], df_vectors['vectorId'],\n",
        "#                                                                    random_state=2018,\n",
        "#                                                                    test_size=0.2,\n",
        "#                                                                   stratify=df_vectors['vectorId'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "6C6JhRwdZscG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "7c20d079547a4ff499e9c8dbe593ddd5",
            "f52749b7928243719e5c24636b7777cb",
            "1fa094dc9934424aa981c19ced54c067",
            "4a6501ae90a54ef88e54b004867d0def",
            "ffd41e4f15674e6f9d2292b641965398",
            "7279b8e89aa144fdb9c723cd8a67dfb3",
            "9f7973c086484a89aea6113577bb9487",
            "c697228244e541d4a877baf1b8542f81",
            "b29629e162044d1484bedbbe83f35c52",
            "0a017b3cd9804034bfa034061846746a",
            "e401c83fb5764f199fdf267946daa525",
            "fcc06bce3684481fae59673d5a797e28",
            "7715db69e778468e8a6c424ebff56c97",
            "6b958cf46ebc4170b92a027f68637e4f",
            "c65fb93cd0014b508b220f24c33cc774",
            "15b08ce233f74f21a6d94ac366376f36",
            "d417b89160a2437c90868ee784c7564a",
            "77ec1ee59ff04bdaa2838e98c7dfbb8e",
            "44e8bd1c2efb4547ad952eb5d06b39bd",
            "185393076ccd4434a8e7d9582a559b93",
            "b94d824494514f2aac56081c368e7029",
            "9fe55d5660da4e65a73e4647511095f8",
            "2f3e4d569c9346fd83793ddac12d330a",
            "37891755c15b4c50a66bc1f8d1a71d14",
            "79fc09d63b9143ccbccba7b4d9f55e86",
            "56c8ce486a7642e6bc2d0b72861dc075",
            "29268585f7d44c87ab9d39ad041310e1",
            "dc73f69d7d754f01a7fe0343bb259339",
            "224ccf326d784786bf9aba6ae3a74c2b",
            "5d0fc3d9060c4d9e85a265ce08a4437d",
            "9f0f2e50ada6415c96605f9d259cf1f9",
            "d56b83b03044443ca31ca67fbef05d3a",
            "fc8c212ce9cd4819b5396dd03970a9da"
          ]
        },
        "outputId": "ce8ad512-e082-4eae-9403-661f9f6f37a5"
      },
      "cell_type": "code",
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"sberbank-ai/ruBert-base\")\n",
        "bert = BertModel.from_pretrained(\"sberbank-ai/ruBert-base\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c20d079547a4ff499e9c8dbe593ddd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/590 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcc06bce3684481fae59673d5a797e28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/716M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f3e4d569c9346fd83793ddac12d330a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at sberbank-ai/ruBert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yILCzqK0ZscH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "7bc5f759-d4a4-4362-8a3e-73ba5af47271"
      },
      "cell_type": "code",
      "source": [
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)\n",
        "max_seq_len = max(seq_len)\n",
        "print(max_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pcgvy8wEZscI"
      },
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "if max_seq_len>512:\n",
        "    max_seq_len = 512\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "JfqOwHiEZscI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8d3da6-7338-404f-ea90-6a5afd63b80f"
      },
      "cell_type": "code",
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "print(\"train_y:\",train_y)\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "print(\"val_y:\",val_y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_y: tensor([0, 0, 0,  ..., 3, 3, 3])\n",
            "val_y: tensor([2, 3, 3,  ..., 3, 0, 3])\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "R628lET0ZscJ"
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 16\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Ae32U8K6ZscJ"
      },
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "VOYdFmb5ZscK"
      },
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert, num_classes):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        self.bert = bert\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # relu activation function\n",
        "        self.relu =  nn.ReLU()\n",
        "\n",
        "        # dense layer 1\n",
        "        self.fc1 = nn.Linear(768, 512)\n",
        "\n",
        "        # dense layer 2 (Output layer)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "        #softmax activation function\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "        #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "        #pass the inputs to the model\n",
        "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "\n",
        "        x = self.fc1(cls_hs)\n",
        "\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # output layer\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # apply softmax activation\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Lm02pGy6ZscK"
      },
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert, len(danger_types))\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "r6o4tHfKZscK"
      },
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "WMgjhIwmZscK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ba12f8-e33f-40e4-9728-dad126dbd33c"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.98125837 1.00825309 1.21357616 0.85831382]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "iHmtEjhUZscL"
      },
      "cell_type": "code",
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "F7cf-cFrZscL"
      },
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "    total_labels =[]\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "        # append the model predictions\n",
        "        total_preds+=list(preds)\n",
        "        total_labels+=labels.tolist()\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
        "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hpwv7x0gZscL"
      },
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "    total_labels = []\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "\n",
        "          # Calculate elapsed time in minutes.\n",
        "          #elapsed = format_time(time.time() - t0)\n",
        "\n",
        "          # Report progress.\n",
        "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            preds = model(sent_id, mask)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            preds = np.argmax(preds, axis=1)\n",
        "            total_preds+=list(preds)\n",
        "            total_labels+=labels.tolist()\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
        "    return avg_loss, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "cUK72dHnZscL"
      },
      "cell_type": "code",
      "source": [
        "def save_checkpoint(filename, epoch, model, optimizer, label_map, id2label):\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'model': model,\n",
        "        'optimizer': optimizer,\n",
        "        'label_map': label_map,\n",
        "        'id_map':id2label}\n",
        "    torch.save(state, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IYaQ0CKeZscM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52e2ca9d-a1a8-42ee-cbc1-1092c87cfa2b"
      },
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_train_loss = float('inf')\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, f1_train = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, f1_valid = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if train_loss < best_train_loss:\n",
        "        best_train_loss = train_loss\n",
        "        file_name = 'drive/MyDrive/BERT/model_weights_danger.pt'\n",
        "        save_checkpoint(file_name, epoch, model, optimizer, label_map, id2label)\n",
        "\n",
        "    if valid_loss < best_val_loss:\n",
        "        best_val_loss = valid_loss\n",
        "        file_name = 'drive/MyDrive/BERT/model_weights_danger_val.pt'\n",
        "        save_checkpoint(file_name, epoch, model, optimizer, label_map, id2label)\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "    print(f'\\nTraining F1: {f1_train:.3f}')\n",
        "    print(f'Validation F1: {f1_valid:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            " Epoch 22 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 1.048\n",
            "Validation Loss: 0.947\n",
            "\n",
            "Training F1: 0.550\n",
            "Validation F1: 0.650\n",
            "\n",
            " Epoch 23 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 1.026\n",
            "Validation Loss: 1.454\n",
            "\n",
            "Training F1: 0.562\n",
            "Validation F1: 0.387\n",
            "\n",
            " Epoch 24 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 1.012\n",
            "Validation Loss: 1.028\n",
            "\n",
            "Training F1: 0.565\n",
            "Validation F1: 0.598\n",
            "\n",
            " Epoch 25 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 1.028\n",
            "Validation Loss: 1.043\n",
            "\n",
            "Training F1: 0.560\n",
            "Validation F1: 0.601\n",
            "\n",
            " Epoch 26 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 1.011\n",
            "Validation Loss: 0.952\n",
            "\n",
            "Training F1: 0.559\n",
            "Validation F1: 0.643\n",
            "\n",
            " Epoch 27 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.995\n",
            "Validation Loss: 1.074\n",
            "\n",
            "Training F1: 0.581\n",
            "Validation F1: 0.606\n",
            "\n",
            " Epoch 28 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.988\n",
            "Validation Loss: 1.052\n",
            "\n",
            "Training F1: 0.586\n",
            "Validation F1: 0.588\n",
            "\n",
            " Epoch 29 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.998\n",
            "Validation Loss: 1.104\n",
            "\n",
            "Training F1: 0.576\n",
            "Validation F1: 0.569\n",
            "\n",
            " Epoch 30 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.960\n",
            "Validation Loss: 1.054\n",
            "\n",
            "Training F1: 0.602\n",
            "Validation F1: 0.582\n",
            "\n",
            " Epoch 31 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.955\n",
            "Validation Loss: 1.162\n",
            "\n",
            "Training F1: 0.586\n",
            "Validation F1: 0.524\n",
            "\n",
            " Epoch 32 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.931\n",
            "Validation Loss: 1.239\n",
            "\n",
            "Training F1: 0.602\n",
            "Validation F1: 0.477\n",
            "\n",
            " Epoch 33 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.951\n",
            "Validation Loss: 0.903\n",
            "\n",
            "Training F1: 0.596\n",
            "Validation F1: 0.677\n",
            "\n",
            " Epoch 34 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.926\n",
            "Validation Loss: 1.239\n",
            "\n",
            "Training F1: 0.605\n",
            "Validation F1: 0.509\n",
            "\n",
            " Epoch 35 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.933\n",
            "Validation Loss: 0.959\n",
            "\n",
            "Training F1: 0.603\n",
            "Validation F1: 0.636\n",
            "\n",
            " Epoch 36 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.914\n",
            "Validation Loss: 1.000\n",
            "\n",
            "Training F1: 0.617\n",
            "Validation F1: 0.639\n",
            "\n",
            " Epoch 37 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.921\n",
            "Validation Loss: 1.159\n",
            "\n",
            "Training F1: 0.611\n",
            "Validation F1: 0.561\n",
            "\n",
            " Epoch 38 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.900\n",
            "Validation Loss: 1.143\n",
            "\n",
            "Training F1: 0.619\n",
            "Validation F1: 0.505\n",
            "\n",
            " Epoch 39 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.885\n",
            "Validation Loss: 1.094\n",
            "\n",
            "Training F1: 0.631\n",
            "Validation F1: 0.593\n",
            "\n",
            " Epoch 40 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.895\n",
            "Validation Loss: 0.973\n",
            "\n",
            "Training F1: 0.623\n",
            "Validation F1: 0.627\n",
            "\n",
            " Epoch 41 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.909\n",
            "Validation Loss: 0.936\n",
            "\n",
            "Training F1: 0.620\n",
            "Validation F1: 0.656\n",
            "\n",
            " Epoch 42 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.864\n",
            "Validation Loss: 1.049\n",
            "\n",
            "Training F1: 0.650\n",
            "Validation F1: 0.598\n",
            "\n",
            " Epoch 43 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.857\n",
            "Validation Loss: 1.034\n",
            "\n",
            "Training F1: 0.635\n",
            "Validation F1: 0.622\n",
            "\n",
            " Epoch 44 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.853\n",
            "Validation Loss: 1.000\n",
            "\n",
            "Training F1: 0.646\n",
            "Validation F1: 0.608\n",
            "\n",
            " Epoch 45 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.858\n",
            "Validation Loss: 1.313\n",
            "\n",
            "Training F1: 0.642\n",
            "Validation F1: 0.476\n",
            "\n",
            " Epoch 46 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.842\n",
            "Validation Loss: 1.106\n",
            "\n",
            "Training F1: 0.654\n",
            "Validation F1: 0.587\n",
            "\n",
            " Epoch 47 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.832\n",
            "Validation Loss: 1.051\n",
            "\n",
            "Training F1: 0.651\n",
            "Validation F1: 0.585\n",
            "\n",
            " Epoch 48 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.858\n",
            "Validation Loss: 1.196\n",
            "\n",
            "Training F1: 0.641\n",
            "Validation F1: 0.526\n",
            "\n",
            " Epoch 49 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.851\n",
            "Validation Loss: 1.110\n",
            "\n",
            "Training F1: 0.653\n",
            "Validation F1: 0.560\n",
            "\n",
            " Epoch 50 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.831\n",
            "Validation Loss: 1.094\n",
            "\n",
            "Training F1: 0.649\n",
            "Validation F1: 0.578\n",
            "\n",
            " Epoch 51 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.812\n",
            "Validation Loss: 0.999\n",
            "\n",
            "Training F1: 0.668\n",
            "Validation F1: 0.641\n",
            "\n",
            " Epoch 52 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.844\n",
            "Validation Loss: 0.992\n",
            "\n",
            "Training F1: 0.646\n",
            "Validation F1: 0.636\n",
            "\n",
            " Epoch 53 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.807\n",
            "Validation Loss: 1.232\n",
            "\n",
            "Training F1: 0.661\n",
            "Validation F1: 0.542\n",
            "\n",
            " Epoch 54 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.782\n",
            "Validation Loss: 1.102\n",
            "\n",
            "Training F1: 0.669\n",
            "Validation F1: 0.594\n",
            "\n",
            " Epoch 55 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.793\n",
            "Validation Loss: 1.235\n",
            "\n",
            "Training F1: 0.664\n",
            "Validation F1: 0.527\n",
            "\n",
            " Epoch 56 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.782\n",
            "Validation Loss: 1.043\n",
            "\n",
            "Training F1: 0.669\n",
            "Validation F1: 0.613\n",
            "\n",
            " Epoch 57 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.769\n",
            "Validation Loss: 1.034\n",
            "\n",
            "Training F1: 0.689\n",
            "Validation F1: 0.630\n",
            "\n",
            " Epoch 58 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.793\n",
            "Validation Loss: 1.251\n",
            "\n",
            "Training F1: 0.680\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 59 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.763\n",
            "Validation Loss: 1.112\n",
            "\n",
            "Training F1: 0.681\n",
            "Validation F1: 0.589\n",
            "\n",
            " Epoch 60 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.762\n",
            "Validation Loss: 1.216\n",
            "\n",
            "Training F1: 0.694\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 61 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.778\n",
            "Validation Loss: 0.956\n",
            "\n",
            "Training F1: 0.683\n",
            "Validation F1: 0.653\n",
            "\n",
            " Epoch 62 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.761\n",
            "Validation Loss: 1.131\n",
            "\n",
            "Training F1: 0.676\n",
            "Validation F1: 0.593\n",
            "\n",
            " Epoch 63 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.749\n",
            "Validation Loss: 1.154\n",
            "\n",
            "Training F1: 0.694\n",
            "Validation F1: 0.587\n",
            "\n",
            " Epoch 64 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.733\n",
            "Validation Loss: 1.154\n",
            "\n",
            "Training F1: 0.695\n",
            "Validation F1: 0.583\n",
            "\n",
            " Epoch 65 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.731\n",
            "Validation Loss: 1.208\n",
            "\n",
            "Training F1: 0.700\n",
            "Validation F1: 0.550\n",
            "\n",
            " Epoch 66 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.735\n",
            "Validation Loss: 1.084\n",
            "\n",
            "Training F1: 0.702\n",
            "Validation F1: 0.608\n",
            "\n",
            " Epoch 67 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.745\n",
            "Validation Loss: 1.386\n",
            "\n",
            "Training F1: 0.697\n",
            "Validation F1: 0.495\n",
            "\n",
            " Epoch 68 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.714\n",
            "Validation Loss: 1.051\n",
            "\n",
            "Training F1: 0.709\n",
            "Validation F1: 0.625\n",
            "\n",
            " Epoch 69 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.724\n",
            "Validation Loss: 1.067\n",
            "\n",
            "Training F1: 0.724\n",
            "Validation F1: 0.620\n",
            "\n",
            " Epoch 70 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.723\n",
            "Validation Loss: 1.158\n",
            "\n",
            "Training F1: 0.698\n",
            "Validation F1: 0.587\n",
            "\n",
            " Epoch 71 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.740\n",
            "Validation Loss: 1.118\n",
            "\n",
            "Training F1: 0.696\n",
            "Validation F1: 0.574\n",
            "\n",
            " Epoch 72 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.714\n",
            "Validation Loss: 1.138\n",
            "\n",
            "Training F1: 0.704\n",
            "Validation F1: 0.577\n",
            "\n",
            " Epoch 73 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.713\n",
            "Validation Loss: 1.262\n",
            "\n",
            "Training F1: 0.694\n",
            "Validation F1: 0.560\n",
            "\n",
            " Epoch 74 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.699\n",
            "Validation Loss: 1.255\n",
            "\n",
            "Training F1: 0.706\n",
            "Validation F1: 0.551\n",
            "\n",
            " Epoch 75 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.716\n",
            "Validation Loss: 1.396\n",
            "\n",
            "Training F1: 0.712\n",
            "Validation F1: 0.500\n",
            "\n",
            " Epoch 76 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.715\n",
            "Validation Loss: 1.237\n",
            "\n",
            "Training F1: 0.707\n",
            "Validation F1: 0.569\n",
            "\n",
            " Epoch 77 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.720\n",
            "Validation Loss: 1.244\n",
            "\n",
            "Training F1: 0.699\n",
            "Validation F1: 0.576\n",
            "\n",
            " Epoch 78 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.684\n",
            "Validation Loss: 1.424\n",
            "\n",
            "Training F1: 0.713\n",
            "Validation F1: 0.511\n",
            "\n",
            " Epoch 79 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.670\n",
            "Validation Loss: 1.205\n",
            "\n",
            "Training F1: 0.727\n",
            "Validation F1: 0.581\n",
            "\n",
            " Epoch 80 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.682\n",
            "Validation Loss: 1.252\n",
            "\n",
            "Training F1: 0.719\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 81 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.699\n",
            "Validation Loss: 1.254\n",
            "\n",
            "Training F1: 0.727\n",
            "Validation F1: 0.549\n",
            "\n",
            " Epoch 82 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.673\n",
            "Validation Loss: 1.185\n",
            "\n",
            "Training F1: 0.729\n",
            "Validation F1: 0.573\n",
            "\n",
            " Epoch 83 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.671\n",
            "Validation Loss: 1.393\n",
            "\n",
            "Training F1: 0.721\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 84 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.687\n",
            "Validation Loss: 1.180\n",
            "\n",
            "Training F1: 0.710\n",
            "Validation F1: 0.593\n",
            "\n",
            " Epoch 85 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.652\n",
            "Validation Loss: 1.437\n",
            "\n",
            "Training F1: 0.730\n",
            "Validation F1: 0.509\n",
            "\n",
            " Epoch 86 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.633\n",
            "Validation Loss: 1.480\n",
            "\n",
            "Training F1: 0.732\n",
            "Validation F1: 0.509\n",
            "\n",
            " Epoch 87 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.653\n",
            "Validation Loss: 1.329\n",
            "\n",
            "Training F1: 0.734\n",
            "Validation F1: 0.532\n",
            "\n",
            " Epoch 88 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.673\n",
            "Validation Loss: 1.332\n",
            "\n",
            "Training F1: 0.724\n",
            "Validation F1: 0.531\n",
            "\n",
            " Epoch 89 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.667\n",
            "Validation Loss: 1.159\n",
            "\n",
            "Training F1: 0.734\n",
            "Validation F1: 0.607\n",
            "\n",
            " Epoch 90 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.663\n",
            "Validation Loss: 1.340\n",
            "\n",
            "Training F1: 0.731\n",
            "Validation F1: 0.540\n",
            "\n",
            " Epoch 91 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.654\n",
            "Validation Loss: 1.383\n",
            "\n",
            "Training F1: 0.736\n",
            "Validation F1: 0.528\n",
            "\n",
            " Epoch 92 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.675\n",
            "Validation Loss: 1.546\n",
            "\n",
            "Training F1: 0.729\n",
            "Validation F1: 0.477\n",
            "\n",
            " Epoch 93 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.635\n",
            "Validation Loss: 1.549\n",
            "\n",
            "Training F1: 0.738\n",
            "Validation F1: 0.446\n",
            "\n",
            " Epoch 94 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.632\n",
            "Validation Loss: 1.320\n",
            "\n",
            "Training F1: 0.747\n",
            "Validation F1: 0.530\n",
            "\n",
            " Epoch 95 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.643\n",
            "Validation Loss: 1.267\n",
            "\n",
            "Training F1: 0.737\n",
            "Validation F1: 0.570\n",
            "\n",
            " Epoch 96 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.621\n",
            "Validation Loss: 1.040\n",
            "\n",
            "Training F1: 0.750\n",
            "Validation F1: 0.655\n",
            "\n",
            " Epoch 97 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.630\n",
            "Validation Loss: 1.237\n",
            "\n",
            "Training F1: 0.751\n",
            "Validation F1: 0.573\n",
            "\n",
            " Epoch 98 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.629\n",
            "Validation Loss: 1.132\n",
            "\n",
            "Training F1: 0.737\n",
            "Validation F1: 0.623\n",
            "\n",
            " Epoch 99 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.638\n",
            "Validation Loss: 1.402\n",
            "\n",
            "Training F1: 0.742\n",
            "Validation F1: 0.528\n",
            "\n",
            " Epoch 100 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.652\n",
            "Validation Loss: 1.357\n",
            "\n",
            "Training F1: 0.736\n",
            "Validation F1: 0.560\n",
            "\n",
            " Epoch 101 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.649\n",
            "Validation Loss: 1.277\n",
            "\n",
            "Training F1: 0.733\n",
            "Validation F1: 0.559\n",
            "\n",
            " Epoch 102 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.646\n",
            "Validation Loss: 1.568\n",
            "\n",
            "Training F1: 0.746\n",
            "Validation F1: 0.476\n",
            "\n",
            " Epoch 103 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.628\n",
            "Validation Loss: 1.253\n",
            "\n",
            "Training F1: 0.739\n",
            "Validation F1: 0.580\n",
            "\n",
            " Epoch 104 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.640\n",
            "Validation Loss: 1.536\n",
            "\n",
            "Training F1: 0.728\n",
            "Validation F1: 0.517\n",
            "\n",
            " Epoch 105 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.605\n",
            "Validation Loss: 1.403\n",
            "\n",
            "Training F1: 0.754\n",
            "Validation F1: 0.503\n",
            "\n",
            " Epoch 106 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.597\n",
            "Validation Loss: 1.389\n",
            "\n",
            "Training F1: 0.763\n",
            "Validation F1: 0.552\n",
            "\n",
            " Epoch 107 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.611\n",
            "Validation Loss: 1.621\n",
            "\n",
            "Training F1: 0.762\n",
            "Validation F1: 0.499\n",
            "\n",
            " Epoch 108 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.598\n",
            "Validation Loss: 1.656\n",
            "\n",
            "Training F1: 0.755\n",
            "Validation F1: 0.490\n",
            "\n",
            " Epoch 109 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.613\n",
            "Validation Loss: 1.424\n",
            "\n",
            "Training F1: 0.755\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 110 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.614\n",
            "Validation Loss: 1.315\n",
            "\n",
            "Training F1: 0.755\n",
            "Validation F1: 0.569\n",
            "\n",
            " Epoch 111 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.599\n",
            "Validation Loss: 1.273\n",
            "\n",
            "Training F1: 0.762\n",
            "Validation F1: 0.573\n",
            "\n",
            " Epoch 112 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.574\n",
            "Validation Loss: 1.214\n",
            "\n",
            "Training F1: 0.774\n",
            "Validation F1: 0.616\n",
            "\n",
            " Epoch 113 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.600\n",
            "Validation Loss: 1.894\n",
            "\n",
            "Training F1: 0.757\n",
            "Validation F1: 0.419\n",
            "\n",
            " Epoch 114 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.600\n",
            "Validation Loss: 1.470\n",
            "\n",
            "Training F1: 0.755\n",
            "Validation F1: 0.518\n",
            "\n",
            " Epoch 115 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.605\n",
            "Validation Loss: 1.400\n",
            "\n",
            "Training F1: 0.761\n",
            "Validation F1: 0.533\n",
            "\n",
            " Epoch 116 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.597\n",
            "Validation Loss: 1.446\n",
            "\n",
            "Training F1: 0.761\n",
            "Validation F1: 0.543\n",
            "\n",
            " Epoch 117 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.584\n",
            "Validation Loss: 1.189\n",
            "\n",
            "Training F1: 0.770\n",
            "Validation F1: 0.598\n",
            "\n",
            " Epoch 118 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.585\n",
            "Validation Loss: 1.417\n",
            "\n",
            "Training F1: 0.767\n",
            "Validation F1: 0.535\n",
            "\n",
            " Epoch 119 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.587\n",
            "Validation Loss: 1.464\n",
            "\n",
            "Training F1: 0.764\n",
            "Validation F1: 0.533\n",
            "\n",
            " Epoch 120 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.571\n",
            "Validation Loss: 1.664\n",
            "\n",
            "Training F1: 0.780\n",
            "Validation F1: 0.489\n",
            "\n",
            " Epoch 121 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.587\n",
            "Validation Loss: 1.587\n",
            "\n",
            "Training F1: 0.769\n",
            "Validation F1: 0.493\n",
            "\n",
            " Epoch 122 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.569\n",
            "Validation Loss: 1.304\n",
            "\n",
            "Training F1: 0.766\n",
            "Validation F1: 0.568\n",
            "\n",
            " Epoch 123 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.583\n",
            "Validation Loss: 1.317\n",
            "\n",
            "Training F1: 0.759\n",
            "Validation F1: 0.589\n",
            "\n",
            " Epoch 124 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.572\n",
            "Validation Loss: 1.547\n",
            "\n",
            "Training F1: 0.767\n",
            "Validation F1: 0.488\n",
            "\n",
            " Epoch 125 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.561\n",
            "Validation Loss: 1.744\n",
            "\n",
            "Training F1: 0.776\n",
            "Validation F1: 0.468\n",
            "\n",
            " Epoch 126 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.557\n",
            "Validation Loss: 1.232\n",
            "\n",
            "Training F1: 0.778\n",
            "Validation F1: 0.619\n",
            "\n",
            " Epoch 127 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.565\n",
            "Validation Loss: 1.427\n",
            "\n",
            "Training F1: 0.769\n",
            "Validation F1: 0.564\n",
            "\n",
            " Epoch 128 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.563\n",
            "Validation Loss: 1.813\n",
            "\n",
            "Training F1: 0.763\n",
            "Validation F1: 0.417\n",
            "\n",
            " Epoch 129 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.576\n",
            "Validation Loss: 1.291\n",
            "\n",
            "Training F1: 0.778\n",
            "Validation F1: 0.594\n",
            "\n",
            " Epoch 130 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.546\n",
            "Validation Loss: 1.579\n",
            "\n",
            "Training F1: 0.780\n",
            "Validation F1: 0.517\n",
            "\n",
            " Epoch 131 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.569\n",
            "Validation Loss: 1.514\n",
            "\n",
            "Training F1: 0.767\n",
            "Validation F1: 0.521\n",
            "\n",
            " Epoch 132 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.564\n",
            "Validation Loss: 1.277\n",
            "\n",
            "Training F1: 0.777\n",
            "Validation F1: 0.582\n",
            "\n",
            " Epoch 133 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.586\n",
            "Validation Loss: 1.373\n",
            "\n",
            "Training F1: 0.762\n",
            "Validation F1: 0.556\n",
            "\n",
            " Epoch 134 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.566\n",
            "Validation Loss: 1.583\n",
            "\n",
            "Training F1: 0.770\n",
            "Validation F1: 0.500\n",
            "\n",
            " Epoch 135 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.541\n",
            "Validation Loss: 1.438\n",
            "\n",
            "Training F1: 0.775\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 136 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.541\n",
            "Validation Loss: 1.388\n",
            "\n",
            "Training F1: 0.785\n",
            "Validation F1: 0.545\n",
            "\n",
            " Epoch 137 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.545\n",
            "Validation Loss: 1.286\n",
            "\n",
            "Training F1: 0.781\n",
            "Validation F1: 0.601\n",
            "\n",
            " Epoch 138 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.542\n",
            "Validation Loss: 1.323\n",
            "\n",
            "Training F1: 0.784\n",
            "Validation F1: 0.607\n",
            "\n",
            " Epoch 139 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.537\n",
            "Validation Loss: 1.713\n",
            "\n",
            "Training F1: 0.786\n",
            "Validation F1: 0.493\n",
            "\n",
            " Epoch 140 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.539\n",
            "Validation Loss: 1.111\n",
            "\n",
            "Training F1: 0.795\n",
            "Validation F1: 0.649\n",
            "\n",
            " Epoch 141 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.560\n",
            "Validation Loss: 1.360\n",
            "\n",
            "Training F1: 0.772\n",
            "Validation F1: 0.545\n",
            "\n",
            " Epoch 142 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.535\n",
            "Validation Loss: 1.361\n",
            "\n",
            "Training F1: 0.787\n",
            "Validation F1: 0.575\n",
            "\n",
            " Epoch 143 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.532\n",
            "Validation Loss: 1.251\n",
            "\n",
            "Training F1: 0.782\n",
            "Validation F1: 0.613\n",
            "\n",
            " Epoch 144 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.528\n",
            "Validation Loss: 1.364\n",
            "\n",
            "Training F1: 0.791\n",
            "Validation F1: 0.553\n",
            "\n",
            " Epoch 145 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.531\n",
            "Validation Loss: 1.302\n",
            "\n",
            "Training F1: 0.782\n",
            "Validation F1: 0.582\n",
            "\n",
            " Epoch 146 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.553\n",
            "Validation Loss: 1.463\n",
            "\n",
            "Training F1: 0.781\n",
            "Validation F1: 0.518\n",
            "\n",
            " Epoch 147 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.556\n",
            "Validation Loss: 1.372\n",
            "\n",
            "Training F1: 0.780\n",
            "Validation F1: 0.579\n",
            "\n",
            " Epoch 148 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.524\n",
            "Validation Loss: 1.217\n",
            "\n",
            "Training F1: 0.790\n",
            "Validation F1: 0.629\n",
            "\n",
            " Epoch 149 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.548\n",
            "Validation Loss: 1.182\n",
            "\n",
            "Training F1: 0.787\n",
            "Validation F1: 0.640\n",
            "\n",
            " Epoch 150 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.521\n",
            "Validation Loss: 1.383\n",
            "\n",
            "Training F1: 0.787\n",
            "Validation F1: 0.575\n",
            "\n",
            " Epoch 151 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.528\n",
            "Validation Loss: 1.666\n",
            "\n",
            "Training F1: 0.794\n",
            "Validation F1: 0.505\n",
            "\n",
            " Epoch 152 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.522\n",
            "Validation Loss: 1.484\n",
            "\n",
            "Training F1: 0.791\n",
            "Validation F1: 0.540\n",
            "\n",
            " Epoch 153 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.515\n",
            "Validation Loss: 1.355\n",
            "\n",
            "Training F1: 0.790\n",
            "Validation F1: 0.598\n",
            "\n",
            " Epoch 154 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.527\n",
            "Validation Loss: 1.749\n",
            "\n",
            "Training F1: 0.789\n",
            "Validation F1: 0.486\n",
            "\n",
            " Epoch 155 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.502\n",
            "Validation Loss: 1.758\n",
            "\n",
            "Training F1: 0.802\n",
            "Validation F1: 0.489\n",
            "\n",
            " Epoch 156 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.516\n",
            "Validation Loss: 1.248\n",
            "\n",
            "Training F1: 0.788\n",
            "Validation F1: 0.629\n",
            "\n",
            " Epoch 157 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.508\n",
            "Validation Loss: 1.232\n",
            "\n",
            "Training F1: 0.805\n",
            "Validation F1: 0.628\n",
            "\n",
            " Epoch 158 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.526\n",
            "Validation Loss: 1.341\n",
            "\n",
            "Training F1: 0.794\n",
            "Validation F1: 0.608\n",
            "\n",
            " Epoch 159 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.508\n",
            "Validation Loss: 1.474\n",
            "\n",
            "Training F1: 0.797\n",
            "Validation F1: 0.578\n",
            "\n",
            " Epoch 160 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.508\n",
            "Validation Loss: 1.513\n",
            "\n",
            "Training F1: 0.796\n",
            "Validation F1: 0.535\n",
            "\n",
            " Epoch 161 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.512\n",
            "Validation Loss: 1.439\n",
            "\n",
            "Training F1: 0.803\n",
            "Validation F1: 0.577\n",
            "\n",
            " Epoch 162 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.542\n",
            "Validation Loss: 1.378\n",
            "\n",
            "Training F1: 0.785\n",
            "Validation F1: 0.592\n",
            "\n",
            " Epoch 163 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.524\n",
            "Validation Loss: 1.475\n",
            "\n",
            "Training F1: 0.795\n",
            "Validation F1: 0.555\n",
            "\n",
            " Epoch 164 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.513\n",
            "Validation Loss: 1.381\n",
            "\n",
            "Training F1: 0.802\n",
            "Validation F1: 0.581\n",
            "\n",
            " Epoch 165 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.516\n",
            "Validation Loss: 1.749\n",
            "\n",
            "Training F1: 0.790\n",
            "Validation F1: 0.466\n",
            "\n",
            " Epoch 166 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.531\n",
            "Validation Loss: 1.253\n",
            "\n",
            "Training F1: 0.791\n",
            "Validation F1: 0.616\n",
            "\n",
            " Epoch 167 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.524\n",
            "Validation Loss: 1.398\n",
            "\n",
            "Training F1: 0.787\n",
            "Validation F1: 0.585\n",
            "\n",
            " Epoch 168 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.523\n",
            "Validation Loss: 1.598\n",
            "\n",
            "Training F1: 0.802\n",
            "Validation F1: 0.525\n",
            "\n",
            " Epoch 169 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.502\n",
            "Validation Loss: 1.526\n",
            "\n",
            "Training F1: 0.797\n",
            "Validation F1: 0.547\n",
            "\n",
            " Epoch 170 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.503\n",
            "Validation Loss: 1.645\n",
            "\n",
            "Training F1: 0.793\n",
            "Validation F1: 0.514\n",
            "\n",
            " Epoch 171 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.510\n",
            "Validation Loss: 1.745\n",
            "\n",
            "Training F1: 0.797\n",
            "Validation F1: 0.491\n",
            "\n",
            " Epoch 172 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.488\n",
            "Validation Loss: 1.739\n",
            "\n",
            "Training F1: 0.800\n",
            "Validation F1: 0.496\n",
            "\n",
            " Epoch 173 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.513\n",
            "Validation Loss: 1.501\n",
            "\n",
            "Training F1: 0.802\n",
            "Validation F1: 0.548\n",
            "\n",
            " Epoch 174 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.507\n",
            "Validation Loss: 1.307\n",
            "\n",
            "Training F1: 0.797\n",
            "Validation F1: 0.620\n",
            "\n",
            " Epoch 175 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.513\n",
            "Validation Loss: 1.428\n",
            "\n",
            "Training F1: 0.798\n",
            "Validation F1: 0.587\n",
            "\n",
            " Epoch 176 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.481\n",
            "Validation Loss: 1.624\n",
            "\n",
            "Training F1: 0.816\n",
            "Validation F1: 0.530\n",
            "\n",
            " Epoch 177 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.467\n",
            "Validation Loss: 1.425\n",
            "\n",
            "Training F1: 0.817\n",
            "Validation F1: 0.590\n",
            "\n",
            " Epoch 178 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.503\n",
            "Validation Loss: 1.326\n",
            "\n",
            "Training F1: 0.802\n",
            "Validation F1: 0.626\n",
            "\n",
            " Epoch 179 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.514\n",
            "Validation Loss: 1.799\n",
            "\n",
            "Training F1: 0.803\n",
            "Validation F1: 0.524\n",
            "\n",
            " Epoch 180 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.477\n",
            "Validation Loss: 1.385\n",
            "\n",
            "Training F1: 0.809\n",
            "Validation F1: 0.583\n",
            "\n",
            " Epoch 181 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.477\n",
            "Validation Loss: 1.634\n",
            "\n",
            "Training F1: 0.812\n",
            "Validation F1: 0.529\n",
            "\n",
            " Epoch 182 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.484\n",
            "Validation Loss: 2.066\n",
            "\n",
            "Training F1: 0.816\n",
            "Validation F1: 0.454\n",
            "\n",
            " Epoch 183 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.477\n",
            "Validation Loss: 1.663\n",
            "\n",
            "Training F1: 0.811\n",
            "Validation F1: 0.558\n",
            "\n",
            " Epoch 184 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.480\n",
            "Validation Loss: 1.672\n",
            "\n",
            "Training F1: 0.805\n",
            "Validation F1: 0.535\n",
            "\n",
            " Epoch 185 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.493\n",
            "Validation Loss: 1.829\n",
            "\n",
            "Training F1: 0.808\n",
            "Validation F1: 0.493\n",
            "\n",
            " Epoch 186 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.468\n",
            "Validation Loss: 1.726\n",
            "\n",
            "Training F1: 0.811\n",
            "Validation F1: 0.502\n",
            "\n",
            " Epoch 187 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.476\n",
            "Validation Loss: 1.595\n",
            "\n",
            "Training F1: 0.809\n",
            "Validation F1: 0.558\n",
            "\n",
            " Epoch 188 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.490\n",
            "Validation Loss: 1.428\n",
            "\n",
            "Training F1: 0.807\n",
            "Validation F1: 0.599\n",
            "\n",
            " Epoch 189 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.485\n",
            "Validation Loss: 1.699\n",
            "\n",
            "Training F1: 0.810\n",
            "Validation F1: 0.513\n",
            "\n",
            " Epoch 190 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.490\n",
            "Validation Loss: 1.651\n",
            "\n",
            "Training F1: 0.807\n",
            "Validation F1: 0.556\n",
            "\n",
            " Epoch 191 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.506\n",
            "Validation Loss: 1.757\n",
            "\n",
            "Training F1: 0.802\n",
            "Validation F1: 0.467\n",
            "\n",
            " Epoch 192 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.473\n",
            "Validation Loss: 1.233\n",
            "\n",
            "Training F1: 0.811\n",
            "Validation F1: 0.651\n",
            "\n",
            " Epoch 193 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.484\n",
            "Validation Loss: 1.457\n",
            "\n",
            "Training F1: 0.807\n",
            "Validation F1: 0.583\n",
            "\n",
            " Epoch 194 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.458\n",
            "Validation Loss: 1.648\n",
            "\n",
            "Training F1: 0.818\n",
            "Validation F1: 0.560\n",
            "\n",
            " Epoch 195 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.470\n",
            "Validation Loss: 1.757\n",
            "\n",
            "Training F1: 0.813\n",
            "Validation F1: 0.525\n",
            "\n",
            " Epoch 196 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.485\n",
            "Validation Loss: 1.669\n",
            "\n",
            "Training F1: 0.814\n",
            "Validation F1: 0.529\n",
            "\n",
            " Epoch 197 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.457\n",
            "Validation Loss: 1.646\n",
            "\n",
            "Training F1: 0.822\n",
            "Validation F1: 0.536\n",
            "\n",
            " Epoch 198 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.482\n",
            "Validation Loss: 1.364\n",
            "\n",
            "Training F1: 0.808\n",
            "Validation F1: 0.592\n",
            "\n",
            " Epoch 199 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.481\n",
            "Validation Loss: 1.695\n",
            "\n",
            "Training F1: 0.803\n",
            "Validation F1: 0.542\n",
            "\n",
            " Epoch 200 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.466\n",
            "Validation Loss: 1.668\n",
            "\n",
            "Training F1: 0.809\n",
            "Validation F1: 0.545\n",
            "\n",
            " Epoch 201 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.480\n",
            "Validation Loss: 1.565\n",
            "\n",
            "Training F1: 0.813\n",
            "Validation F1: 0.554\n",
            "\n",
            " Epoch 202 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.477\n",
            "Validation Loss: 1.732\n",
            "\n",
            "Training F1: 0.815\n",
            "Validation F1: 0.509\n",
            "\n",
            " Epoch 203 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.463\n",
            "Validation Loss: 1.605\n",
            "\n",
            "Training F1: 0.819\n",
            "Validation F1: 0.536\n",
            "\n",
            " Epoch 204 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.473\n",
            "Validation Loss: 1.615\n",
            "\n",
            "Training F1: 0.808\n",
            "Validation F1: 0.546\n",
            "\n",
            " Epoch 205 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.484\n",
            "Validation Loss: 1.504\n",
            "\n",
            "Training F1: 0.812\n",
            "Validation F1: 0.561\n",
            "\n",
            " Epoch 206 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.479\n",
            "Validation Loss: 1.836\n",
            "\n",
            "Training F1: 0.799\n",
            "Validation F1: 0.493\n",
            "\n",
            " Epoch 207 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.475\n",
            "Validation Loss: 1.747\n",
            "\n",
            "Training F1: 0.822\n",
            "Validation F1: 0.503\n",
            "\n",
            " Epoch 208 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.499\n",
            "Validation Loss: 1.647\n",
            "\n",
            "Training F1: 0.807\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 209 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.464\n",
            "Validation Loss: 1.589\n",
            "\n",
            "Training F1: 0.812\n",
            "Validation F1: 0.547\n",
            "\n",
            " Epoch 210 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.476\n",
            "Validation Loss: 1.556\n",
            "\n",
            "Training F1: 0.816\n",
            "Validation F1: 0.555\n",
            "\n",
            " Epoch 211 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.469\n",
            "Validation Loss: 1.106\n",
            "\n",
            "Training F1: 0.815\n",
            "Validation F1: 0.677\n",
            "\n",
            " Epoch 212 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.458\n",
            "Validation Loss: 1.449\n",
            "\n",
            "Training F1: 0.823\n",
            "Validation F1: 0.578\n",
            "\n",
            " Epoch 213 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.478\n",
            "Validation Loss: 1.560\n",
            "\n",
            "Training F1: 0.810\n",
            "Validation F1: 0.569\n",
            "\n",
            " Epoch 214 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.449\n",
            "Validation Loss: 1.447\n",
            "\n",
            "Training F1: 0.827\n",
            "Validation F1: 0.596\n",
            "\n",
            " Epoch 215 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.452\n",
            "Validation Loss: 1.728\n",
            "\n",
            "Training F1: 0.816\n",
            "Validation F1: 0.554\n",
            "\n",
            " Epoch 216 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.455\n",
            "Validation Loss: 1.737\n",
            "\n",
            "Training F1: 0.823\n",
            "Validation F1: 0.545\n",
            "\n",
            " Epoch 217 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.458\n",
            "Validation Loss: 1.968\n",
            "\n",
            "Training F1: 0.815\n",
            "Validation F1: 0.511\n",
            "\n",
            " Epoch 218 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.457\n",
            "Validation Loss: 1.967\n",
            "\n",
            "Training F1: 0.822\n",
            "Validation F1: 0.445\n",
            "\n",
            " Epoch 219 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.462\n",
            "Validation Loss: 1.451\n",
            "\n",
            "Training F1: 0.811\n",
            "Validation F1: 0.561\n",
            "\n",
            " Epoch 220 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.453\n",
            "Validation Loss: 1.647\n",
            "\n",
            "Training F1: 0.823\n",
            "Validation F1: 0.553\n",
            "\n",
            " Epoch 221 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.484\n",
            "Validation Loss: 1.743\n",
            "\n",
            "Training F1: 0.820\n",
            "Validation F1: 0.532\n",
            "\n",
            " Epoch 222 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.458\n",
            "Validation Loss: 1.570\n",
            "\n",
            "Training F1: 0.820\n",
            "Validation F1: 0.565\n",
            "\n",
            " Epoch 223 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.463\n",
            "Validation Loss: 1.679\n",
            "\n",
            "Training F1: 0.824\n",
            "Validation F1: 0.540\n",
            "\n",
            " Epoch 224 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.458\n",
            "Validation Loss: 1.410\n",
            "\n",
            "Training F1: 0.823\n",
            "Validation F1: 0.587\n",
            "\n",
            " Epoch 225 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.433\n",
            "Validation Loss: 1.789\n",
            "\n",
            "Training F1: 0.831\n",
            "Validation F1: 0.516\n",
            "\n",
            " Epoch 226 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.452\n",
            "Validation Loss: 1.446\n",
            "\n",
            "Training F1: 0.819\n",
            "Validation F1: 0.585\n",
            "\n",
            " Epoch 227 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.447\n",
            "Validation Loss: 1.741\n",
            "\n",
            "Training F1: 0.829\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 228 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.477\n",
            "Validation Loss: 1.655\n",
            "\n",
            "Training F1: 0.816\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 229 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.451\n",
            "Validation Loss: 1.565\n",
            "\n",
            "Training F1: 0.822\n",
            "Validation F1: 0.557\n",
            "\n",
            " Epoch 230 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.484\n",
            "Validation Loss: 1.532\n",
            "\n",
            "Training F1: 0.815\n",
            "Validation F1: 0.580\n",
            "\n",
            " Epoch 231 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.441\n",
            "Validation Loss: 1.718\n",
            "\n",
            "Training F1: 0.829\n",
            "Validation F1: 0.525\n",
            "\n",
            " Epoch 232 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.450\n",
            "Validation Loss: 1.821\n",
            "\n",
            "Training F1: 0.822\n",
            "Validation F1: 0.530\n",
            "\n",
            " Epoch 233 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.453\n",
            "Validation Loss: 1.763\n",
            "\n",
            "Training F1: 0.830\n",
            "Validation F1: 0.537\n",
            "\n",
            " Epoch 234 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.471\n",
            "Validation Loss: 1.194\n",
            "\n",
            "Training F1: 0.819\n",
            "Validation F1: 0.663\n",
            "\n",
            " Epoch 235 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.453\n",
            "Validation Loss: 1.926\n",
            "\n",
            "Training F1: 0.813\n",
            "Validation F1: 0.489\n",
            "\n",
            " Epoch 236 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.460\n",
            "Validation Loss: 1.459\n",
            "\n",
            "Training F1: 0.824\n",
            "Validation F1: 0.575\n",
            "\n",
            " Epoch 237 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.437\n",
            "Validation Loss: 1.560\n",
            "\n",
            "Training F1: 0.824\n",
            "Validation F1: 0.585\n",
            "\n",
            " Epoch 238 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.457\n",
            "Validation Loss: 1.623\n",
            "\n",
            "Training F1: 0.823\n",
            "Validation F1: 0.548\n",
            "\n",
            " Epoch 239 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.437\n",
            "Validation Loss: 1.630\n",
            "\n",
            "Training F1: 0.830\n",
            "Validation F1: 0.561\n",
            "\n",
            " Epoch 240 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.425\n",
            "Validation Loss: 2.104\n",
            "\n",
            "Training F1: 0.834\n",
            "Validation F1: 0.497\n",
            "\n",
            " Epoch 241 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.424\n",
            "Validation Loss: 1.660\n",
            "\n",
            "Training F1: 0.836\n",
            "Validation F1: 0.546\n",
            "\n",
            " Epoch 242 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.447\n",
            "Validation Loss: 1.795\n",
            "\n",
            "Training F1: 0.819\n",
            "Validation F1: 0.499\n",
            "\n",
            " Epoch 243 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.440\n",
            "Validation Loss: 1.697\n",
            "\n",
            "Training F1: 0.834\n",
            "Validation F1: 0.554\n",
            "\n",
            " Epoch 244 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.442\n",
            "Validation Loss: 1.592\n",
            "\n",
            "Training F1: 0.822\n",
            "Validation F1: 0.554\n",
            "\n",
            " Epoch 245 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.423\n",
            "Validation Loss: 2.018\n",
            "\n",
            "Training F1: 0.840\n",
            "Validation F1: 0.509\n",
            "\n",
            " Epoch 246 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.445\n",
            "Validation Loss: 1.938\n",
            "\n",
            "Training F1: 0.823\n",
            "Validation F1: 0.489\n",
            "\n",
            " Epoch 247 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.434\n",
            "Validation Loss: 1.700\n",
            "\n",
            "Training F1: 0.834\n",
            "Validation F1: 0.563\n",
            "\n",
            " Epoch 248 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.437\n",
            "Validation Loss: 1.634\n",
            "\n",
            "Training F1: 0.830\n",
            "Validation F1: 0.560\n",
            "\n",
            " Epoch 249 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.418\n",
            "Validation Loss: 1.931\n",
            "\n",
            "Training F1: 0.834\n",
            "Validation F1: 0.513\n",
            "\n",
            " Epoch 250 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.435\n",
            "Validation Loss: 1.776\n",
            "\n",
            "Training F1: 0.827\n",
            "Validation F1: 0.518\n",
            "\n",
            " Epoch 251 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.431\n",
            "Validation Loss: 1.511\n",
            "\n",
            "Training F1: 0.833\n",
            "Validation F1: 0.580\n",
            "\n",
            " Epoch 252 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.436\n",
            "Validation Loss: 1.892\n",
            "\n",
            "Training F1: 0.828\n",
            "Validation F1: 0.494\n",
            "\n",
            " Epoch 253 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.439\n",
            "Validation Loss: 1.800\n",
            "\n",
            "Training F1: 0.830\n",
            "Validation F1: 0.522\n",
            "\n",
            " Epoch 254 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.429\n",
            "Validation Loss: 1.639\n",
            "\n",
            "Training F1: 0.830\n",
            "Validation F1: 0.575\n",
            "\n",
            " Epoch 255 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.463\n",
            "Validation Loss: 1.698\n",
            "\n",
            "Training F1: 0.824\n",
            "Validation F1: 0.548\n",
            "\n",
            " Epoch 256 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.428\n",
            "Validation Loss: 1.482\n",
            "\n",
            "Training F1: 0.830\n",
            "Validation F1: 0.570\n",
            "\n",
            " Epoch 257 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.414\n",
            "Validation Loss: 1.560\n",
            "\n",
            "Training F1: 0.830\n",
            "Validation F1: 0.587\n",
            "\n",
            " Epoch 258 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.445\n",
            "Validation Loss: 1.587\n",
            "\n",
            "Training F1: 0.824\n",
            "Validation F1: 0.594\n",
            "\n",
            " Epoch 259 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.414\n",
            "Validation Loss: 1.872\n",
            "\n",
            "Training F1: 0.836\n",
            "Validation F1: 0.520\n",
            "\n",
            " Epoch 260 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.441\n",
            "Validation Loss: 1.659\n",
            "\n",
            "Training F1: 0.824\n",
            "Validation F1: 0.549\n",
            "\n",
            " Epoch 261 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.433\n",
            "Validation Loss: 1.635\n",
            "\n",
            "Training F1: 0.834\n",
            "Validation F1: 0.556\n",
            "\n",
            " Epoch 262 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.443\n",
            "Validation Loss: 2.383\n",
            "\n",
            "Training F1: 0.830\n",
            "Validation F1: 0.424\n",
            "\n",
            " Epoch 263 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.439\n",
            "Validation Loss: 2.026\n",
            "\n",
            "Training F1: 0.832\n",
            "Validation F1: 0.479\n",
            "\n",
            " Epoch 264 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.426\n",
            "Validation Loss: 1.502\n",
            "\n",
            "Training F1: 0.825\n",
            "Validation F1: 0.594\n",
            "\n",
            " Epoch 265 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.424\n",
            "Validation Loss: 1.623\n",
            "\n",
            "Training F1: 0.836\n",
            "Validation F1: 0.569\n",
            "\n",
            " Epoch 266 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.411\n",
            "Validation Loss: 1.789\n",
            "\n",
            "Training F1: 0.834\n",
            "Validation F1: 0.520\n",
            "\n",
            " Epoch 267 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.416\n",
            "Validation Loss: 1.850\n",
            "\n",
            "Training F1: 0.836\n",
            "Validation F1: 0.537\n",
            "\n",
            " Epoch 268 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.430\n",
            "Validation Loss: 1.669\n",
            "\n",
            "Training F1: 0.827\n",
            "Validation F1: 0.584\n",
            "\n",
            " Epoch 269 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.419\n",
            "Validation Loss: 1.814\n",
            "\n",
            "Training F1: 0.834\n",
            "Validation F1: 0.528\n",
            "\n",
            " Epoch 270 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.429\n",
            "Validation Loss: 1.779\n",
            "\n",
            "Training F1: 0.831\n",
            "Validation F1: 0.543\n",
            "\n",
            " Epoch 271 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.414\n",
            "Validation Loss: 1.531\n",
            "\n",
            "Training F1: 0.839\n",
            "Validation F1: 0.613\n",
            "\n",
            " Epoch 272 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.413\n",
            "Validation Loss: 1.862\n",
            "\n",
            "Training F1: 0.838\n",
            "Validation F1: 0.522\n",
            "\n",
            " Epoch 273 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.455\n",
            "Validation Loss: 1.491\n",
            "\n",
            "Training F1: 0.819\n",
            "Validation F1: 0.598\n",
            "\n",
            " Epoch 274 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.396\n",
            "Validation Loss: 1.786\n",
            "\n",
            "Training F1: 0.842\n",
            "Validation F1: 0.550\n",
            "\n",
            " Epoch 275 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.442\n",
            "Validation Loss: 1.600\n",
            "\n",
            "Training F1: 0.831\n",
            "Validation F1: 0.594\n",
            "\n",
            " Epoch 276 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.406\n",
            "Validation Loss: 1.716\n",
            "\n",
            "Training F1: 0.838\n",
            "Validation F1: 0.572\n",
            "\n",
            " Epoch 277 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.421\n",
            "Validation Loss: 1.520\n",
            "\n",
            "Training F1: 0.829\n",
            "Validation F1: 0.610\n",
            "\n",
            " Epoch 278 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.427\n",
            "Validation Loss: 1.392\n",
            "\n",
            "Training F1: 0.833\n",
            "Validation F1: 0.640\n",
            "\n",
            " Epoch 279 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.418\n",
            "Validation Loss: 1.606\n",
            "\n",
            "Training F1: 0.833\n",
            "Validation F1: 0.595\n",
            "\n",
            " Epoch 280 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.408\n",
            "Validation Loss: 1.741\n",
            "\n",
            "Training F1: 0.843\n",
            "Validation F1: 0.568\n",
            "\n",
            " Epoch 281 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.407\n",
            "Validation Loss: 1.984\n",
            "\n",
            "Training F1: 0.840\n",
            "Validation F1: 0.503\n",
            "\n",
            " Epoch 282 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.399\n",
            "Validation Loss: 1.933\n",
            "\n",
            "Training F1: 0.840\n",
            "Validation F1: 0.532\n",
            "\n",
            " Epoch 283 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.411\n",
            "Validation Loss: 2.141\n",
            "\n",
            "Training F1: 0.835\n",
            "Validation F1: 0.488\n",
            "\n",
            " Epoch 284 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.411\n",
            "Validation Loss: 1.495\n",
            "\n",
            "Training F1: 0.836\n",
            "Validation F1: 0.614\n",
            "\n",
            " Epoch 285 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.421\n",
            "Validation Loss: 1.337\n",
            "\n",
            "Training F1: 0.836\n",
            "Validation F1: 0.632\n",
            "\n",
            " Epoch 286 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.399\n",
            "Validation Loss: 1.511\n",
            "\n",
            "Training F1: 0.848\n",
            "Validation F1: 0.627\n",
            "\n",
            " Epoch 287 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.424\n",
            "Validation Loss: 1.511\n",
            "\n",
            "Training F1: 0.835\n",
            "Validation F1: 0.602\n",
            "\n",
            " Epoch 288 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.424\n",
            "Validation Loss: 1.569\n",
            "\n",
            "Training F1: 0.835\n",
            "Validation F1: 0.607\n",
            "\n",
            " Epoch 289 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.429\n",
            "Validation Loss: 1.836\n",
            "\n",
            "Training F1: 0.837\n",
            "Validation F1: 0.533\n",
            "\n",
            " Epoch 290 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.423\n",
            "Validation Loss: 1.543\n",
            "\n",
            "Training F1: 0.824\n",
            "Validation F1: 0.590\n",
            "\n",
            " Epoch 291 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.403\n",
            "Validation Loss: 1.712\n",
            "\n",
            "Training F1: 0.845\n",
            "Validation F1: 0.549\n",
            "\n",
            " Epoch 292 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.408\n",
            "Validation Loss: 1.879\n",
            "\n",
            "Training F1: 0.842\n",
            "Validation F1: 0.562\n",
            "\n",
            " Epoch 293 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.434\n",
            "Validation Loss: 1.483\n",
            "\n",
            "Training F1: 0.831\n",
            "Validation F1: 0.604\n",
            "\n",
            " Epoch 294 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.413\n",
            "Validation Loss: 1.498\n",
            "\n",
            "Training F1: 0.850\n",
            "Validation F1: 0.618\n",
            "\n",
            " Epoch 295 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.438\n",
            "Validation Loss: 1.865\n",
            "\n",
            "Training F1: 0.829\n",
            "Validation F1: 0.560\n",
            "\n",
            " Epoch 296 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.406\n",
            "Validation Loss: 1.934\n",
            "\n",
            "Training F1: 0.841\n",
            "Validation F1: 0.504\n",
            "\n",
            " Epoch 297 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.418\n",
            "Validation Loss: 1.521\n",
            "\n",
            "Training F1: 0.840\n",
            "Validation F1: 0.608\n",
            "\n",
            " Epoch 298 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.408\n",
            "Validation Loss: 1.750\n",
            "\n",
            "Training F1: 0.841\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 299 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.403\n",
            "Validation Loss: 1.505\n",
            "\n",
            "Training F1: 0.834\n",
            "Validation F1: 0.600\n",
            "\n",
            " Epoch 300 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.430\n",
            "Validation Loss: 1.789\n",
            "\n",
            "Training F1: 0.827\n",
            "Validation F1: 0.549\n",
            "\n",
            " Epoch 301 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.389\n",
            "Validation Loss: 1.812\n",
            "\n",
            "Training F1: 0.846\n",
            "Validation F1: 0.552\n",
            "\n",
            " Epoch 302 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.379\n",
            "Validation Loss: 1.810\n",
            "\n",
            "Training F1: 0.861\n",
            "Validation F1: 0.542\n",
            "\n",
            " Epoch 303 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.392\n",
            "Validation Loss: 2.046\n",
            "\n",
            "Training F1: 0.845\n",
            "Validation F1: 0.516\n",
            "\n",
            " Epoch 304 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.393\n",
            "Validation Loss: 2.133\n",
            "\n",
            "Training F1: 0.843\n",
            "Validation F1: 0.477\n",
            "\n",
            " Epoch 305 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.419\n",
            "Validation Loss: 1.455\n",
            "\n",
            "Training F1: 0.833\n",
            "Validation F1: 0.600\n",
            "\n",
            " Epoch 306 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.399\n",
            "Validation Loss: 1.432\n",
            "\n",
            "Training F1: 0.839\n",
            "Validation F1: 0.597\n",
            "\n",
            " Epoch 307 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.422\n",
            "Validation Loss: 2.001\n",
            "\n",
            "Training F1: 0.842\n",
            "Validation F1: 0.516\n",
            "\n",
            " Epoch 308 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.409\n",
            "Validation Loss: 1.916\n",
            "\n",
            "Training F1: 0.841\n",
            "Validation F1: 0.530\n",
            "\n",
            " Epoch 309 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.408\n",
            "Validation Loss: 1.872\n",
            "\n",
            "Training F1: 0.830\n",
            "Validation F1: 0.517\n",
            "\n",
            " Epoch 310 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.410\n",
            "Validation Loss: 1.971\n",
            "\n",
            "Training F1: 0.841\n",
            "Validation F1: 0.522\n",
            "\n",
            " Epoch 311 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.415\n",
            "Validation Loss: 1.873\n",
            "\n",
            "Training F1: 0.842\n",
            "Validation F1: 0.514\n",
            "\n",
            " Epoch 312 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.408\n",
            "Validation Loss: 1.572\n",
            "\n",
            "Training F1: 0.839\n",
            "Validation F1: 0.610\n",
            "\n",
            " Epoch 313 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.394\n",
            "Validation Loss: 1.766\n",
            "\n",
            "Training F1: 0.842\n",
            "Validation F1: 0.561\n",
            "\n",
            " Epoch 314 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.357\n",
            "Validation Loss: 1.604\n",
            "\n",
            "Training F1: 0.857\n",
            "Validation F1: 0.597\n",
            "\n",
            " Epoch 315 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.398\n",
            "Validation Loss: 1.713\n",
            "\n",
            "Training F1: 0.849\n",
            "Validation F1: 0.559\n",
            "\n",
            " Epoch 316 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.402\n",
            "Validation Loss: 1.734\n",
            "\n",
            "Training F1: 0.843\n",
            "Validation F1: 0.564\n",
            "\n",
            " Epoch 317 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.388\n",
            "Validation Loss: 1.888\n",
            "\n",
            "Training F1: 0.843\n",
            "Validation F1: 0.530\n",
            "\n",
            " Epoch 318 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.387\n",
            "Validation Loss: 1.620\n",
            "\n",
            "Training F1: 0.848\n",
            "Validation F1: 0.581\n",
            "\n",
            " Epoch 319 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.390\n",
            "Validation Loss: 1.816\n",
            "\n",
            "Training F1: 0.845\n",
            "Validation F1: 0.560\n",
            "\n",
            " Epoch 320 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.426\n",
            "Validation Loss: 1.902\n",
            "\n",
            "Training F1: 0.839\n",
            "Validation F1: 0.501\n",
            "\n",
            " Epoch 321 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.396\n",
            "Validation Loss: 1.732\n",
            "\n",
            "Training F1: 0.845\n",
            "Validation F1: 0.583\n",
            "\n",
            " Epoch 322 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.406\n",
            "Validation Loss: 2.002\n",
            "\n",
            "Training F1: 0.842\n",
            "Validation F1: 0.511\n",
            "\n",
            " Epoch 323 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.404\n",
            "Validation Loss: 2.148\n",
            "\n",
            "Training F1: 0.847\n",
            "Validation F1: 0.476\n",
            "\n",
            " Epoch 324 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.388\n",
            "Validation Loss: 1.829\n",
            "\n",
            "Training F1: 0.846\n",
            "Validation F1: 0.566\n",
            "\n",
            " Epoch 325 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.390\n",
            "Validation Loss: 1.737\n",
            "\n",
            "Training F1: 0.844\n",
            "Validation F1: 0.557\n",
            "\n",
            " Epoch 326 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.376\n",
            "Validation Loss: 2.552\n",
            "\n",
            "Training F1: 0.851\n",
            "Validation F1: 0.442\n",
            "\n",
            " Epoch 327 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.412\n",
            "Validation Loss: 1.821\n",
            "\n",
            "Training F1: 0.838\n",
            "Validation F1: 0.541\n",
            "\n",
            " Epoch 328 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.397\n",
            "Validation Loss: 1.931\n",
            "\n",
            "Training F1: 0.846\n",
            "Validation F1: 0.529\n",
            "\n",
            " Epoch 329 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.399\n",
            "Validation Loss: 1.967\n",
            "\n",
            "Training F1: 0.845\n",
            "Validation F1: 0.500\n",
            "\n",
            " Epoch 330 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.404\n",
            "Validation Loss: 1.725\n",
            "\n",
            "Training F1: 0.837\n",
            "Validation F1: 0.540\n",
            "\n",
            " Epoch 331 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.396\n",
            "Validation Loss: 1.916\n",
            "\n",
            "Training F1: 0.845\n",
            "Validation F1: 0.529\n",
            "\n",
            " Epoch 332 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.410\n",
            "Validation Loss: 1.981\n",
            "\n",
            "Training F1: 0.837\n",
            "Validation F1: 0.508\n",
            "\n",
            " Epoch 333 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.389\n",
            "Validation Loss: 1.528\n",
            "\n",
            "Training F1: 0.849\n",
            "Validation F1: 0.609\n",
            "\n",
            " Epoch 334 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.404\n",
            "Validation Loss: 1.719\n",
            "\n",
            "Training F1: 0.841\n",
            "Validation F1: 0.557\n",
            "\n",
            " Epoch 335 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.406\n",
            "Validation Loss: 1.810\n",
            "\n",
            "Training F1: 0.851\n",
            "Validation F1: 0.533\n",
            "\n",
            " Epoch 336 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.384\n",
            "Validation Loss: 2.100\n",
            "\n",
            "Training F1: 0.843\n",
            "Validation F1: 0.487\n",
            "\n",
            " Epoch 337 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.372\n",
            "Validation Loss: 1.682\n",
            "\n",
            "Training F1: 0.850\n",
            "Validation F1: 0.597\n",
            "\n",
            " Epoch 338 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.396\n",
            "Validation Loss: 1.959\n",
            "\n",
            "Training F1: 0.845\n",
            "Validation F1: 0.544\n",
            "\n",
            " Epoch 339 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.389\n",
            "Validation Loss: 1.782\n",
            "\n",
            "Training F1: 0.854\n",
            "Validation F1: 0.570\n",
            "\n",
            " Epoch 340 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.402\n",
            "Validation Loss: 1.807\n",
            "\n",
            "Training F1: 0.841\n",
            "Validation F1: 0.553\n",
            "\n",
            " Epoch 341 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.395\n",
            "Validation Loss: 1.555\n",
            "\n",
            "Training F1: 0.838\n",
            "Validation F1: 0.601\n",
            "\n",
            " Epoch 342 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.379\n",
            "Validation Loss: 1.783\n",
            "\n",
            "Training F1: 0.853\n",
            "Validation F1: 0.559\n",
            "\n",
            " Epoch 343 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.382\n",
            "Validation Loss: 1.572\n",
            "\n",
            "Training F1: 0.851\n",
            "Validation F1: 0.600\n",
            "\n",
            " Epoch 344 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.367\n",
            "Validation Loss: 2.146\n",
            "\n",
            "Training F1: 0.852\n",
            "Validation F1: 0.505\n",
            "\n",
            " Epoch 345 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.394\n",
            "Validation Loss: 1.913\n",
            "\n",
            "Training F1: 0.843\n",
            "Validation F1: 0.545\n",
            "\n",
            " Epoch 346 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.394\n",
            "Validation Loss: 1.831\n",
            "\n",
            "Training F1: 0.845\n",
            "Validation F1: 0.552\n",
            "\n",
            " Epoch 347 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.396\n",
            "Validation Loss: 1.641\n",
            "\n",
            "Training F1: 0.844\n",
            "Validation F1: 0.600\n",
            "\n",
            " Epoch 348 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.388\n",
            "Validation Loss: 1.828\n",
            "\n",
            "Training F1: 0.840\n",
            "Validation F1: 0.548\n",
            "\n",
            " Epoch 349 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.388\n",
            "Validation Loss: 2.099\n",
            "\n",
            "Training F1: 0.844\n",
            "Validation F1: 0.501\n",
            "\n",
            " Epoch 350 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.394\n",
            "Validation Loss: 1.606\n",
            "\n",
            "Training F1: 0.844\n",
            "Validation F1: 0.589\n",
            "\n",
            " Epoch 351 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.374\n",
            "Validation Loss: 1.949\n",
            "\n",
            "Training F1: 0.853\n",
            "Validation F1: 0.526\n",
            "\n",
            " Epoch 352 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.383\n",
            "Validation Loss: 1.877\n",
            "\n",
            "Training F1: 0.855\n",
            "Validation F1: 0.530\n",
            "\n",
            " Epoch 353 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.419\n",
            "Validation Loss: 1.877\n",
            "\n",
            "Training F1: 0.842\n",
            "Validation F1: 0.513\n",
            "\n",
            " Epoch 354 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n",
            "  Batch   100  of    206.\n",
            "  Batch   150  of    206.\n",
            "  Batch   200  of    206.\n",
            "\n",
            "Training Loss: 0.400\n",
            "Validation Loss: 1.825\n",
            "\n",
            "Training F1: 0.841\n",
            "Validation F1: 0.539\n",
            "\n",
            " Epoch 355 / 400\n",
            "  Batch   100  of    184.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    206.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-08b2f748afc6>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#save the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-4867d61902de>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "dn8hAbOkZscM"
      },
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/BERT/model_weights.pt'\n",
        "\n",
        "checkpoint = torch.load(path, map_location=device)\n",
        "model = checkpoint.get(\"model\")\n",
        "tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-base')\n",
        "\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "test_text = []; test_labels = []\n",
        "\n",
        "# Загружаем описание личности человека для каждого вектора из книги М.В. Бородянского\n",
        "for person_vector in person_vectors:\n",
        "    with open(\"drive/MyDrive/vectors_/\" + person_vector + \".txt\", encoding=\"utf8\") as rf:\n",
        "        for sentence in split_text(rf.read().strip()):\n",
        "            if len(sentence) <= 2: continue\n",
        "            test_text.append(sentence)\n",
        "            test_labels.append(person_vectors.index(person_vector))\n",
        "\n",
        "test_text = np.array(test_text)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())\n",
        "print(\"test_y:\",test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wEvR7h6EZscM"
      },
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hThwcQugZscM"
      },
      "cell_type": "code",
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zOtcxnqrZscM"
      },
      "cell_type": "code",
      "source": [
        "class Prediction:\n",
        "    def __init__(self):\n",
        "        path = 'drive/MyDrive/BERT/model_weights.pt'\n",
        "\n",
        "        checkpoint = torch.load(path,map_location=device)\n",
        "        self.predictor = checkpoint.get(\"model\")\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-base')\n",
        "        self.tag = checkpoint.get(\"id_map\")\n",
        "\n",
        "    def predict(self,text):\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        tokens = tokens[:max_seq_len - 2]\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        input_ids = input_ids + [0] * (max_seq_len-len(input_ids))\n",
        "        input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
        "        input_ids = input_ids.to(device)\n",
        "\n",
        "        input_mask = [1]*len(tokens) + [0] * (max_seq_len - len(tokens))\n",
        "        input_mask = torch.tensor(input_mask).unsqueeze(0)\n",
        "        input_mask = input_mask.to(device)\n",
        "\n",
        "        logits = self.predictor(input_ids,input_mask)\n",
        "        prob = torch.nn.functional.softmax(logits,dim=1)\n",
        "        result = [(self.tag[idx],item) for idx,item in enumerate(prob[0].tolist())]\n",
        "        preds = logits.detach().cpu().numpy()\n",
        "        pred_val = np.argmax(preds)\n",
        "        pred_val = self.tag[pred_val]\n",
        "        return result,pred_val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "W_ClvtnbZscN"
      },
      "cell_type": "code",
      "source": [
        "pred = Prediction()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = []\n",
        "\n",
        "with open(\"drive/MyDrive/val/Основы дзэн-буддизма.txt\", encoding=\"utf8\") as rf:\n",
        "    for sentence in split_text(rf.read().strip()):\n",
        "        if len(sentence) <= 5: continue\n",
        "        text.append(sentence)\n",
        "\n",
        "text[:30]"
      ],
      "metadata": {
        "id": "tbwKhvSp5ir2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lEtm_Vh3ZscN"
      },
      "cell_type": "code",
      "source": [
        "list_input = ['Такие люди обладают ясновидением, точнее яснослышанием.']\n",
        "\n",
        "for item in list_input:\n",
        "    confidence,pred_val = pred.predict(item)\n",
        "    print(pred_val)\n",
        "    print(confidence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/BERT/model_weights.pt'\n",
        "\n",
        "checkpoint = torch.load(path, map_location=device)\n",
        "model = checkpoint.get(\"model\")\n",
        "tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-base')\n",
        "\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "test_text = []\n",
        "\n",
        "with open(\"drive/MyDrive/val/Гамлет, принц Датский - Уильям Шекспир.txt\", encoding=\"utf8\") as rf:\n",
        "    for text in rf.readlines():\n",
        "        for sentence in split_text(text):\n",
        "            if len(sentence) <= 5: continue\n",
        "            test_text.append(sentence.strip())\n",
        "\n",
        "test_text = np.array(test_text)\n",
        "\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])"
      ],
      "metadata": {
        "id": "HOIAi-848v-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "7dmwK1he9TyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(preds, axis = 1)"
      ],
      "metadata": {
        "id": "SRHfQiyC9ZEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for vectorId in range(len(person_vectors)):\n",
        "    prob = (preds == vectorId).sum() / len(preds)\n",
        "    print(person_vectors[vectorId], prob)"
      ],
      "metadata": {
        "id": "EeViIw7l_219"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c20d079547a4ff499e9c8dbe593ddd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f52749b7928243719e5c24636b7777cb",
              "IPY_MODEL_1fa094dc9934424aa981c19ced54c067",
              "IPY_MODEL_4a6501ae90a54ef88e54b004867d0def"
            ],
            "layout": "IPY_MODEL_ffd41e4f15674e6f9d2292b641965398"
          }
        },
        "f52749b7928243719e5c24636b7777cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7279b8e89aa144fdb9c723cd8a67dfb3",
            "placeholder": "​",
            "style": "IPY_MODEL_9f7973c086484a89aea6113577bb9487",
            "value": "Downloading (…)solve/main/vocab.txt: "
          }
        },
        "1fa094dc9934424aa981c19ced54c067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c697228244e541d4a877baf1b8542f81",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b29629e162044d1484bedbbe83f35c52",
            "value": 1
          }
        },
        "4a6501ae90a54ef88e54b004867d0def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a017b3cd9804034bfa034061846746a",
            "placeholder": "​",
            "style": "IPY_MODEL_e401c83fb5764f199fdf267946daa525",
            "value": " 1.78M/? [00:00&lt;00:00, 6.42MB/s]"
          }
        },
        "ffd41e4f15674e6f9d2292b641965398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7279b8e89aa144fdb9c723cd8a67dfb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7973c086484a89aea6113577bb9487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c697228244e541d4a877baf1b8542f81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b29629e162044d1484bedbbe83f35c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a017b3cd9804034bfa034061846746a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e401c83fb5764f199fdf267946daa525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcc06bce3684481fae59673d5a797e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7715db69e778468e8a6c424ebff56c97",
              "IPY_MODEL_6b958cf46ebc4170b92a027f68637e4f",
              "IPY_MODEL_c65fb93cd0014b508b220f24c33cc774"
            ],
            "layout": "IPY_MODEL_15b08ce233f74f21a6d94ac366376f36"
          }
        },
        "7715db69e778468e8a6c424ebff56c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d417b89160a2437c90868ee784c7564a",
            "placeholder": "​",
            "style": "IPY_MODEL_77ec1ee59ff04bdaa2838e98c7dfbb8e",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "6b958cf46ebc4170b92a027f68637e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44e8bd1c2efb4547ad952eb5d06b39bd",
            "max": 590,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_185393076ccd4434a8e7d9582a559b93",
            "value": 590
          }
        },
        "c65fb93cd0014b508b220f24c33cc774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b94d824494514f2aac56081c368e7029",
            "placeholder": "​",
            "style": "IPY_MODEL_9fe55d5660da4e65a73e4647511095f8",
            "value": " 590/590 [00:00&lt;00:00, 16.2kB/s]"
          }
        },
        "15b08ce233f74f21a6d94ac366376f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d417b89160a2437c90868ee784c7564a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ec1ee59ff04bdaa2838e98c7dfbb8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44e8bd1c2efb4547ad952eb5d06b39bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185393076ccd4434a8e7d9582a559b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b94d824494514f2aac56081c368e7029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fe55d5660da4e65a73e4647511095f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f3e4d569c9346fd83793ddac12d330a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37891755c15b4c50a66bc1f8d1a71d14",
              "IPY_MODEL_79fc09d63b9143ccbccba7b4d9f55e86",
              "IPY_MODEL_56c8ce486a7642e6bc2d0b72861dc075"
            ],
            "layout": "IPY_MODEL_29268585f7d44c87ab9d39ad041310e1"
          }
        },
        "37891755c15b4c50a66bc1f8d1a71d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc73f69d7d754f01a7fe0343bb259339",
            "placeholder": "​",
            "style": "IPY_MODEL_224ccf326d784786bf9aba6ae3a74c2b",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "79fc09d63b9143ccbccba7b4d9f55e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d0fc3d9060c4d9e85a265ce08a4437d",
            "max": 716133354,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f0f2e50ada6415c96605f9d259cf1f9",
            "value": 716133354
          }
        },
        "56c8ce486a7642e6bc2d0b72861dc075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d56b83b03044443ca31ca67fbef05d3a",
            "placeholder": "​",
            "style": "IPY_MODEL_fc8c212ce9cd4819b5396dd03970a9da",
            "value": " 716M/716M [00:07&lt;00:00, 33.3MB/s]"
          }
        },
        "29268585f7d44c87ab9d39ad041310e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc73f69d7d754f01a7fe0343bb259339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "224ccf326d784786bf9aba6ae3a74c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d0fc3d9060c4d9e85a265ce08a4437d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f0f2e50ada6415c96605f9d259cf1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d56b83b03044443ca31ca67fbef05d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc8c212ce9cd4819b5396dd03970a9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}