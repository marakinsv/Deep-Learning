{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "                !pip install -q transformers"
      ],
      "metadata": {
        "id": "pT-BjEyUSXuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import os\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "KyoyY9YPcx3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0271879a-b82c-46a8-fe3d-d51ab206712d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNlKs_9Hb-VO",
        "outputId": "8b28924c-19bd-405b-efc2-f607620786e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text):\n",
        "    text = text.replace('«', '')\n",
        "    text = text.replace('»', '')\n",
        "    text = text.replace('\"', '')\n",
        "    text = text.replace('-', '')\n",
        "\n",
        "    text = text.replace('т. д.', 'т д')\n",
        "    text = text.replace('т. п.', 'т п')\n",
        "    text = text.replace('др.', 'др')\n",
        "\n",
        "    text = text.replace('...,', ',')\n",
        "    text = text.replace('?,', ',')\n",
        "    text = text.replace('!,', ',')\n",
        "    text = text.replace('.,', ',')\n",
        "    text = text.replace('.)', ')')\n",
        "    text = text.replace(';,', ',')\n",
        "\n",
        "    text = text.replace('....', ';')\n",
        "    text = text.replace('...', ';')\n",
        "    text = text.replace('..', ';')\n",
        "\n",
        "    text = text.replace('!', ';')\n",
        "    text = text.replace('!!', ';')\n",
        "    text = text.replace('!!!', ';')\n",
        "    text = text.replace('?', ';')\n",
        "    text = text.replace('??', ';')\n",
        "    text = text.replace('???', ';')\n",
        "    text = text.replace('!?', ';')\n",
        "    text = text.replace('?!', ';')\n",
        "    text = text.replace('.', ';')\n",
        "    text = text.replace(u'\\xa0', u' ')\n",
        "\n",
        "    return [txt.strip() for txt in text.split(';')]"
      ],
      "metadata": {
        "id": "D6D6Z7QCb_ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка описания психологических векторов.**"
      ],
      "metadata": {
        "id": "zWesr9__cHVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "person_vectors = (\"brown\", \"black\", \"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\")\n",
        "danger_types = (\"type1\", \"type2\", \"type3\", \"type4\")"
      ],
      "metadata": {
        "id": "nejPs-qPcKek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'positive': 0, 'negative': 1}\n",
        "id2label = {0: 'positive', 1: 'negative'}"
      ],
      "metadata": {
        "id": "k1S9fSpmhaSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = []; train_labels = []\n",
        "\n",
        "# Загружаем описание личности человека для каждого вектора из книги В.К. Толкачева\n",
        "for person_vector in person_vectors:\n",
        "    with open(\"drive/MyDrive/vectors/\" + person_vector + \".txt\", encoding=\"utf8\") as rf:\n",
        "        with open(\"drive/MyDrive/vectors/\" + person_vector + \"_neg.txt\", encoding=\"utf8\") as rf_:\n",
        "            sentences_neg = split_text(rf_.read().strip())\n",
        "            for sentence in split_text(rf.read().strip()):\n",
        "                if len(sentence) <= 5: continue\n",
        "                train_text.append(sentence.strip())\n",
        "                if sentence in sentences_neg:\n",
        "                    #print(sentence)\n",
        "                    train_labels.append(1)\n",
        "                else:\n",
        "                  train_labels.append(0)\n",
        "\n",
        "# Загружаем описание личности человека для каждого вектора из книги М.В. Бородянского\n",
        "for person_vector in person_vectors:\n",
        "    with open(\"drive/MyDrive/vectors_/\" + person_vector + \".txt\", encoding=\"utf8\") as rf:\n",
        "        with open(\"drive/MyDrive/vectors_/\" + person_vector + \"_neg.txt\", encoding=\"utf8\") as rf_:\n",
        "            sentences_neg = split_text(rf_.read().strip())\n",
        "            for sentence in split_text(rf.read().strip()):\n",
        "                if len(sentence) <= 5: continue\n",
        "                train_text.append(sentence.strip())\n",
        "                if sentence in sentences_neg:\n",
        "                    #print(sentence)\n",
        "                    train_labels.append(1)\n",
        "                else:\n",
        "                  train_labels.append(0)\n",
        "\n",
        "# Загружаем описание личности человека для каждого типа из книги Джо Наварро \"Опасные личности\"\n",
        "for danger_type in danger_types:\n",
        "    with open(\"drive/MyDrive/danger_types/\" + danger_type + \".txt\", encoding=\"utf8\") as rf:\n",
        "        for text in rf.readlines():\n",
        "            for sentence in split_text(text):\n",
        "              if len(sentence) <= 5: continue\n",
        "              train_text.append(sentence.strip())\n",
        "              train_labels.append(1)\n",
        "\n",
        "train_text = np.array(train_text)\n",
        "train_labels = np.array(train_labels)"
      ],
      "metadata": {
        "id": "TWmmomZOcDb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxhyLe4uj2Mx",
        "outputId": "b0ac2800-43de-4beb-8e09-34261cac529c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Люди, которых я хотел бы описать, выделяются тем, что в их характере обнаруживается, как правило, присутствие следующих трех черт: они аккуратны, бережливы и упрямы',\n",
              "       'От себя добавим, что есть в этом характере и четвертая обязательная черта — склонность к садизму, в том числе и в его скрытых, латентных формах',\n",
              "       'Аккуратность обозначает здесь не только физическую чистоплотность, но также и добросовестность в исполнении иного рода мелких обязательств: на людей аккуратных в этом смысле можно положиться',\n",
              "       'Эти люди обладают морально нравственной чистоплотностью, иногда просто патологически честны',\n",
              "       'Такой ребенок может ответить по телефону: Мама сказала, что ее нет дома',\n",
              "       'Он — классический флегматик (носитель флегматического темперамента), он способен спокойно и рассудительно продумать расходование каждого рубля',\n",
              "       'При покупке товара в магазине ведет себя крайне нерешительно и выбирает долго, перетрогает и перепробует весь то вар, при этом будет спрашивать совет у продавца и других покупателей',\n",
              "       'Он — человек нерешительный, нуждается в советах и ищет советчиков',\n",
              "       'Помогите ему советами в начале дела',\n",
              "       'По нашему мнению его гнев и мстительность — это не гнев и мстительность в чистом виде, а проявления бытового садизма в скрытых формах'],\n",
              "      dtype='<U775')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_text = []; val_labels = []\n",
        "\n",
        "for i in range(2):\n",
        "    rf = None\n",
        "    if i == 0:\n",
        "        with open(\"drive/MyDrive/val/\" + \"Дюймовочка.txt\", encoding=\"utf8\") as rf:\n",
        "            for sentence in split_text(rf.read().strip()):\n",
        "                if len(sentence) <= 5: continue\n",
        "                val_text.append(sentence.strip())\n",
        "                val_labels.append(i)\n",
        "    else:\n",
        "        with open(\"drive/MyDrive/val/\" + \"Потрошитель.txt\", encoding=\"utf8\") as rf:\n",
        "            for sentence in split_text(rf.read().strip()):\n",
        "                if len(sentence) <= 5: continue\n",
        "                val_text.append(sentence.strip())\n",
        "                val_labels.append(i)\n",
        "\n",
        "val_text = np.array(val_text)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "_, val_text, _, val_labels = train_test_split(val_text, val_labels, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "ROaglS0jhXmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxPuKPSsmWcY",
        "outputId": "e6795ca4-9081-428f-daa0-253a09b00e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RWE1dcQ8ZscG"
      },
      "cell_type": "code",
      "source": [
        "#train_text, val_text, train_labels, val_labels = train_test_split(df_vectors['description'], df_vectors['vectorId'],\n",
        "#                                                                    random_state=2018,\n",
        "#                                                                    test_size=0.2,\n",
        "#                                                                   stratify=df_vectors['vectorId'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C6JhRwdZscG",
        "outputId": "4e44a1d9-4fe7-495a-a661-2f74b0147034"
      },
      "cell_type": "code",
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"sberbank-ai/ruBert-base\")\n",
        "bert = BertModel.from_pretrained(\"sberbank-ai/ruBert-base\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at sberbank-ai/ruBert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "yILCzqK0ZscH",
        "outputId": "0ec4ecc3-1a3f-487d-9643-f7917e845075"
      },
      "cell_type": "code",
      "source": [
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)\n",
        "max_seq_len = max(seq_len)\n",
        "print(max_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pcgvy8wEZscI"
      },
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "if max_seq_len>512:\n",
        "    max_seq_len = 512\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfqOwHiEZscI",
        "outputId": "f2218d2c-7168-4dfe-953f-c7e62010be0e"
      },
      "cell_type": "code",
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "print(\"train_y:\",train_y)\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "print(\"val_y:\",val_y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_y: tensor([0, 1, 0,  ..., 1, 1, 1])\n",
            "val_y: tensor([1, 1, 1,  ..., 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "R628lET0ZscJ"
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 16\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Ae32U8K6ZscJ"
      },
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "VOYdFmb5ZscK"
      },
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert, num_classes):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        self.bert = bert\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # relu activation function\n",
        "        self.relu =  nn.ReLU()\n",
        "\n",
        "        # dense layer 1\n",
        "        self.fc1 = nn.Linear(768, 512)\n",
        "\n",
        "        # dense layer 2 (Output layer)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "        #softmax activation function\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "        #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "        #pass the inputs to the model\n",
        "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "\n",
        "        x = self.fc1(cls_hs)\n",
        "\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # output layer\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # apply softmax activation\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Lm02pGy6ZscK"
      },
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert, 2)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "r6o4tHfKZscK"
      },
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "WMgjhIwmZscK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dcbeac1-1e86-412c-b7b8-146ca81bc892"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.89650216 1.1305136 ]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "iHmtEjhUZscL"
      },
      "cell_type": "code",
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.CrossEntropyLoss()\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "F7cf-cFrZscL"
      },
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "    total_labels =[]\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "        # append the model predictions\n",
        "        total_preds+=list(preds)\n",
        "        total_labels+=labels.tolist()\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
        "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hpwv7x0gZscL"
      },
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "    total_labels = []\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "\n",
        "          # Calculate elapsed time in minutes.\n",
        "          #elapsed = format_time(time.time() - t0)\n",
        "\n",
        "          # Report progress.\n",
        "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            preds = model(sent_id, mask)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            preds = np.argmax(preds, axis=1)\n",
        "            total_preds+=list(preds)\n",
        "            total_labels+=labels.tolist()\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
        "    return avg_loss, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "cUK72dHnZscL"
      },
      "cell_type": "code",
      "source": [
        "def save_checkpoint(filename, epoch, model, optimizer, label_map, id2label):\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'model': model,\n",
        "        'optimizer': optimizer,\n",
        "        'label_map': label_map,\n",
        "        'id_map':id2label}\n",
        "    torch.save(state, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IYaQ0CKeZscM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a3485e-e2f2-477d-8202-a814dc051446"
      },
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_train_loss = float('inf')\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, f1_train = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, f1_valid = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if train_loss < best_train_loss:\n",
        "        best_train_loss = train_loss\n",
        "        file_name = 'drive/MyDrive/BERT/model_weights_pos.pt'\n",
        "        save_checkpoint(file_name, epoch, model, optimizer, label_map, id2label)\n",
        "\n",
        "    if valid_loss < best_val_loss:\n",
        "        best_val_loss = valid_loss\n",
        "        file_name = 'drive/MyDrive/BERT/model_weights_pos_val.pt'\n",
        "        save_checkpoint(file_name, epoch, model, optimizer, label_map, id2label)\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "    print(f'\\nTraining F1: {f1_train:.3f}')\n",
        "    print(f'Validation F1: {f1_valid:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 7\n",
            "  Batch   100  of    468.\n",
            "  Batch   200  of    468.\n",
            "  Batch   300  of    468.\n",
            "  Batch   400  of    468.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    153.\n",
            "  Batch   100  of    153.\n",
            "  Batch   150  of    153.\n",
            "\n",
            "Training Loss: 0.523\n",
            "Validation Loss: 0.788\n",
            "\n",
            "Training F1: 0.738\n",
            "Validation F1: 0.687\n",
            "\n",
            " Epoch 2 / 7\n",
            "  Batch   100  of    468.\n",
            "  Batch   200  of    468.\n",
            "  Batch   300  of    468.\n",
            "  Batch   400  of    468.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    153.\n",
            "  Batch   100  of    153.\n",
            "  Batch   150  of    153.\n",
            "\n",
            "Training Loss: 0.460\n",
            "Validation Loss: 0.826\n",
            "\n",
            "Training F1: 0.784\n",
            "Validation F1: 0.661\n",
            "\n",
            " Epoch 3 / 7\n",
            "  Batch   100  of    468.\n",
            "  Batch   200  of    468.\n",
            "  Batch   300  of    468.\n",
            "  Batch   400  of    468.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    153.\n",
            "  Batch   100  of    153.\n",
            "  Batch   150  of    153.\n",
            "\n",
            "Training Loss: 0.450\n",
            "Validation Loss: 0.809\n",
            "\n",
            "Training F1: 0.784\n",
            "Validation F1: 0.682\n",
            "\n",
            " Epoch 4 / 7\n",
            "  Batch   100  of    468.\n",
            "  Batch   200  of    468.\n",
            "  Batch   300  of    468.\n",
            "  Batch   400  of    468.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    153.\n",
            "  Batch   100  of    153.\n",
            "  Batch   150  of    153.\n",
            "\n",
            "Training Loss: 0.419\n",
            "Validation Loss: 0.455\n",
            "\n",
            "Training F1: 0.807\n",
            "Validation F1: 0.844\n",
            "\n",
            " Epoch 5 / 7\n",
            "  Batch   100  of    468.\n",
            "  Batch   200  of    468.\n",
            "  Batch   300  of    468.\n",
            "  Batch   400  of    468.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    153.\n",
            "  Batch   100  of    153.\n",
            "  Batch   150  of    153.\n",
            "\n",
            "Training Loss: 0.425\n",
            "Validation Loss: 0.514\n",
            "\n",
            "Training F1: 0.808\n",
            "Validation F1: 0.824\n",
            "\n",
            " Epoch 6 / 7\n",
            "  Batch   100  of    468.\n",
            "  Batch   200  of    468.\n",
            "  Batch   300  of    468.\n",
            "  Batch   400  of    468.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    153.\n",
            "  Batch   100  of    153.\n",
            "  Batch   150  of    153.\n",
            "\n",
            "Training Loss: 0.413\n",
            "Validation Loss: 0.303\n",
            "\n",
            "Training F1: 0.807\n",
            "Validation F1: 0.898\n",
            "\n",
            " Epoch 7 / 7\n",
            "  Batch   100  of    468.\n",
            "  Batch   200  of    468.\n",
            "  Batch   300  of    468.\n",
            "  Batch   400  of    468.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    153.\n",
            "  Batch   100  of    153.\n",
            "  Batch   150  of    153.\n",
            "\n",
            "Training Loss: 0.414\n",
            "Validation Loss: 0.587\n",
            "\n",
            "Training F1: 0.810\n",
            "Validation F1: 0.789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/BERT/model_weights_pos_val.pt'\n",
        "\n",
        "checkpoint = torch.load(path, map_location=device)\n",
        "model_pos = checkpoint.get(\"model\")"
      ],
      "metadata": {
        "id": "Kg-c-nty3MjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the test set\n",
        "test_text = []\n",
        "\n",
        "with open(\"drive/MyDrive/val/Потрошитель.txt\", encoding=\"utf8\") as rf:\n",
        "    for sentence in split_text(rf.read().strip()):\n",
        "        if len(sentence) <= 5: continue\n",
        "        test_text.append(sentence.strip())\n",
        "\n",
        "test_text = np.array(test_text)\n",
        "\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 250,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])"
      ],
      "metadata": {
        "id": "QFdmOytP3Zlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "count_seq = 500\n",
        "need_br = False\n",
        "\n",
        "vectors_pos = [0] * 2\n",
        "\n",
        "count = 0\n",
        "\n",
        "while True:\n",
        "    count += 1\n",
        "    next_idx = idx + count_seq\n",
        "    if idx + count_seq >= len(test_seq) - 1:\n",
        "        next_idx = len(test_seq)\n",
        "        need_br = True\n",
        "    #print(idx, next_idx)\n",
        "    # get predictions for test data\n",
        "    logits_pos = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits_pos = model(test_seq[idx: next_idx].to(device), test_mask[idx: next_idx].to(device))\n",
        "\n",
        "    probs_pos = (torch.nn.functional.softmax(logits_pos, dim=1)).detach().cpu().numpy()\n",
        "    for posId, prob in enumerate(np.mean(probs_pos, axis=0).tolist()):\n",
        "      vectors_pos[posId] += prob\n",
        "\n",
        "    idx += count_seq\n",
        "    if need_br: break\n",
        "\n",
        "vectors_pos = np.array(vectors_pos) / count"
      ],
      "metadata": {
        "id": "5wCGZdeD3eoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('positive: {}, negative - {}'.format(vectors_pos[0], vectors_pos[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmBLxuUv3w4s",
        "outputId": "99534a3f-9669-4833-8fe4-1b4128f12925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive: 0.3401610334714254, negative - 0.6598389426867167\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}